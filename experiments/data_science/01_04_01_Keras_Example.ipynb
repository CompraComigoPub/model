{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f6e4f4",
   "metadata": {},
   "source": [
    "# Models with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392112c",
   "metadata": {},
   "source": [
    "Trains models on synthetic data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1edadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d2b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import arange\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84cb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_compra_comigo.experimenter import Experimenter\n",
    "from model_compra_comigo.data_handler.data_simulator import DataSimulator\n",
    "from model_compra_comigo.data_handler import DataHandler\n",
    "from model_compra_comigo.data_handler.utils import plot_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7bd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_simulator = DataSimulator()\n",
    "data_handler = DataHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278e88c",
   "metadata": {},
   "source": [
    "## Generate a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb74e019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x800>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_range = 365*3\n",
    "split = 365\n",
    "time_data = arange(time_range)\n",
    "\n",
    "series, parameters = data_simulator.generate(\n",
    "    time_range = time_range,\n",
    ")\n",
    "\n",
    "labels=[(f\"trend_slope = {parameters['trend_slope']}\\n\"\n",
    "         f\"seasonality_period = {parameters['seasonality_period']}\\n\"\n",
    "         f\"seasonality_amplitude = {parameters['seasonality_amplitude']}\\n\"\n",
    "         f\"seasonality_phase = {parameters['seasonality_phase']}\\n\"\n",
    "         f\"seasonality_time_threshold = {parameters['seasonality_time_threshold']}\\n\"\n",
    "         f\"seasonality_ncos = {parameters['seasonality_ncos']}\\n\"\n",
    "         f\"seasonality_nexp = {parameters['seasonality_nexp']}\\n\"\n",
    "         f\"noise_scaling_factor = {parameters['noise_scaling_factor']}\\n\"\n",
    "         f\"autocorrelation_amplitude = {parameters['autocorrelation_amplitude']}\\n\"\n",
    "         f\"autocorrelation_phi = {parameters['autocorrelation_phi']}\"\n",
    "        )]\n",
    "\n",
    "data_handler.plot_series(\n",
    "    time=time_data,\n",
    "    series=series,\n",
    "    labels=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed6caf",
   "metadata": {},
   "source": [
    "## Creates Windowed Dataset with N forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "033cf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "nforecast = 20\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7bc95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=300\n",
    "dataset=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49f69b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_handler.generate_windowed_dataset(\n",
    "    data = series,\n",
    "    window_size = window_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle_buffer_size = shuffle_buffer_size,\n",
    "    nforecast = nforecast,\n",
    "    shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ff414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, TimeDistributed, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bd9cecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 07:02:12.333381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1095]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-25 07:02:12.334129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1095]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset creation function\n",
    "def create_dataset(data, window_size, n):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.window(window_size + n, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + n))\n",
    "    dataset = dataset.map(lambda window: (window[:-n], window[-n:])).shuffle(buffer_size=100)\n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset(series, window_size, nforecast)\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for input_seq, target_seq in dataset:\n",
    "    inputs.append(input_seq.numpy())\n",
    "    targets.append(target_seq.numpy())\n",
    "\n",
    "inputs_ts = tf.convert_to_tensor(inputs)\n",
    "targets_ts = tf.convert_to_tensor(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "603d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2200815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046, 30, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = np.array(inputs)\n",
    "inp = inp.reshape(inp.shape[0], inp.shape[1], 1)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbdb17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046, 20, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array(targets)\n",
    "t = t.reshape(t.shape[0], t.shape[1], 1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9844aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 35.50095574,  31.05878821,  23.86649836,  31.69713304,\n",
      "        34.87904887,  25.94054179,  24.3385511 ,  18.82975711,\n",
      "        11.61124281,  11.26577353,  -2.597541  , -16.56780841,\n",
      "       -17.88060635, -20.83358444, -16.58157204, -19.19608332,\n",
      "       -28.02062634, -15.73223387, -12.76621762, -14.09199302,\n",
      "       -23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 34.87904887,  25.94054179,  24.3385511 ,  18.82975711,\n",
      "        11.61124281,  11.26577353,  -2.597541  , -16.56780841,\n",
      "       -17.88060635, -20.83358444, -16.58157204, -19.19608332,\n",
      "       -28.02062634, -15.73223387, -12.76621762, -14.09199302,\n",
      "       -23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 23.86649836,  31.69713304,  34.87904887,  25.94054179,\n",
      "        24.3385511 ,  18.82975711,  11.61124281,  11.26577353,\n",
      "        -2.597541  , -16.56780841, -17.88060635, -20.83358444,\n",
      "       -16.58157204, -19.19608332, -28.02062634, -15.73223387,\n",
      "       -12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.02062634, -15.73223387, -12.76621762, -14.09199302,\n",
      "       -23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-19.19608332, -28.02062634, -15.73223387, -12.76621762,\n",
      "       -14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 11.61124281,  11.26577353,  -2.597541  , -16.56780841,\n",
      "       -17.88060635, -20.83358444, -16.58157204, -19.19608332,\n",
      "       -28.02062634, -15.73223387, -12.76621762, -14.09199302,\n",
      "       -23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-16.56780841, -17.88060635, -20.83358444, -16.58157204,\n",
      "       -19.19608332, -28.02062634, -15.73223387, -12.76621762,\n",
      "       -14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.88060635, -20.83358444, -16.58157204, -19.19608332,\n",
      "       -28.02062634, -15.73223387, -12.76621762, -14.09199302,\n",
      "       -23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ,\n",
      "        10.52495473,  26.80256559,  14.89549679,  14.2120442 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 25.94054179,  24.3385511 ,  18.82975711,  11.61124281,\n",
      "        11.26577353,  -2.597541  , -16.56780841, -17.88060635,\n",
      "       -20.83358444, -16.58157204, -19.19608332, -28.02062634,\n",
      "       -15.73223387, -12.76621762, -14.09199302, -23.06607258,\n",
      "       -27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.06607258, -27.12225277, -23.51686458, -29.27809746,\n",
      "       -26.5205597 , -27.55894507, -29.59322765, -32.06700723,\n",
      "       -18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473,\n",
      "        26.80256559,  14.89549679,  14.2120442 ,   6.60137577])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([32.54861768, 31.87835152, 24.90212536, 25.55156357, 18.6136465 ,\n",
      "       13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([27.3567797 , 31.13897622, 30.07589012, 32.54861768, 31.87835152,\n",
      "       24.90212536, 25.55156357, 18.6136465 , 13.4551445 , 10.181703  ,\n",
      "       10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ,\n",
      "       -66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473,\n",
      "        26.80256559,  14.89549679,  14.2120442 ,   6.60137577,\n",
      "         2.23218413,  13.22627403])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756,\n",
      "       19.05684612, 24.81353912, 32.07915975, 24.2053383 , 20.44653167])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([30.07589012, 32.54861768, 31.87835152, 24.90212536, 25.55156357,\n",
      "       18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 24.3385511 ,  18.82975711,  11.61124281,  11.26577353,\n",
      "        -2.597541  , -16.56780841, -17.88060635, -20.83358444,\n",
      "       -16.58157204, -19.19608332, -28.02062634, -15.73223387,\n",
      "       -12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([31.13897622, 30.07589012, 32.54861768, 31.87835152, 24.90212536,\n",
      "       25.55156357, 18.6136465 , 13.4551445 , 10.181703  , 10.52495473,\n",
      "       26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228, -72.07863276, -81.83213321])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-15.73223387, -12.76621762, -14.09199302, -23.06607258,\n",
      "       -27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ,\n",
      "        10.52495473,  26.80256559,  14.89549679,  14.2120442 ,\n",
      "         6.60137577,   2.23218413,  13.22627403,  16.39113981,\n",
      "         8.46271719,   4.14273222,  11.75100712,  10.22413696,\n",
      "        11.96761474,  15.20830462])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912,\n",
      "       32.07915975, 24.2053383 , 20.44653167, 19.97016802, 17.34540155,\n",
      "       31.22694707, 37.03838759, 26.3225838 , 31.35001544, 48.24119707])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 26.7360806 ,  35.50095574,  31.05878821,  23.86649836,\n",
      "        31.69713304,  34.87904887,  25.94054179,  24.3385511 ,\n",
      "        18.82975711,  11.61124281,  11.26577353,  -2.597541  ,\n",
      "       -16.56780841, -17.88060635, -20.83358444, -16.58157204,\n",
      "       -19.19608332, -28.02062634, -15.73223387, -12.76621762,\n",
      "       -14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612,\n",
      "       24.81353912, 32.07915975, 24.2053383 , 20.44653167, 19.97016802])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 31.69713304,  34.87904887,  25.94054179,  24.3385511 ,\n",
      "        18.82975711,  11.61124281,  11.26577353,  -2.597541  ,\n",
      "       -16.56780841, -17.88060635, -20.83358444, -16.58157204,\n",
      "       -19.19608332, -28.02062634, -15.73223387, -12.76621762,\n",
      "       -14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756,\n",
      "       19.05684612, 24.81353912, 32.07915975, 24.2053383 , 20.44653167,\n",
      "       19.97016802, 17.34540155, 31.22694707, 37.03838759, 26.3225838 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 1.74950479, 27.3567797 , 31.13897622, 30.07589012, 32.54861768,\n",
      "       31.87835152, 24.90212536, 25.55156357, 18.6136465 , 13.4551445 ,\n",
      "       10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-2.30145415,  1.74950479, 27.3567797 , 31.13897622, 30.07589012,\n",
      "       32.54861768, 31.87835152, 24.90212536, 25.55156357, 18.6136465 ,\n",
      "       13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 18.82975711,  11.61124281,  11.26577353,  -2.597541  ,\n",
      "       -16.56780841, -17.88060635, -20.83358444, -16.58157204,\n",
      "       -19.19608332, -28.02062634, -15.73223387, -12.76621762,\n",
      "       -14.09199302, -23.06607258, -27.12225277, -23.51686458,\n",
      "       -29.27809746, -26.5205597 , -27.55894507, -29.59322765,\n",
      "       -32.06700723, -18.82476274, -17.01115558, -27.89690405,\n",
      "       -23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217, -46.53193091, -42.1385738 ,\n",
      "       -55.35669582, -54.55357809, -53.69160883, -58.37035013,\n",
      "       -53.46104984, -44.8335132 , -39.51598547, -47.70648874,\n",
      "       -53.32808099, -51.19783676, -45.09986945, -49.79186939,\n",
      "       -54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ,\n",
      "        10.52495473,  26.80256559])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 15.20830462,  12.09216166,  27.45549888,  34.60841127,\n",
      "        17.84155919,  17.03987712,  16.77075776,  23.13223269,\n",
      "        20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473,\n",
      "        26.80256559,  14.89549679,  14.2120442 ,   6.60137577,\n",
      "         2.23218413,  13.22627403,  16.39113981,   8.46271719,\n",
      "         4.14273222,  11.75100712,  10.22413696,  11.96761474,\n",
      "        15.20830462,  12.09216166])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975,\n",
      "       24.2053383 , 20.44653167, 19.97016802, 17.34540155, 31.22694707,\n",
      "       37.03838759, 26.3225838 , 31.35001544, 48.24119707, 54.06493159])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473,\n",
      "        26.80256559,  14.89549679,  14.2120442 ,   6.60137577,\n",
      "         2.23218413,  13.22627403,  16.39113981,   8.46271719,\n",
      "         4.14273222,  11.75100712])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269,\n",
      "       20.48695756, 19.05684612, 24.81353912, 32.07915975, 24.2053383 ,\n",
      "       20.44653167, 19.97016802, 17.34540155, 31.22694707, 37.03838759])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 17.03987712,  16.77075776,  23.13223269,  20.48695756,\n",
      "        19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  8.46271719,   4.14273222,  11.75100712,  10.22413696,\n",
      "        11.96761474,  15.20830462,  12.09216166,  27.45549888,\n",
      "        34.60841127,  17.84155919,  17.03987712,  16.77075776,\n",
      "        23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.73421685, -69.53599301, -66.41834844, -74.6054292 ,\n",
      "       -68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.04220562, -55.78628484, -55.84174217, -46.53193091,\n",
      "       -42.1385738 , -55.35669582, -54.55357809, -53.69160883,\n",
      "       -58.37035013, -53.46104984, -44.8335132 , -39.51598547,\n",
      "       -47.70648874, -53.32808099, -51.19783676, -45.09986945,\n",
      "       -49.79186939, -54.51002167, -62.63956677, -71.58715818,\n",
      "       -64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-68.217067  , -76.55679624, -76.40372561, -59.82984212,\n",
      "       -67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 12.09216166,  27.45549888,  34.60841127,  17.84155919,\n",
      "        17.03987712,  16.77075776,  23.13223269,  20.48695756,\n",
      "        19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([24.90212536, 25.55156357, 18.6136465 , 13.4551445 , 10.181703  ,\n",
      "       10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([24.90212536, 25.55156357, 18.6136465 , 13.4551445 , 10.181703  ,\n",
      "       10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-16.58157204, -19.19608332, -28.02062634, -15.73223387,\n",
      "       -12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092, -41.01124055, -51.04220562,\n",
      "       -55.78628484, -55.84174217])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ,\n",
      "        10.181703  ,  10.52495473,  26.80256559,  14.89549679,\n",
      "        14.2120442 ,   6.60137577])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975,\n",
      "       24.2053383 , 20.44653167, 19.97016802, 17.34540155, 31.22694707,\n",
      "       37.03838759, 26.3225838 , 31.35001544, 48.24119707, 54.06493159])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 16.77075776,  23.13223269,  20.48695756,  19.05684612,\n",
      "        24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.51002167, -62.63956677, -71.58715818, -64.8448447 ,\n",
      "       -53.1190795 , -54.66849744, -51.48102205, -50.28394252,\n",
      "       -58.17463856, -58.73047229, -49.07558376, -51.30483641,\n",
      "       -46.06038471, -65.77241327, -66.53089464, -62.92988528,\n",
      "       -67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559,\n",
      "        14.89549679,  14.2120442 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ,\n",
      "        10.181703  ,  10.52495473])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 17.84155919,  17.03987712,  16.77075776,  23.13223269,\n",
      "        20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559,\n",
      "        14.89549679,  14.2120442 ,   6.60137577,   2.23218413])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ,\n",
      "        10.181703  ,  10.52495473,  26.80256559,  14.89549679,\n",
      "        14.2120442 ,   6.60137577,   2.23218413,  13.22627403,\n",
      "        16.39113981,   8.46271719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912,\n",
      "       32.07915975, 24.2053383 , 20.44653167, 19.97016802, 17.34540155])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-70.96730216, -64.63031228, -72.07863276, -81.83213321,\n",
      "       -75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-67.35384456, -76.62096424, -75.60991438, -78.2600511 ,\n",
      "       -88.80158805, -87.30438792, -90.14988336, -85.47915426,\n",
      "       -87.49130508, -76.2117089 , -77.52271447, -81.25843525,\n",
      "       -73.47588124, -79.53590913, -78.6715574 , -66.47930556,\n",
      "       -75.87316101, -76.61148518, -70.96730216, -64.63031228])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  4.14273222,  11.75100712,  10.22413696,  11.96761474,\n",
      "        15.20830462,  12.09216166,  27.45549888,  34.60841127,\n",
      "        17.84155919,  17.03987712,  16.77075776,  23.13223269,\n",
      "        20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 1.74950479, 27.3567797 , 31.13897622, 30.07589012, 32.54861768,\n",
      "       31.87835152, 24.90212536, 25.55156357, 18.6136465 , 13.4551445 ,\n",
      "       10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 16.77075776,  23.13223269,  20.48695756,  19.05684612,\n",
      "        24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ,\n",
      "       -77.52271447, -81.25843525, -73.47588124, -79.53590913,\n",
      "       -78.6715574 , -66.47930556, -75.87316101, -76.61148518,\n",
      "       -70.96730216, -64.63031228])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([25.55156357, 18.6136465 , 13.4551445 , 10.181703  , 10.52495473,\n",
      "       26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905, -74.01945992, -83.34690084,\n",
      "       -76.73421685, -69.53599301, -66.41834844, -74.6054292 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ,\n",
      "       -54.66849744, -51.48102205, -50.28394252, -58.17463856,\n",
      "       -58.73047229, -49.07558376, -51.30483641, -46.06038471,\n",
      "       -65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177, -82.00557186, -91.59249844,\n",
      "       -89.15433706, -83.9011135 , -83.33124763, -84.79350202,\n",
      "       -93.87733144, -96.03141701, -94.65602659, -97.58086949,\n",
      "       -96.42928854, -90.38647819, -75.59036149, -73.5081707 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([30.07589012, 32.54861768, 31.87835152, 24.90212536, 25.55156357,\n",
      "       18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([32.54861768, 31.87835152, 24.90212536, 25.55156357, 18.6136465 ,\n",
      "       13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101,\n",
      "       -76.61148518, -70.96730216])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([31.13897622, 30.07589012, 32.54861768, 31.87835152, 24.90212536,\n",
      "       25.55156357, 18.6136465 , 13.4551445 , 10.181703  , 10.52495473,\n",
      "       26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 11.26577353,  -2.597541  , -16.56780841, -17.88060635,\n",
      "       -20.83358444, -16.58157204, -19.19608332, -28.02062634,\n",
      "       -15.73223387, -12.76621762, -14.09199302, -23.06607258,\n",
      "       -27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677,\n",
      "       -71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.31199139, -68.76685337, -65.90750987, -62.59761776,\n",
      "       -66.35902059, -64.69539496, -60.41614616, -64.35231518,\n",
      "       -51.70904361, -45.88653058, -56.69901358, -53.79257359,\n",
      "       -57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.87316101, -76.61148518, -70.96730216, -64.63031228,\n",
      "       -72.07863276, -81.83213321, -75.31199139, -68.76685337,\n",
      "       -65.90750987, -62.59761776, -66.35902059, -64.69539496,\n",
      "       -60.41614616, -64.35231518, -51.70904361, -45.88653058,\n",
      "       -56.69901358, -53.79257359, -57.74075855, -53.31569498,\n",
      "       -42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-57.74075855, -53.31569498, -42.90707875, -48.78827414,\n",
      "       -44.63475162, -40.14020947, -36.27026719, -24.64926779,\n",
      "       -28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([27.3567797 , 31.13897622, 30.07589012, 32.54861768, 31.87835152,\n",
      "       24.90212536, 25.55156357, 18.6136465 , 13.4551445 , 10.181703  ,\n",
      "       10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685, -69.53599301, -66.41834844,\n",
      "       -74.6054292 , -68.217067  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124,\n",
      "       -79.53590913, -78.6715574 , -66.47930556, -75.87316101])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 31.05878821,  23.86649836,  31.69713304,  34.87904887,\n",
      "        25.94054179,  24.3385511 ,  18.82975711,  11.61124281,\n",
      "        11.26577353,  -2.597541  , -16.56780841, -17.88060635,\n",
      "       -20.83358444, -16.58157204, -19.19608332, -28.02062634,\n",
      "       -15.73223387, -12.76621762, -14.09199302, -23.06607258,\n",
      "       -27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.90593835, -30.76415026, -31.92433778, -43.31385151,\n",
      "       -53.12329577, -48.01518719, -39.14163662, -36.84869924,\n",
      "       -38.46987092, -41.01124055, -51.04220562, -55.78628484,\n",
      "       -55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 34.60841127,  17.84155919,  17.03987712,  16.77075776,\n",
      "        23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([25.55156357, 18.6136465 , 13.4551445 , 10.181703  , 10.52495473,\n",
      "       26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269,\n",
      "       20.48695756, 19.05684612, 24.81353912, 32.07915975, 24.2053383 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ,\n",
      "        10.52495473,  26.80256559,  14.89549679,  14.2120442 ,\n",
      "         6.60137577,   2.23218413])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269,\n",
      "       20.48695756, 19.05684612, 24.81353912, 32.07915975, 24.2053383 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 11.96761474,  15.20830462,  12.09216166,  27.45549888,\n",
      "        34.60841127,  17.84155919,  17.03987712,  16.77075776,\n",
      "        23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379,\n",
      "       -69.81462362, -69.94992041, -72.95703905, -74.01945992,\n",
      "       -83.34690084, -76.73421685])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456,\n",
      "       -76.62096424, -75.60991438, -78.2600511 , -88.80158805,\n",
      "       -87.30438792, -90.14988336, -85.47915426, -87.49130508,\n",
      "       -76.2117089 , -77.52271447, -81.25843525, -73.47588124])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ,\n",
      "        10.52495473,  26.80256559,  14.89549679,  14.2120442 ,\n",
      "         6.60137577,   2.23218413,  13.22627403,  16.39113981,\n",
      "         8.46271719,   4.14273222])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975,\n",
      "       24.2053383 , 20.44653167, 19.97016802, 17.34540155, 31.22694707])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912,\n",
      "       32.07915975, 24.2053383 , 20.44653167, 19.97016802, 17.34540155])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.47930556, -75.87316101, -76.61148518, -70.96730216,\n",
      "       -64.63031228, -72.07863276, -81.83213321, -75.31199139,\n",
      "       -68.76685337, -65.90750987, -62.59761776, -66.35902059,\n",
      "       -64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129, -24.76759396, -26.08279549,\n",
      "       -11.05815156,  -6.59657173, -18.66715127, -29.40068022,\n",
      "       -26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039, -43.99667345, -40.37587525,\n",
      "       -34.1200691 , -33.40391129])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-64.8448447 , -53.1190795 , -54.66849744, -51.48102205,\n",
      "       -50.28394252, -58.17463856, -58.73047229, -49.07558376,\n",
      "       -51.30483641, -46.06038471, -65.77241327, -66.53089464,\n",
      "       -62.92988528, -67.43801966, -68.35270157, -82.04093824,\n",
      "       -84.80819467, -78.69033684, -67.54763889, -70.92535333,\n",
      "       -79.60688356, -82.93722056, -75.6151789 , -72.05329685,\n",
      "       -77.26219484, -75.17905918, -73.9672208 , -68.97457988,\n",
      "       -74.41286548, -79.61992177])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 16.39113981,   8.46271719,   4.14273222,  11.75100712,\n",
      "        10.22413696,  11.96761474,  15.20830462,  12.09216166,\n",
      "        27.45549888,  34.60841127,  17.84155919,  17.03987712,\n",
      "        16.77075776,  23.13223269,  20.48695756,  19.05684612,\n",
      "        24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-8.98634392, -2.30145415,  1.74950479, 27.3567797 , 31.13897622,\n",
      "       30.07589012, 32.54861768, 31.87835152, 24.90212536, 25.55156357,\n",
      "       18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 17.84155919,  17.03987712,  16.77075776,  23.13223269,\n",
      "        20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([10.52495473, 26.80256559, 14.89549679, 14.2120442 ,  6.60137577,\n",
      "        2.23218413, 13.22627403, 16.39113981,  8.46271719,  4.14273222,\n",
      "       11.75100712, 10.22413696, 11.96761474, 15.20830462, 12.09216166,\n",
      "       27.45549888, 34.60841127, 17.84155919, 17.03987712, 16.77075776,\n",
      "       23.13223269, 20.48695756, 19.05684612, 24.81353912, 32.07915975,\n",
      "       24.2053383 , 20.44653167, 19.97016802, 17.34540155, 31.22694707])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 24.93884072,  26.7360806 ,  35.50095574,  31.05878821,\n",
      "        23.86649836,  31.69713304,  34.87904887,  25.94054179,\n",
      "        24.3385511 ,  18.82975711,  11.61124281,  11.26577353,\n",
      "        -2.597541  , -16.56780841, -17.88060635, -20.83358444,\n",
      "       -16.58157204, -19.19608332, -28.02062634, -15.73223387,\n",
      "       -12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-18.82476274, -17.01115558, -27.89690405, -23.90593835,\n",
      "       -30.76415026, -31.92433778, -43.31385151, -53.12329577,\n",
      "       -48.01518719, -39.14163662, -36.84869924, -38.46987092,\n",
      "       -41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756,\n",
      "       19.05684612, 24.81353912, 32.07915975, 24.2053383 , 20.44653167])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-8.98634392, -2.30145415,  1.74950479, 27.3567797 , 31.13897622,\n",
      "       30.07589012, 32.54861768, 31.87835152, 24.90212536, 25.55156357,\n",
      "       18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([31.87835152, 24.90212536, 25.55156357, 18.6136465 , 13.4551445 ,\n",
      "       10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-22.96991088, -19.05401836, -24.8845942 , -20.99511075,\n",
      "       -12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559,\n",
      "        14.89549679,  14.2120442 ,   6.60137577,   2.23218413,\n",
      "        13.22627403,  16.39113981])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612,\n",
      "       24.81353912, 32.07915975, 24.2053383 , 20.44653167, 19.97016802])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 27.45549888,  34.60841127,  17.84155919,  17.03987712,\n",
      "        16.77075776,  23.13223269,  20.48695756,  19.05684612,\n",
      "        24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949, -96.42928854, -90.38647819,\n",
      "       -75.59036149, -73.5081707 , -75.18334068, -76.74951483,\n",
      "       -90.76704699, -91.73993674, -87.36744379, -69.81462362,\n",
      "       -69.94992041, -72.95703905])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624,\n",
      "       -76.40372561, -59.82984212, -67.35384456, -76.62096424,\n",
      "       -75.60991438, -78.2600511 , -88.80158805, -87.30438792,\n",
      "       -90.14988336, -85.47915426, -87.49130508, -76.2117089 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-65.77241327, -66.53089464, -62.92988528, -67.43801966,\n",
      "       -68.35270157, -82.04093824, -84.80819467, -78.69033684,\n",
      "       -67.54763889, -70.92535333, -79.60688356, -82.93722056,\n",
      "       -75.6151789 , -72.05329685, -77.26219484, -75.17905918,\n",
      "       -73.9672208 , -68.97457988, -74.41286548, -79.61992177,\n",
      "       -82.00557186, -91.59249844, -89.15433706, -83.9011135 ,\n",
      "       -83.33124763, -84.79350202, -93.87733144, -96.03141701,\n",
      "       -94.65602659, -97.58086949])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-96.42928854, -90.38647819, -75.59036149, -73.5081707 ,\n",
      "       -75.18334068, -76.74951483, -90.76704699, -91.73993674,\n",
      "       -87.36744379, -69.81462362, -69.94992041, -72.95703905,\n",
      "       -74.01945992, -83.34690084, -76.73421685, -69.53599301,\n",
      "       -66.41834844, -74.6054292 , -68.217067  , -76.55679624])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901,\n",
      "       -29.68458137, -27.67355936, -20.91415141, -24.88158385,\n",
      "       -22.96991088, -19.05401836])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768,  31.87835152,  24.90212536,\n",
      "        25.55156357,  18.6136465 ,  13.4551445 ,  10.181703  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ,\n",
      "        10.181703  ,  10.52495473,  26.80256559,  14.89549679,\n",
      "        14.2120442 ,   6.60137577,   2.23218413,  13.22627403,\n",
      "        16.39113981,   8.46271719,   4.14273222,  11.75100712,\n",
      "        10.22413696,  11.96761474])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612,\n",
      "       24.81353912, 32.07915975, 24.2053383 , 20.44653167, 19.97016802,\n",
      "       17.34540155, 31.22694707, 37.03838759, 26.3225838 , 31.35001544])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612,\n",
      "       24.81353912, 32.07915975, 24.2053383 , 20.44653167, 19.97016802,\n",
      "       17.34540155, 31.22694707, 37.03838759, 26.3225838 , 31.35001544])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814, -21.89853901, -29.68458137,\n",
      "       -27.67355936, -20.91415141, -24.88158385, -22.96991088,\n",
      "       -19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([18.6136465 , 13.4551445 , 10.181703  , 10.52495473, 26.80256559,\n",
      "       14.89549679, 14.2120442 ,  6.60137577,  2.23218413, 13.22627403,\n",
      "       16.39113981,  8.46271719,  4.14273222, 11.75100712, 10.22413696,\n",
      "       11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-2.30145415,  1.74950479, 27.3567797 , 31.13897622, 30.07589012,\n",
      "       32.54861768, 31.87835152, 24.90212536, 25.55156357, 18.6136465 ,\n",
      "       13.4551445 , 10.181703  , 10.52495473, 26.80256559, 14.89549679,\n",
      "       14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 17.03987712,  16.77075776,  23.13223269,  20.48695756,\n",
      "        19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-76.61148518, -70.96730216, -64.63031228, -72.07863276,\n",
      "       -81.83213321, -75.31199139, -68.76685337, -65.90750987,\n",
      "       -62.59761776, -66.35902059, -64.69539496, -60.41614616,\n",
      "       -64.35231518, -51.70904361, -45.88653058, -56.69901358,\n",
      "       -53.79257359, -57.74075855, -53.31569498, -42.90707875,\n",
      "       -48.78827414, -44.63475162, -40.14020947, -36.27026719,\n",
      "       -24.64926779, -28.18693742, -38.29600244, -45.5628245 ,\n",
      "       -50.41493826, -49.02019039])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022, -26.29957481, -25.91729805,\n",
      "       -21.83523093, -17.86154858, -19.38442869, -26.01227339,\n",
      "       -36.0666894 , -37.01401294, -26.77293814, -21.89853901])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ,\n",
      "        10.181703  ,  10.52495473,  26.80256559,  14.89549679])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-42.90707875, -48.78827414, -44.63475162, -40.14020947,\n",
      "       -36.27026719, -24.64926779, -28.18693742, -38.29600244,\n",
      "       -45.5628245 , -50.41493826, -49.02019039, -43.99667345,\n",
      "       -40.37587525, -34.1200691 , -33.40391129, -24.76759396,\n",
      "       -26.08279549, -11.05815156,  -6.59657173, -18.66715127,\n",
      "       -29.40068022, -26.29957481, -25.91729805, -21.83523093,\n",
      "       -17.86154858, -19.38442869, -26.01227339, -36.0666894 ,\n",
      "       -37.01401294, -26.77293814])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.18693742, -38.29600244, -45.5628245 , -50.41493826,\n",
      "       -49.02019039, -43.99667345, -40.37587525, -34.1200691 ,\n",
      "       -33.40391129, -24.76759396, -26.08279549, -11.05815156,\n",
      "        -6.59657173, -18.66715127, -29.40068022, -26.29957481,\n",
      "       -25.91729805, -21.83523093, -17.86154858, -19.38442869,\n",
      "       -26.01227339, -36.0666894 , -37.01401294, -26.77293814,\n",
      "       -21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-19.05401836, -24.8845942 , -20.99511075, -12.94546845,\n",
      "        -4.10066211,   3.58724588,  -6.67613226, -15.15874378,\n",
      "        -8.98634392,  -2.30145415,   1.74950479,  27.3567797 ,\n",
      "        31.13897622,  30.07589012,  32.54861768,  31.87835152,\n",
      "        24.90212536,  25.55156357,  18.6136465 ,  13.4551445 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.89853901, -29.68458137, -27.67355936, -20.91415141,\n",
      "       -24.88158385, -22.96991088, -19.05401836, -24.8845942 ,\n",
      "       -20.99511075, -12.94546845,  -4.10066211,   3.58724588,\n",
      "        -6.67613226, -15.15874378,  -8.98634392,  -2.30145415,\n",
      "         1.74950479,  27.3567797 ,  31.13897622,  30.07589012,\n",
      "        32.54861768,  31.87835152,  24.90212536,  25.55156357,\n",
      "        18.6136465 ,  13.4551445 ,  10.181703  ,  10.52495473,\n",
      "        26.80256559,  14.89549679])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([14.2120442 ,  6.60137577,  2.23218413, 13.22627403, 16.39113981,\n",
      "        8.46271719,  4.14273222, 11.75100712, 10.22413696, 11.96761474,\n",
      "       15.20830462, 12.09216166, 27.45549888, 34.60841127, 17.84155919,\n",
      "       17.03987712, 16.77075776, 23.13223269, 20.48695756, 19.05684612])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.47058793, -33.20703003, -28.3880031 , -30.28747406,\n",
      "       -31.64097778, -24.20094644, -29.14270043, -29.43103609,\n",
      "       -31.07422697, -34.79360621, -28.32274363, -23.10125036,\n",
      "       -20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-68.97457988, -74.41286548, -79.61992177, -82.00557186,\n",
      "       -91.59249844, -89.15433706, -83.9011135 , -83.33124763,\n",
      "       -84.79350202, -93.87733144, -96.03141701, -94.65602659,\n",
      "       -97.58086949, -96.42928854, -90.38647819, -75.59036149,\n",
      "       -73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-74.6054292 , -68.217067  , -76.55679624, -76.40372561,\n",
      "       -59.82984212, -67.35384456, -76.62096424, -75.60991438,\n",
      "       -78.2600511 , -88.80158805, -87.30438792, -90.14988336,\n",
      "       -85.47915426, -87.49130508, -76.2117089 , -77.52271447,\n",
      "       -81.25843525, -73.47588124, -79.53590913, -78.6715574 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-71.58715818, -64.8448447 , -53.1190795 , -54.66849744,\n",
      "       -51.48102205, -50.28394252, -58.17463856, -58.73047229,\n",
      "       -49.07558376, -51.30483641, -46.06038471, -65.77241327,\n",
      "       -66.53089464, -62.92988528, -67.43801966, -68.35270157,\n",
      "       -82.04093824, -84.80819467, -78.69033684, -67.54763889,\n",
      "       -70.92535333, -79.60688356, -82.93722056, -75.6151789 ,\n",
      "       -72.05329685, -77.26219484, -75.17905918, -73.9672208 ,\n",
      "       -68.97457988, -74.41286548])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149, -73.5081707 , -75.18334068,\n",
      "       -76.74951483, -90.76704699, -91.73993674, -87.36744379])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462,\n",
      "       12.09216166, 27.45549888, 34.60841127, 17.84155919, 17.03987712,\n",
      "       16.77075776, 23.13223269, 20.48695756, 19.05684612, 24.81353912,\n",
      "       32.07915975, 24.2053383 , 20.44653167, 19.97016802, 17.34540155,\n",
      "       31.22694707, 37.03838759, 26.3225838 , 31.35001544, 48.24119707])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425, -21.11952555, -28.77036928,\n",
      "       -31.92780838, -52.57262215, -59.94663704, -54.39197114,\n",
      "       -57.87783181, -43.84103585, -47.763687  , -51.69679116,\n",
      "       -46.4540148 , -33.84324657, -41.5256601 , -35.89039793])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-64.69539496, -60.41614616, -64.35231518, -51.70904361,\n",
      "       -45.88653058, -56.69901358, -53.79257359, -57.74075855,\n",
      "       -53.31569498, -42.90707875, -48.78827414, -44.63475162,\n",
      "       -40.14020947, -36.27026719, -24.64926779, -28.18693742,\n",
      "       -38.29600244, -45.5628245 , -50.41493826, -49.02019039,\n",
      "       -43.99667345, -40.37587525, -34.1200691 , -33.40391129,\n",
      "       -24.76759396, -26.08279549, -11.05815156,  -6.59657173,\n",
      "       -18.66715127, -29.40068022])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478,\n",
      "       -31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559,\n",
      "        14.89549679,  14.2120442 ,   6.60137577,   2.23218413,\n",
      "        13.22627403,  16.39113981,   8.46271719,   4.14273222,\n",
      "        11.75100712,  10.22413696,  11.96761474,  15.20830462,\n",
      "        12.09216166,  27.45549888])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 34.60841127,  17.84155919,  17.03987712,  16.77075776,\n",
      "        23.13223269,  20.48695756,  19.05684612,  24.81353912,\n",
      "        32.07915975,  24.2053383 ,  20.44653167,  19.97016802,\n",
      "        17.34540155,  31.22694707,  37.03838759,  26.3225838 ,\n",
      "        31.35001544,  48.24119707,  54.06493159, -23.12935478])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 10.22413696,  11.96761474,  15.20830462,  12.09216166,\n",
      "        27.45549888,  34.60841127,  17.84155919,  17.03987712,\n",
      "        16.77075776,  23.13223269,  20.48695756,  19.05684612,\n",
      "        24.81353912,  32.07915975,  24.2053383 ,  20.44653167,\n",
      "        19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.13409248, -21.18330503, -32.54409172, -39.07752843,\n",
      "       -32.6193292 , -30.3979265 , -35.82502589, -38.39941951,\n",
      "       -40.8587613 , -44.3605501 , -37.51854439, -33.19416132,\n",
      "       -38.89286159, -33.87752766, -30.4497584 , -26.87455689,\n",
      "       -23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366, -19.49839101, -24.38188179])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 19.97016802,  17.34540155,  31.22694707,  37.03838759,\n",
      "        26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.89946758, -38.21277366, -38.09611349, -39.2634198 ,\n",
      "       -38.27880333, -32.69642308, -21.86251436, -31.13409248,\n",
      "       -21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.83358444, -16.58157204, -19.19608332, -28.02062634,\n",
      "       -15.73223387, -12.76621762, -14.09199302, -23.06607258,\n",
      "       -27.12225277, -23.51686458, -29.27809746, -26.5205597 ,\n",
      "       -27.55894507, -29.59322765, -32.06700723, -18.82476274,\n",
      "       -17.01115558, -27.89690405, -23.90593835, -30.76415026,\n",
      "       -31.92433778, -43.31385151, -53.12329577, -48.01518719,\n",
      "       -39.14163662, -36.84869924, -38.46987092, -41.01124055,\n",
      "       -51.04220562, -55.78628484])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.84174217, -46.53193091, -42.1385738 , -55.35669582,\n",
      "       -54.55357809, -53.69160883, -58.37035013, -53.46104984,\n",
      "       -44.8335132 , -39.51598547, -47.70648874, -53.32808099,\n",
      "       -51.19783676, -45.09986945, -49.79186939, -54.51002167,\n",
      "       -62.63956677, -71.58715818, -64.8448447 , -53.1190795 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548, -67.21634117, -71.38228486,\n",
      "       -85.07712696, -95.24742212, -91.30069548, -84.87992198])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548, -67.21634117, -71.38228486,\n",
      "       -85.07712696, -95.24742212, -91.30069548, -84.87992198,\n",
      "       -89.17023791, -84.49174081, -92.82438722, -94.0739295 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 20.48695756,  19.05684612,  24.81353912,  32.07915975,\n",
      "        24.2053383 ,  20.44653167,  19.97016802,  17.34540155,\n",
      "        31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-15.33936452, -18.78325366, -19.49839101, -24.38188179,\n",
      "       -26.23653412, -28.83948176, -30.78330987, -28.28532672,\n",
      "       -35.21828535, -24.04853364, -30.04320969, -43.68344864,\n",
      "       -35.97944258, -28.73898249, -27.069698  , -25.53018059,\n",
      "       -28.35541819, -37.40919149, -38.84519845, -42.74785086])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267, -54.84779331, -53.02627976,\n",
      "       -55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013, -43.02577216, -45.71710015,\n",
      "       -51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -59.21544083,  -54.28294391,  -62.12156779,  -63.33533342,\n",
      "        -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117, -71.38228486, -85.07712696])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548,\n",
      "       -67.21634117, -71.38228486, -85.07712696, -95.24742212,\n",
      "       -91.30069548, -84.87992198, -89.17023791, -84.49174081])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117, -71.38228486, -85.07712696,\n",
      "       -95.24742212, -91.30069548, -84.87992198, -89.17023791])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.4540148 , -33.84324657, -41.5256601 , -35.89039793,\n",
      "       -32.31698343, -40.40103391, -37.51279054, -33.89946758,\n",
      "       -38.21277366, -38.09611349, -39.2634198 , -38.27880333,\n",
      "       -32.69642308, -21.86251436, -31.13409248, -21.18330503,\n",
      "       -32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.87262907, -31.91710917, -38.47058793, -33.20703003,\n",
      "       -28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -54.08871692,  -56.00071842,  -62.1448811 ,  -65.90353698,\n",
      "        -59.21544083,  -54.28294391,  -62.12156779,  -63.33533342,\n",
      "        -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -63.33533342,  -57.1916876 ,  -68.78889142,  -67.79769699,\n",
      "        -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.597541  , -16.56780841, -17.88060635, -20.83358444,\n",
      "       -16.58157204, -19.19608332, -28.02062634, -15.73223387,\n",
      "       -12.76621762, -14.09199302, -23.06607258, -27.12225277,\n",
      "       -23.51686458, -29.27809746, -26.5205597 , -27.55894507,\n",
      "       -29.59322765, -32.06700723, -18.82476274, -17.01115558,\n",
      "       -27.89690405, -23.90593835, -30.76415026, -31.92433778,\n",
      "       -43.31385151, -53.12329577, -48.01518719, -39.14163662,\n",
      "       -36.84869924, -38.46987092])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.01124055, -51.04220562, -55.78628484, -55.84174217,\n",
      "       -46.53193091, -42.1385738 , -55.35669582, -54.55357809,\n",
      "       -53.69160883, -58.37035013, -53.46104984, -44.8335132 ,\n",
      "       -39.51598547, -47.70648874, -53.32808099, -51.19783676,\n",
      "       -45.09986945, -49.79186939, -54.51002167, -62.63956677])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -59.21544083,  -54.28294391,  -62.12156779,  -63.33533342,\n",
      "        -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-67.43801966, -68.35270157, -82.04093824, -84.80819467,\n",
      "       -78.69033684, -67.54763889, -70.92535333, -79.60688356,\n",
      "       -82.93722056, -75.6151789 , -72.05329685, -77.26219484,\n",
      "       -75.17905918, -73.9672208 , -68.97457988, -74.41286548,\n",
      "       -79.61992177, -82.00557186, -91.59249844, -89.15433706,\n",
      "       -83.9011135 , -83.33124763, -84.79350202, -93.87733144,\n",
      "       -96.03141701, -94.65602659, -97.58086949, -96.42928854,\n",
      "       -90.38647819, -75.59036149])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-73.5081707 , -75.18334068, -76.74951483, -90.76704699,\n",
      "       -91.73993674, -87.36744379, -69.81462362, -69.94992041,\n",
      "       -72.95703905, -74.01945992, -83.34690084, -76.73421685,\n",
      "       -69.53599301, -66.41834844, -74.6054292 , -68.217067  ,\n",
      "       -76.55679624, -76.40372561, -59.82984212, -67.35384456])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.76270293, -15.33936452, -18.78325366, -19.49839101,\n",
      "       -24.38188179, -26.23653412, -28.83948176, -30.78330987,\n",
      "       -28.28532672, -35.21828535, -24.04853364, -30.04320969,\n",
      "       -43.68344864, -35.97944258, -28.73898249, -27.069698  ,\n",
      "       -25.53018059, -28.35541819, -37.40919149, -38.84519845,\n",
      "       -42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -55.60035949,  -54.08871692,  -56.00071842,  -62.1448811 ,\n",
      "        -65.90353698,  -59.21544083,  -54.28294391,  -62.12156779,\n",
      "        -63.33533342,  -57.1916876 ,  -68.78889142,  -67.79769699,\n",
      "        -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934, -60.9254664 , -48.45111915,\n",
      "       -47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ,\n",
      "       -33.84324657, -41.5256601 , -35.89039793, -32.31698343,\n",
      "       -40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.18330503, -32.54409172, -39.07752843, -32.6193292 ,\n",
      "       -30.3979265 , -35.82502589, -38.39941951, -40.8587613 ,\n",
      "       -44.3605501 , -37.51854439, -33.19416132, -38.89286159,\n",
      "       -33.87752766, -30.4497584 , -26.87455689, -23.87262907,\n",
      "       -31.91710917, -38.47058793, -33.20703003, -28.3880031 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646,\n",
      "       -39.45023454, -41.6093651 , -48.602559  , -49.27693921,\n",
      "       -49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -63.33533342,  -57.1916876 ,  -68.78889142,  -67.79769699,\n",
      "        -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 , -30.28747406, -31.64097778,\n",
      "       -24.20094644, -29.14270043, -29.43103609, -31.07422697,\n",
      "       -34.79360621, -28.32274363, -23.10125036, -20.76270293,\n",
      "       -15.33936452, -18.78325366])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -62.12156779,  -63.33533342,  -57.1916876 ,  -68.78889142,\n",
      "        -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117,\n",
      "       -71.38228486, -85.07712696, -95.24742212, -91.30069548])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117,\n",
      "       -71.38228486, -85.07712696, -95.24742212, -91.30069548,\n",
      "       -84.87992198, -89.17023791, -84.49174081, -92.82438722])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845, -42.74785086, -37.07992409,\n",
      "       -36.87624589, -44.54875271, -47.16187013, -43.02577216,\n",
      "       -45.71710015, -51.76266284, -48.92333837, -44.90934984,\n",
      "       -47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-49.23777458, -46.6197508 , -51.01234398, -47.90662164,\n",
      "       -35.61559793, -36.62026087, -37.39793702, -33.65829497,\n",
      "       -38.03920528, -39.27023782, -39.66014711, -40.40661814,\n",
      "       -46.46028405, -47.39243052, -43.01051215, -33.38768891,\n",
      "       -28.07213065, -17.56337419, -26.23666663, -27.69435434])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117,\n",
      "       -71.38228486, -85.07712696, -95.24742212, -91.30069548,\n",
      "       -84.87992198, -89.17023791, -84.49174081, -92.82438722,\n",
      "       -94.0739295 , -98.26183131])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -53.58290387,  -57.37501157,  -55.60035949,  -54.08871692,\n",
      "        -56.00071842,  -62.1448811 ,  -65.90353698,  -59.21544083,\n",
      "        -54.28294391,  -62.12156779,  -63.33533342,  -57.1916876 ,\n",
      "        -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-26.29957481, -25.91729805, -21.83523093, -17.86154858,\n",
      "       -19.38442869, -26.01227339, -36.0666894 , -37.01401294,\n",
      "       -26.77293814, -21.89853901, -29.68458137, -27.67355936,\n",
      "       -20.91415141, -24.88158385, -22.96991088, -19.05401836,\n",
      "       -24.8845942 , -20.99511075, -12.94546845,  -4.10066211,\n",
      "         3.58724588,  -6.67613226, -15.15874378,  -8.98634392,\n",
      "        -2.30145415,   1.74950479,  27.3567797 ,  31.13897622,\n",
      "        30.07589012,  32.54861768])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([31.87835152, 24.90212536, 25.55156357, 18.6136465 , 13.4551445 ,\n",
      "       10.181703  , 10.52495473, 26.80256559, 14.89549679, 14.2120442 ,\n",
      "        6.60137577,  2.23218413, 13.22627403, 16.39113981,  8.46271719,\n",
      "        4.14273222, 11.75100712, 10.22413696, 11.96761474, 15.20830462])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.01051215, -33.38768891, -28.07213065, -17.56337419,\n",
      "       -26.23666663, -27.69435434, -28.06387242, -17.81686205,\n",
      "       -25.90797694, -38.95825618, -44.77153165, -59.27039873,\n",
      "       -62.82287848, -63.46415926, -60.04779591, -54.54238238,\n",
      "       -40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548, -67.21634117, -71.38228486,\n",
      "       -85.07712696, -95.24742212])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548,\n",
      "       -67.21634117, -71.38228486, -85.07712696, -95.24742212])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548,\n",
      "       -67.21634117, -71.38228486, -85.07712696, -95.24742212,\n",
      "       -91.30069548, -84.87992198, -89.17023791, -84.49174081,\n",
      "       -92.82438722, -94.0739295 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381, -45.18113249, -58.12165896,\n",
      "       -70.49083278, -70.63950934])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548,\n",
      "       -67.21634117, -71.38228486])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 31.22694707,  37.03838759,  26.3225838 ,  31.35001544,\n",
      "        48.24119707,  54.06493159, -23.12935478, -31.08379428,\n",
      "       -21.79316183, -26.11448851, -26.60234425, -21.11952555,\n",
      "       -28.77036928, -31.92780838, -52.57262215, -59.94663704,\n",
      "       -54.39197114, -57.87783181, -43.84103585, -47.763687  ,\n",
      "       -51.69679116, -46.4540148 , -33.84324657, -41.5256601 ,\n",
      "       -35.89039793, -32.31698343, -40.40103391, -37.51279054,\n",
      "       -33.89946758, -38.21277366])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -54.28294391,  -62.12156779,  -63.33533342,  -57.1916876 ,\n",
      "        -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059, -28.35541819, -37.40919149,\n",
      "       -38.84519845, -42.74785086, -37.07992409, -36.87624589,\n",
      "       -44.54875271, -47.16187013])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.91710917, -38.47058793, -33.20703003, -28.3880031 ,\n",
      "       -30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364,\n",
      "       -30.04320969, -43.68344864, -35.97944258, -28.73898249,\n",
      "       -27.069698  , -25.53018059])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.35541819, -37.40919149, -38.84519845, -42.74785086,\n",
      "       -37.07992409, -36.87624589, -44.54875271, -47.16187013,\n",
      "       -43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117,\n",
      "       -71.38228486, -85.07712696])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.3880031 , -30.28747406, -31.64097778, -24.20094644,\n",
      "       -29.14270043, -29.43103609, -31.07422697, -34.79360621,\n",
      "       -28.32274363, -23.10125036, -20.76270293, -15.33936452,\n",
      "       -18.78325366, -19.49839101, -24.38188179, -26.23653412,\n",
      "       -28.83948176, -30.78330987, -28.28532672, -35.21828535,\n",
      "       -24.04853364, -30.04320969, -43.68344864, -35.97944258,\n",
      "       -28.73898249, -27.069698  , -25.53018059, -28.35541819,\n",
      "       -37.40919149, -38.84519845])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-42.74785086, -37.07992409, -36.87624589, -44.54875271,\n",
      "       -47.16187013, -43.02577216, -45.71710015, -51.76266284,\n",
      "       -48.92333837, -44.90934984, -47.81268096, -50.97484316,\n",
      "       -48.04210726, -55.90322868, -65.08798087, -66.12832317,\n",
      "       -62.77003226, -56.66040893, -43.84223914, -36.53049646])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548, -67.21634117, -71.38228486,\n",
      "       -85.07712696, -95.24742212, -91.30069548, -84.87992198,\n",
      "       -89.17023791, -84.49174081])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531,   0.5782572 ,   5.22926088,\n",
      "        -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.6558729 , -33.65276222, -41.02069418, -50.21334121,\n",
      "       -47.2679263 , -54.67706271, -43.81117962, -33.08278436,\n",
      "       -39.6248105 , -54.71995434, -46.57897458, -44.21442029,\n",
      "       -38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342, -57.1916876 , -68.78889142,\n",
      "       -67.79769699, -69.60917548, -67.21634117, -71.38228486])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -62.12156779,  -63.33533342,  -57.1916876 ,  -68.78889142,\n",
      "        -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117, -71.38228486, -85.07712696,\n",
      "       -95.24742212, -91.30069548])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946, -34.40533543, -44.93134497,\n",
      "       -38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117, -71.38228486, -85.07712696,\n",
      "       -95.24742212, -91.30069548, -84.87992198, -89.17023791,\n",
      "       -84.49174081, -92.82438722, -94.0739295 , -98.26183131])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 11.75100712,  10.22413696,  11.96761474,  15.20830462,\n",
      "        12.09216166,  27.45549888,  34.60841127,  17.84155919,\n",
      "        17.03987712,  16.77075776,  23.13223269,  20.48695756,\n",
      "        19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478, -31.08379428, -21.79316183,\n",
      "       -26.11448851, -26.60234425])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949,\n",
      "       -54.08871692, -56.00071842, -62.1448811 , -65.90353698,\n",
      "       -59.21544083, -54.28294391, -62.12156779, -63.33533342,\n",
      "       -57.1916876 , -68.78889142, -67.79769699, -69.60917548,\n",
      "       -67.21634117, -71.38228486, -85.07712696, -95.24742212,\n",
      "       -91.30069548, -84.87992198])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.08092535, -56.74664446, -58.70174154, -55.47945877,\n",
      "       -50.92793592, -45.69665265, -53.79388325, -65.80872704,\n",
      "       -55.52265629, -49.20368683, -55.59560719, -46.0044349 ,\n",
      "       -43.45226521, -38.80092872, -39.40013794, -29.36559089,\n",
      "       -19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.80716297, -39.78770894, -49.56079929, -65.43325541,\n",
      "         3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -48.85675414,  -54.51849708,  -53.58290387,  -57.37501157,\n",
      "        -55.60035949,  -54.08871692,  -56.00071842,  -62.1448811 ,\n",
      "        -65.90353698,  -59.21544083,  -54.28294391,  -62.12156779,\n",
      "        -63.33533342,  -57.1916876 ,  -68.78889142,  -67.79769699,\n",
      "        -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387,\n",
      "       -57.37501157, -55.60035949, -54.08871692, -56.00071842,\n",
      "       -62.1448811 , -65.90353698, -59.21544083, -54.28294391,\n",
      "       -62.12156779, -63.33533342])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 , -14.65412608, -14.89898574,\n",
      "       -18.51630509, -29.35671154, -33.09912348, -37.46923045,\n",
      "       -24.33439739, -14.99583548, -17.62586095, -10.44703695,\n",
      "       -11.14530563, -21.67818278, -14.41146859, -11.01238107,\n",
      "       -22.85847664, -28.16956946])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271,\n",
      "       -43.81117962, -33.08278436, -39.6248105 , -54.71995434,\n",
      "       -46.57897458, -44.21442029, -38.6876848 , -49.54893991,\n",
      "       -57.11357267, -54.84779331, -53.02627976, -55.465938  ,\n",
      "       -51.08092535, -56.74664446])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391,\n",
      "       -37.51279054, -33.89946758, -38.21277366, -38.09611349,\n",
      "       -39.2634198 , -38.27880333, -32.69642308, -21.86251436,\n",
      "       -31.13409248, -21.18330503])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.54409172, -39.07752843, -32.6193292 , -30.3979265 ,\n",
      "       -35.82502589, -38.39941951, -40.8587613 , -44.3605501 ,\n",
      "       -37.51854439, -33.19416132, -38.89286159, -33.87752766,\n",
      "       -30.4497584 , -26.87455689, -23.87262907, -31.91710917,\n",
      "       -38.47058793, -33.20703003, -28.3880031 , -30.28747406])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ,\n",
      "       -14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-51.76266284, -48.92333837, -44.90934984, -47.81268096,\n",
      "       -50.97484316, -48.04210726, -55.90322868, -65.08798087,\n",
      "       -66.12832317, -62.77003226, -56.66040893, -43.84223914,\n",
      "       -36.53049646, -39.45023454, -41.6093651 , -48.602559  ,\n",
      "       -49.27693921, -49.23777458, -46.6197508 , -51.01234398,\n",
      "       -47.90662164, -35.61559793, -36.62026087, -37.39793702,\n",
      "       -33.65829497, -38.03920528, -39.27023782, -39.66014711,\n",
      "       -40.40661814, -46.46028405])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875,\n",
      "       -27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-29.36559089, -19.34332875, -27.08150445, -27.67970613,\n",
      "       -26.51331433, -22.57067968, -33.51500603, -35.4411814 ,\n",
      "       -29.78757381, -45.18113249, -58.12165896, -70.49083278,\n",
      "       -70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -54.51849708,  -53.58290387,  -57.37501157,  -55.60035949,\n",
      "        -54.08871692,  -56.00071842,  -62.1448811 ,  -65.90353698,\n",
      "        -59.21544083,  -54.28294391,  -62.12156779,  -63.33533342,\n",
      "        -57.1916876 ,  -68.78889142,  -67.79769699,  -69.60917548,\n",
      "        -67.21634117,  -71.38228486,  -85.07712696,  -95.24742212,\n",
      "        -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488,   0.50183483,   2.88721421,\n",
      "         2.00275384,  -3.58885226,  -2.92916911,  -7.44759695,\n",
      "       -10.05522455, -14.90553531])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739,\n",
      "       -14.99583548, -17.62586095])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-10.44703695, -11.14530563, -21.67818278, -14.41146859,\n",
      "       -11.01238107, -22.85847664, -28.16956946, -34.40533543,\n",
      "       -44.93134497, -38.37470089, -23.10237615, -34.03695882,\n",
      "       -35.71558055, -39.1068809 , -44.81374489, -48.85675414,\n",
      "       -54.51849708, -53.58290387, -57.37501157, -55.60035949])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-70.63950934, -60.9254664 , -48.45111915, -47.80716297,\n",
      "       -39.78770894, -49.56079929, -65.43325541,   3.78591522,\n",
      "         9.90558189,  10.86293222,  -2.93567923,  -3.40104466,\n",
      "        -7.00425836,  -0.72673561,   6.29226408,   0.70467075,\n",
      "        -2.52686044,  -6.85015588,  -5.0551342 ,   4.99640488,\n",
      "         0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -2.04980069,  -0.93614931,  -0.29967987,  -2.08760684,\n",
      "         2.05148563,   7.46001859,   2.45016043,  -3.97926603,\n",
      "        -6.03480611, -20.85070636, -30.92716376, -16.93006873,\n",
      "        -0.85368511,  -3.27830389,  -2.81881203,  -1.20381649,\n",
      "        16.99724166,  22.65474028,  13.1313578 ,   0.1638875 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095,\n",
      "       -10.44703695, -11.14530563, -21.67818278, -14.41146859])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 13.22627403,  16.39113981,   8.46271719,   4.14273222,\n",
      "        11.75100712,  10.22413696,  11.96761474,  15.20830462,\n",
      "        12.09216166,  27.45549888,  34.60841127,  17.84155919,\n",
      "        17.03987712,  16.77075776,  23.13223269,  20.48695756,\n",
      "        19.05684612,  24.81353912,  32.07915975,  24.2053383 ,\n",
      "        20.44653167,  19.97016802,  17.34540155,  31.22694707,\n",
      "        37.03838759,  26.3225838 ,  31.35001544,  48.24119707,\n",
      "        54.06493159, -23.12935478])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-31.08379428, -21.79316183, -26.11448851, -26.60234425,\n",
      "       -21.11952555, -28.77036928, -31.92780838, -52.57262215,\n",
      "       -59.94663704, -54.39197114, -57.87783181, -43.84103585,\n",
      "       -47.763687  , -51.69679116, -46.4540148 , -33.84324657,\n",
      "       -41.5256601 , -35.89039793, -32.31698343, -40.40103391])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -44.81374489,  -48.85675414,  -54.51849708,  -53.58290387,\n",
      "        -57.37501157,  -55.60035949,  -54.08871692,  -56.00071842,\n",
      "        -62.1448811 ,  -65.90353698,  -59.21544083,  -54.28294391,\n",
      "        -62.12156779,  -63.33533342,  -57.1916876 ,  -68.78889142,\n",
      "        -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334,\n",
      "        -83.99473886,  -75.88680929,  -78.21148248,  -88.64399073])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-83.41650142, -88.96061067, -86.6991432 , -80.06104528,\n",
      "       -82.31658328, -80.92018304, -88.17964354, -82.28680729,\n",
      "       -79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.33153445, -123.79453514, -120.04980249, -124.40751793,\n",
      "       -120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.81268096, -50.97484316, -48.04210726, -55.90322868,\n",
      "       -65.08798087, -66.12832317, -62.77003226, -56.66040893,\n",
      "       -43.84223914, -36.53049646, -39.45023454, -41.6093651 ,\n",
      "       -48.602559  , -49.27693921, -49.23777458, -46.6197508 ,\n",
      "       -51.01234398, -47.90662164, -35.61559793, -36.62026087,\n",
      "       -37.39793702, -33.65829497, -38.03920528, -39.27023782,\n",
      "       -39.66014711, -40.40661814, -46.46028405, -47.39243052,\n",
      "       -43.01051215, -33.38768891])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-28.07213065, -17.56337419, -26.23666663, -27.69435434,\n",
      "       -28.06387242, -17.81686205, -25.90797694, -38.95825618,\n",
      "       -44.77153165, -59.27039873, -62.82287848, -63.46415926,\n",
      "       -60.04779591, -54.54238238, -40.6558729 , -33.65276222,\n",
      "       -41.02069418, -50.21334121, -47.2679263 , -54.67706271])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  3.78591522,   9.90558189,  10.86293222,  -2.93567923,\n",
      "        -3.40104466,  -7.00425836,  -0.72673561,   6.29226408,\n",
      "         0.70467075,  -2.52686044,  -6.85015588,  -5.0551342 ,\n",
      "         4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -3.97926603,  -6.03480611, -20.85070636, -30.92716376,\n",
      "       -16.93006873,  -0.85368511,  -3.27830389,  -2.81881203,\n",
      "        -1.20381649,  16.99724166,  22.65474028,  13.1313578 ,\n",
      "         0.1638875 , -14.65412608, -14.89898574, -18.51630509,\n",
      "       -29.35671154, -33.09912348, -37.46923045, -24.33439739])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.33742743,  -98.58009557,  -93.92766603, -101.83772101,\n",
      "        -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-12.94546845,  -4.10066211,   3.58724588,  -6.67613226,\n",
      "       -15.15874378,  -8.98634392,  -2.30145415,   1.74950479,\n",
      "        27.3567797 ,  31.13897622,  30.07589012,  32.54861768,\n",
      "        31.87835152,  24.90212536,  25.55156357,  18.6136465 ,\n",
      "        13.4551445 ,  10.181703  ,  10.52495473,  26.80256559,\n",
      "        14.89549679,  14.2120442 ,   6.60137577,   2.23218413,\n",
      "        13.22627403,  16.39113981,   8.46271719,   4.14273222,\n",
      "        11.75100712,  10.22413696])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([11.96761474, 15.20830462, 12.09216166, 27.45549888, 34.60841127,\n",
      "       17.84155919, 17.03987712, 16.77075776, 23.13223269, 20.48695756,\n",
      "       19.05684612, 24.81353912, 32.07915975, 24.2053383 , 20.44653167,\n",
      "       19.97016802, 17.34540155, 31.22694707, 37.03838759, 26.3225838 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334,\n",
      "        -83.99473886,  -75.88680929,  -78.21148248,  -88.64399073,\n",
      "        -96.94040946,  -88.58944292])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611,\n",
      "       -20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-14.99583548, -17.62586095, -10.44703695, -11.14530563,\n",
      "       -21.67818278, -14.41146859, -11.01238107, -22.85847664,\n",
      "       -28.16956946, -34.40533543, -44.93134497, -38.37470089,\n",
      "       -23.10237615, -34.03695882, -35.71558055, -39.1068809 ,\n",
      "       -44.81374489, -48.85675414, -54.51849708, -53.58290387])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-17.56337419, -26.23666663, -27.69435434, -28.06387242,\n",
      "       -17.81686205, -25.90797694, -38.95825618, -44.77153165,\n",
      "       -59.27039873, -62.82287848, -63.46415926, -60.04779591,\n",
      "       -54.54238238, -40.6558729 , -33.65276222, -41.02069418,\n",
      "       -50.21334121, -47.2679263 , -54.67706271, -43.81117962,\n",
      "       -33.08278436, -39.6248105 , -54.71995434, -46.57897458,\n",
      "       -44.21442029, -38.6876848 , -49.54893991, -57.11357267,\n",
      "       -54.84779331, -53.02627976])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.465938  , -51.08092535, -56.74664446, -58.70174154,\n",
      "       -55.47945877, -50.92793592, -45.69665265, -53.79388325,\n",
      "       -65.80872704, -55.52265629, -49.20368683, -55.59560719,\n",
      "       -46.0044349 , -43.45226521, -38.80092872, -39.40013794,\n",
      "       -29.36559089, -19.34332875, -27.08150445, -27.67970613])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-80.06104528, -82.31658328, -80.92018304, -88.17964354,\n",
      "       -82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248,\n",
      "        -88.64399073,  -96.94040946,  -88.58944292,  -91.01452335,\n",
      "        -77.58356387,  -85.71916208,  -75.59568258,  -67.71143355,\n",
      "        -69.27263486,  -72.10504442,  -68.22832895,  -66.01308384,\n",
      "        -58.08180923,  -55.9762909 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.02577216, -45.71710015, -51.76266284, -48.92333837,\n",
      "       -44.90934984, -47.81268096, -50.97484316, -48.04210726,\n",
      "       -55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.40661814, -46.46028405, -47.39243052, -43.01051215,\n",
      "       -33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929,\n",
      "        -78.21148248,  -88.64399073])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929,\n",
      "        -78.21148248,  -88.64399073,  -96.94040946,  -88.58944292,\n",
      "        -91.01452335,  -77.58356387])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277,  -83.74085993, -101.2500878 ,\n",
      "       -110.9058207 , -103.35499144, -102.59232199, -100.94954263,\n",
      "       -104.67163394, -105.29081196, -105.62399864,  -98.42781302,\n",
      "        -96.79147826,  -97.8009911 , -102.68785185, -108.47661262,\n",
      "       -112.31184448, -110.00129287])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886,\n",
      "        -75.88680929,  -78.21148248,  -88.64399073,  -96.94040946,\n",
      "        -88.58944292,  -91.01452335])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.6876848 , -49.54893991, -57.11357267, -54.84779331,\n",
      "       -53.02627976, -55.465938  , -51.08092535, -56.74664446,\n",
      "       -58.70174154, -55.47945877, -50.92793592, -45.69665265,\n",
      "       -53.79388325, -65.80872704, -55.52265629, -49.20368683,\n",
      "       -55.59560719, -46.0044349 , -43.45226521, -38.80092872,\n",
      "       -39.40013794, -29.36559089, -19.34332875, -27.08150445,\n",
      "       -27.67970613, -26.51331433, -22.57067968, -33.51500603,\n",
      "       -35.4411814 , -29.78757381])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.40103391, -37.51279054, -33.89946758, -38.21277366,\n",
      "       -38.09611349, -39.2634198 , -38.27880333, -32.69642308,\n",
      "       -21.86251436, -31.13409248, -21.18330503, -32.54409172,\n",
      "       -39.07752843, -32.6193292 , -30.3979265 , -35.82502589,\n",
      "       -38.39941951, -40.8587613 , -44.3605501 , -37.51854439,\n",
      "       -33.19416132, -38.89286159, -33.87752766, -30.4497584 ,\n",
      "       -26.87455689, -23.87262907, -31.91710917, -38.47058793,\n",
      "       -33.20703003, -28.3880031 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-30.28747406, -31.64097778, -24.20094644, -29.14270043,\n",
      "       -29.43103609, -31.07422697, -34.79360621, -28.32274363,\n",
      "       -23.10125036, -20.76270293, -15.33936452, -18.78325366,\n",
      "       -19.49839101, -24.38188179, -26.23653412, -28.83948176,\n",
      "       -30.78330987, -28.28532672, -35.21828535, -24.04853364])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929,\n",
      "        -78.21148248,  -88.64399073,  -96.94040946,  -88.58944292,\n",
      "        -91.01452335,  -77.58356387,  -85.71916208,  -75.59568258,\n",
      "        -67.71143355,  -69.27263486,  -72.10504442,  -68.22832895,\n",
      "        -66.01308384,  -58.08180923])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101,  -98.63623694, -103.50943296,\n",
      "       -122.29518075, -131.37125041, -141.47815813, -142.09928023,\n",
      "       -137.33153445, -123.79453514, -120.04980249, -124.40751793])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-93.91332411, -88.62087539, -90.98476108, -83.41650142,\n",
      "       -88.96061067, -86.6991432 , -80.06104528, -82.31658328,\n",
      "       -80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-82.31658328, -80.92018304, -88.17964354, -82.28680729,\n",
      "       -79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-120.4174866 , -135.45531333, -136.87163569, -127.99757245,\n",
      "       -137.77564821, -132.10880561, -126.9691448 , -131.86224812,\n",
      "       -129.15683171, -113.98540129, -114.53371405, -119.25651751,\n",
      "       -125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-129.2979114 , -120.53126801, -127.97864511, -142.34991916,\n",
      "       -155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-86.6991432 , -80.06104528, -82.31658328, -80.92018304,\n",
      "       -88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 , -80.16707854, -80.39458443])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615,\n",
      "       -34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -54.28294391,  -62.12156779,  -63.33533342,  -57.1916876 ,\n",
      "        -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929,\n",
      "        -78.21148248,  -88.64399073,  -96.94040946,  -88.58944292])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-86.6991432 , -80.06104528, -82.31658328, -80.92018304,\n",
      "       -88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([  0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636,\n",
      "       -30.92716376, -16.93006873,  -0.85368511,  -3.27830389,\n",
      "        -2.81881203,  -1.20381649,  16.99724166,  22.65474028,\n",
      "        13.1313578 ,   0.1638875 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-14.65412608, -14.89898574, -18.51630509, -29.35671154,\n",
      "       -33.09912348, -37.46923045, -24.33439739, -14.99583548,\n",
      "       -17.62586095, -10.44703695, -11.14530563, -21.67818278,\n",
      "       -14.41146859, -11.01238107, -22.85847664, -28.16956946,\n",
      "       -34.40533543, -44.93134497, -38.37470089, -23.10237615])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-34.03695882, -35.71558055, -39.1068809 , -44.81374489,\n",
      "       -48.85675414, -54.51849708, -53.58290387, -57.37501157,\n",
      "       -55.60035949, -54.08871692, -56.00071842, -62.1448811 ,\n",
      "       -65.90353698, -59.21544083, -54.28294391, -62.12156779,\n",
      "       -63.33533342, -57.1916876 , -68.78889142, -67.79769699,\n",
      "       -69.60917548, -67.21634117, -71.38228486, -85.07712696,\n",
      "       -95.24742212, -91.30069548, -84.87992198, -89.17023791,\n",
      "       -84.49174081, -92.82438722])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153,  -95.09701277,  -83.74085993,\n",
      "       -101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886,\n",
      "        -75.88680929,  -78.21148248,  -88.64399073,  -96.94040946,\n",
      "        -88.58944292,  -91.01452335,  -77.58356387,  -85.71916208,\n",
      "        -75.59568258,  -67.71143355,  -69.27263486,  -72.10504442,\n",
      "        -68.22832895,  -66.01308384])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.52707944, -116.99462932, -111.43554862, -119.87535554,\n",
      "       -132.95830363, -136.15981113, -135.80875716, -129.27202565,\n",
      "       -141.13921427, -134.25915854, -132.36753554, -138.32127511,\n",
      "       -145.4674055 , -155.94138515, -148.1744804 , -142.67880484,\n",
      "       -150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -56.00071842,  -62.1448811 ,  -65.90353698,  -59.21544083,\n",
      "        -54.28294391,  -62.12156779,  -63.33533342,  -57.1916876 ,\n",
      "        -68.78889142,  -67.79769699,  -69.60917548,  -67.21634117,\n",
      "        -71.38228486,  -85.07712696,  -95.24742212,  -91.30069548,\n",
      "        -84.87992198,  -89.17023791,  -84.49174081,  -92.82438722,\n",
      "        -94.0739295 ,  -98.26183131, -101.50432175,  -97.75337168,\n",
      "       -100.63389467, -102.05984445,  -92.61575456,  -94.31047046,\n",
      "        -90.22673921,  -96.53003153])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603,\n",
      "       -101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -65.90353698,  -59.21544083,  -54.28294391,  -62.12156779,\n",
      "        -63.33533342,  -57.1916876 ,  -68.78889142,  -67.79769699,\n",
      "        -69.60917548,  -67.21634117,  -71.38228486,  -85.07712696,\n",
      "        -95.24742212,  -91.30069548,  -84.87992198,  -89.17023791,\n",
      "        -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.2500878 , -110.9058207 , -103.35499144, -102.59232199,\n",
      "       -100.94954263, -104.67163394, -105.29081196, -105.62399864,\n",
      "        -98.42781302,  -96.79147826,  -97.8009911 , -102.68785185,\n",
      "       -108.47661262, -112.31184448, -110.00129287, -112.67157991,\n",
      "       -112.33742743,  -98.58009557,  -93.92766603, -101.83772101])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296, -70.8054965 , -80.16707854,\n",
      "       -80.39458443, -75.35100815, -74.44415654, -89.09814678,\n",
      "       -98.0311741 , -98.61419852, -98.24416983, -93.6538132 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.31658328, -80.92018304, -88.17964354, -82.28680729,\n",
      "       -79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 , -80.16707854, -80.39458443,\n",
      "       -75.35100815, -74.44415654])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248,\n",
      "        -88.64399073,  -96.94040946,  -88.58944292,  -91.01452335,\n",
      "        -77.58356387,  -85.71916208,  -75.59568258,  -67.71143355,\n",
      "        -69.27263486,  -72.10504442])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.62087539, -90.98476108, -83.41650142, -88.96061067,\n",
      "       -86.6991432 , -80.06104528, -82.31658328, -80.92018304,\n",
      "       -88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.96061067, -86.6991432 , -80.06104528, -82.31658328,\n",
      "       -80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -50.72745374,  -32.00303527,  -23.85200895,  -25.99904734,\n",
      "        -32.67204206,  -91.08540087,  -93.58291408,  -94.442178  ,\n",
      "        -76.67566442,  -77.31861056,  -75.85961461,  -82.38460297,\n",
      "        -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296,\n",
      "       -70.8054965 , -80.16707854])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.90322868, -65.08798087, -66.12832317, -62.77003226,\n",
      "       -56.66040893, -43.84223914, -36.53049646, -39.45023454,\n",
      "       -41.6093651 , -48.602559  , -49.27693921, -49.23777458,\n",
      "       -46.6197508 , -51.01234398, -47.90662164, -35.61559793,\n",
      "       -36.62026087, -37.39793702, -33.65829497, -38.03920528,\n",
      "       -39.27023782, -39.66014711, -40.40661814, -46.46028405,\n",
      "       -47.39243052, -43.01051215, -33.38768891, -28.07213065,\n",
      "       -17.56337419, -26.23666663])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ,\n",
      "       -80.16707854, -80.39458443])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -23.85200895,  -25.99904734,  -32.67204206,  -91.08540087,\n",
      "        -93.58291408,  -94.442178  ,  -76.67566442,  -77.31861056,\n",
      "        -75.85961461,  -82.38460297,  -87.15021022,  -76.16122644,\n",
      "        -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ,\n",
      "       -80.16707854, -80.39458443, -75.35100815, -74.44415654,\n",
      "       -89.09814678, -98.0311741 , -98.61419852, -98.24416983])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886,\n",
      "        -75.88680929,  -78.21148248])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -77.31861056,  -75.85961461,  -82.38460297,  -87.15021022,\n",
      "        -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.83772101,  -98.63623694, -103.50943296, -122.29518075,\n",
      "       -131.37125041, -141.47815813, -142.09928023, -137.33153445,\n",
      "       -123.79453514, -120.04980249, -124.40751793, -120.4174866 ,\n",
      "       -135.45531333, -136.87163569, -127.99757245, -137.77564821,\n",
      "       -132.10880561, -126.9691448 , -131.86224812, -129.15683171,\n",
      "       -113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296,\n",
      "       -70.8054965 , -80.16707854, -80.39458443, -75.35100815])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 , -80.16707854, -80.39458443,\n",
      "       -75.35100815, -74.44415654, -89.09814678, -98.0311741 ,\n",
      "       -98.61419852, -98.24416983])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-38.37470089, -23.10237615, -34.03695882, -35.71558055,\n",
      "       -39.1068809 , -44.81374489, -48.85675414, -54.51849708,\n",
      "       -53.58290387, -57.37501157, -55.60035949, -54.08871692,\n",
      "       -56.00071842, -62.1448811 , -65.90353698, -59.21544083,\n",
      "       -54.28294391, -62.12156779, -63.33533342, -57.1916876 ,\n",
      "       -68.78889142, -67.79769699, -69.60917548, -67.21634117,\n",
      "       -71.38228486, -85.07712696, -95.24742212, -91.30069548,\n",
      "       -84.87992198, -89.17023791])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.49174081,  -92.82438722,  -94.0739295 ,  -98.26183131,\n",
      "       -101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.96061067, -86.6991432 , -80.06104528, -82.31658328,\n",
      "       -80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886,\n",
      "        -75.88680929,  -78.21148248,  -88.64399073,  -96.94040946,\n",
      "        -88.58944292,  -91.01452335,  -77.58356387,  -85.71916208,\n",
      "        -75.59568258,  -67.71143355])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.442178  ,  -76.67566442,  -77.31861056,  -75.85961461,\n",
      "        -82.38460297,  -87.15021022,  -76.16122644,  -81.42824104,\n",
      "        -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -77.31861056,  -75.85961461,  -82.38460297,  -87.15021022,\n",
      "        -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-138.32127511, -145.4674055 , -155.94138515, -148.1744804 ,\n",
      "       -142.67880484, -150.85458764, -158.44759851, -156.67339275,\n",
      "       -140.53271536, -138.40408521, -149.57807405, -149.77749657,\n",
      "       -146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.67566442,  -77.31861056,  -75.85961461,  -82.38460297,\n",
      "        -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248,\n",
      "        -88.64399073,  -96.94040946])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129,\n",
      "       -114.53371405, -119.25651751, -125.51953719, -134.33356531,\n",
      "       -130.22634478, -135.46308188, -137.78070316, -140.2979898 ,\n",
      "       -137.8469443 , -135.00428261, -129.34435275, -133.95427854,\n",
      "       -139.0355469 , -145.91267694, -149.24466127, -145.07136792,\n",
      "       -138.68732465, -145.04957605, -141.07324759, -130.40193536,\n",
      "       -129.2979114 , -120.53126801])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 , -138.34797642, -137.45405663,\n",
      "       -124.52707944, -116.99462932, -111.43554862, -119.87535554])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-155.33313146, -144.4186376 , -136.12484276, -138.79844949,\n",
      "       -138.78281058, -146.84651478, -131.99717195, -128.89717436,\n",
      "       -133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-125.51953719, -134.33356531, -130.22634478, -135.46308188,\n",
      "       -137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-133.51447455, -130.65526379, -129.07056382, -130.4567686 ,\n",
      "       -138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 , -80.16707854, -80.39458443,\n",
      "       -75.35100815, -74.44415654, -89.09814678, -98.0311741 ,\n",
      "       -98.61419852, -98.24416983, -93.6538132 , -92.13003401])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.58291408,  -94.442178  ,  -76.67566442,  -77.31861056,\n",
      "        -75.85961461,  -82.38460297,  -87.15021022,  -76.16122644,\n",
      "        -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -57.37501157,  -55.60035949,  -54.08871692,  -56.00071842,\n",
      "        -62.1448811 ,  -65.90353698,  -59.21544083,  -54.28294391,\n",
      "        -62.12156779,  -63.33533342,  -57.1916876 ,  -68.78889142,\n",
      "        -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -82.38460297,  -87.15021022,  -76.16122644,  -81.42824104,\n",
      "        -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291, -100.35538348,  -98.10173527,\n",
      "       -100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248,\n",
      "        -88.64399073,  -96.94040946,  -88.58944292,  -91.01452335,\n",
      "        -77.58356387,  -85.71916208])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -91.08540087,  -93.58291408,  -94.442178  ,  -76.67566442,\n",
      "        -77.31861056,  -75.85961461,  -82.38460297,  -87.15021022,\n",
      "        -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296,\n",
      "       -70.8054965 , -80.16707854, -80.39458443, -75.35100815,\n",
      "       -74.44415654, -89.09814678, -98.0311741 , -98.61419852])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296, -70.8054965 , -80.16707854,\n",
      "       -80.39458443, -75.35100815])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296, -70.8054965 , -80.16707854])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.38460297,  -87.15021022,  -76.16122644,  -81.42824104,\n",
      "        -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.67566442,  -77.31861056,  -75.85961461,  -82.38460297,\n",
      "        -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -63.65204917,  -50.53126994,  -50.72745374,  -32.00303527,\n",
      "        -23.85200895,  -25.99904734,  -32.67204206,  -91.08540087,\n",
      "        -93.58291408,  -94.442178  ,  -76.67566442,  -77.31861056,\n",
      "        -75.85961461,  -82.38460297,  -87.15021022,  -76.16122644,\n",
      "        -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-80.06104528, -82.31658328, -80.92018304, -88.17964354,\n",
      "       -82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -91.30069548,  -84.87992198,  -89.17023791,  -84.49174081,\n",
      "        -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.31184448, -110.00129287, -112.67157991, -112.33742743,\n",
      "        -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-150.85458764, -158.44759851, -156.67339275, -140.53271536,\n",
      "       -138.40408521, -149.57807405, -149.77749657, -146.93445364,\n",
      "       -161.96197719, -159.78265152, -152.82811348, -144.0131632 ,\n",
      "       -127.61249868, -118.36294649, -122.16191107, -131.73654375,\n",
      "       -114.59089697, -111.26176061, -116.10288173, -117.43808447,\n",
      "       -116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -32.67204206,  -91.08540087,  -93.58291408,  -94.442178  ,\n",
      "        -76.67566442,  -77.31861056,  -75.85961461,  -82.38460297,\n",
      "        -87.15021022,  -76.16122644,  -81.42824104,  -74.78175296,\n",
      "        -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-33.38768891, -28.07213065, -17.56337419, -26.23666663,\n",
      "       -27.69435434, -28.06387242, -17.81686205, -25.90797694,\n",
      "       -38.95825618, -44.77153165, -59.27039873, -62.82287848,\n",
      "       -63.46415926, -60.04779591, -54.54238238, -40.6558729 ,\n",
      "       -33.65276222, -41.02069418, -50.21334121, -47.2679263 ,\n",
      "       -54.67706271, -43.81117962, -33.08278436, -39.6248105 ,\n",
      "       -54.71995434, -46.57897458, -44.21442029, -38.6876848 ,\n",
      "       -49.54893991, -57.11357267])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.84779331, -53.02627976, -55.465938  , -51.08092535,\n",
      "       -56.74664446, -58.70174154, -55.47945877, -50.92793592,\n",
      "       -45.69665265, -53.79388325, -65.80872704, -55.52265629,\n",
      "       -49.20368683, -55.59560719, -46.0044349 , -43.45226521,\n",
      "       -38.80092872, -39.40013794, -29.36559089, -19.34332875])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539,\n",
      "        -90.98476108,  -83.41650142,  -88.96061067,  -86.6991432 ,\n",
      "        -80.06104528,  -82.31658328,  -80.92018304,  -88.17964354,\n",
      "        -82.28680729,  -79.97343334,  -83.99473886,  -75.88680929,\n",
      "        -78.21148248,  -88.64399073,  -96.94040946,  -88.58944292,\n",
      "        -91.01452335,  -77.58356387,  -85.71916208,  -75.59568258,\n",
      "        -67.71143355,  -69.27263486])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104,\n",
      "       -74.78175296, -70.8054965 , -80.16707854, -80.39458443,\n",
      "       -75.35100815, -74.44415654, -89.09814678, -98.0311741 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296,\n",
      "       -70.8054965 , -80.16707854, -80.39458443, -75.35100815,\n",
      "       -74.44415654, -89.09814678, -98.0311741 , -98.61419852,\n",
      "       -98.24416983, -93.6538132 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898,  -93.91332411,  -88.62087539])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334,\n",
      "        -83.99473886,  -75.88680929])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554,\n",
      "       -138.32127511, -145.4674055 , -155.94138515, -148.1744804 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -62.1448811 ,  -65.90353698,  -59.21544083,  -54.28294391,\n",
      "        -62.12156779,  -63.33533342,  -57.1916876 ,  -68.78889142,\n",
      "        -67.79769699,  -69.60917548,  -67.21634117,  -71.38228486,\n",
      "        -85.07712696,  -95.24742212,  -91.30069548,  -84.87992198,\n",
      "        -89.17023791,  -84.49174081,  -92.82438722,  -94.0739295 ,\n",
      "        -98.26183131, -101.50432175,  -97.75337168, -100.63389467,\n",
      "       -102.05984445,  -92.61575456,  -94.31047046,  -90.22673921,\n",
      "        -96.53003153,  -95.09701277])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743,  -98.58009557,  -93.92766603])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657, -146.93445364, -161.96197719,\n",
      "       -159.78265152, -152.82811348, -144.0131632 , -127.61249868,\n",
      "       -118.36294649, -122.16191107, -131.73654375, -114.59089697,\n",
      "       -111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-88.7869476 , -99.3818732 , -94.46403176, -90.86578161,\n",
      "       -82.40929113, -81.95070791, -90.82508376, -91.66475764,\n",
      "       -86.62772714, -84.80344775, -86.37198217, -84.07141657,\n",
      "       -80.44599887, -76.5820445 , -78.14516986, -86.0663459 ,\n",
      "       -90.75310742, -86.25398783, -94.93890187, -98.06049045])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644, -81.42824104, -74.78175296,\n",
      "       -70.8054965 , -80.16707854, -80.39458443, -75.35100815,\n",
      "       -74.44415654, -89.09814678])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -32.00303527,  -23.85200895,  -25.99904734,  -32.67204206,\n",
      "        -91.08540087,  -93.58291408,  -94.442178  ,  -76.67566442,\n",
      "        -77.31861056,  -75.85961461,  -82.38460297,  -87.15021022,\n",
      "        -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -75.85961461,  -82.38460297,  -87.15021022,  -76.16122644,\n",
      "        -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.26176061, -116.10288173, -117.43808447, -116.88679865,\n",
      "       -118.19621787, -122.63837758, -126.10491965, -124.83739507,\n",
      "       -126.34744973, -129.76824429, -126.61002941, -124.9601654 ,\n",
      "       -113.15904449, -128.12941519, -122.84680275, -107.74247681,\n",
      "       -121.13704527, -125.0144325 , -122.19937227, -128.50806931,\n",
      "       -130.63433087, -132.38657704, -115.77977204, -103.25047921,\n",
      "        -94.85500001,  -90.11154958,  -99.41351219, -104.6613764 ,\n",
      "        -99.16721404, -105.12358291])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.35538348,  -98.10173527, -100.35045898,  -93.91332411,\n",
      "        -88.62087539,  -90.98476108,  -83.41650142,  -88.96061067,\n",
      "        -86.6991432 ,  -80.06104528,  -82.31658328,  -80.92018304,\n",
      "        -88.17964354,  -82.28680729,  -79.97343334,  -83.99473886,\n",
      "        -75.88680929,  -78.21148248,  -88.64399073,  -96.94040946])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-116.88679865, -118.19621787, -122.63837758, -126.10491965,\n",
      "       -124.83739507, -126.34744973, -129.76824429, -126.61002941,\n",
      "       -124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348,\n",
      "        -98.10173527, -100.35045898])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-93.91332411, -88.62087539, -90.98476108, -83.41650142,\n",
      "       -88.96061067, -86.6991432 , -80.06104528, -82.31658328,\n",
      "       -80.92018304, -88.17964354, -82.28680729, -79.97343334,\n",
      "       -83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941, -124.9601654 , -113.15904449,\n",
      "       -128.12941519, -122.84680275, -107.74247681, -121.13704527,\n",
      "       -125.0144325 , -122.19937227, -128.50806931, -130.63433087,\n",
      "       -132.38657704, -115.77977204, -103.25047921,  -94.85500001,\n",
      "        -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-90.98476108, -83.41650142, -88.96061067, -86.6991432 ,\n",
      "       -80.06104528, -82.31658328, -80.92018304, -88.17964354,\n",
      "       -82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022, -76.16122644, -81.42824104])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.50432175,  -97.75337168, -100.63389467, -102.05984445,\n",
      "        -92.61575456,  -94.31047046,  -90.22673921,  -96.53003153,\n",
      "        -95.09701277,  -83.74085993, -101.2500878 , -110.9058207 ,\n",
      "       -103.35499144, -102.59232199, -100.94954263, -104.67163394,\n",
      "       -105.29081196, -105.62399864,  -98.42781302,  -96.79147826,\n",
      "        -97.8009911 , -102.68785185, -108.47661262, -112.31184448,\n",
      "       -110.00129287, -112.67157991, -112.33742743,  -98.58009557,\n",
      "        -93.92766603, -101.83772101])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.63623694, -103.50943296, -122.29518075, -131.37125041,\n",
      "       -141.47815813, -142.09928023, -137.33153445, -123.79453514,\n",
      "       -120.04980249, -124.40751793, -120.4174866 , -135.45531333,\n",
      "       -136.87163569, -127.99757245, -137.77564821, -132.10880561,\n",
      "       -126.9691448 , -131.86224812, -129.15683171, -113.98540129])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334,\n",
      "        -83.99473886,  -75.88680929,  -78.21148248,  -88.64399073,\n",
      "        -96.94040946,  -88.58944292,  -91.01452335,  -77.58356387,\n",
      "        -85.71916208,  -75.59568258,  -67.71143355,  -69.27263486,\n",
      "        -72.10504442,  -68.22832895])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-88.62087539, -90.98476108, -83.41650142, -88.96061067,\n",
      "       -86.6991432 , -80.06104528, -82.31658328, -80.92018304,\n",
      "       -88.17964354, -82.28680729, -79.97343334, -83.99473886,\n",
      "       -75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.11154958,  -99.41351219, -104.6613764 ,  -99.16721404,\n",
      "       -105.12358291, -100.35538348,  -98.10173527, -100.35045898,\n",
      "        -93.91332411,  -88.62087539,  -90.98476108,  -83.41650142,\n",
      "        -88.96061067,  -86.6991432 ,  -80.06104528,  -82.31658328,\n",
      "        -80.92018304,  -88.17964354,  -82.28680729,  -79.97343334,\n",
      "        -83.99473886,  -75.88680929,  -78.21148248,  -88.64399073,\n",
      "        -96.94040946,  -88.58944292,  -91.01452335,  -77.58356387,\n",
      "        -85.71916208,  -75.59568258])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461,\n",
      "       -82.38460297, -87.15021022])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -75.85961461,  -82.38460297,  -87.15021022,  -76.16122644,\n",
      "        -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-127.99757245, -137.77564821, -132.10880561, -126.9691448 ,\n",
      "       -131.86224812, -129.15683171, -113.98540129, -114.53371405,\n",
      "       -119.25651751, -125.51953719, -134.33356531, -130.22634478,\n",
      "       -135.46308188, -137.78070316, -140.2979898 , -137.8469443 ,\n",
      "       -135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058, -146.84651478, -131.99717195,\n",
      "       -128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-82.31891513, -88.7869476 , -99.3818732 , -94.46403176,\n",
      "       -90.86578161, -82.40929113, -81.95070791, -90.82508376,\n",
      "       -91.66475764, -86.62772714, -84.80344775, -86.37198217,\n",
      "       -84.07141657, -80.44599887, -76.5820445 , -78.14516986,\n",
      "       -86.0663459 , -90.75310742, -86.25398783, -94.93890187])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-45.100153  , -48.27996867, -54.81777713, -58.07474259,\n",
      "       -61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ,\n",
      "       -80.16707854, -80.39458443, -75.35100815, -74.44415654,\n",
      "       -89.09814678, -98.0311741 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -25.99904734,  -32.67204206,  -91.08540087,  -93.58291408,\n",
      "        -94.442178  ,  -76.67566442,  -77.31861056,  -75.85961461,\n",
      "        -82.38460297,  -87.15021022,  -76.16122644,  -81.42824104,\n",
      "        -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-61.95743214, -63.65204917, -50.53126994, -50.72745374,\n",
      "       -32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ,\n",
      "       -80.16707854, -80.39458443, -75.35100815, -74.44415654,\n",
      "       -89.09814678, -98.0311741 , -98.61419852, -98.24416983,\n",
      "       -93.6538132 , -92.13003401])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734,\n",
      "       -32.67204206, -91.08540087, -93.58291408, -94.442178  ,\n",
      "       -76.67566442, -77.31861056, -75.85961461, -82.38460297,\n",
      "       -87.15021022, -76.16122644])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.42824104,  -74.78175296,  -70.8054965 ,  -80.16707854,\n",
      "        -80.39458443,  -75.35100815,  -74.44415654,  -89.09814678,\n",
      "        -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-90.98476108, -83.41650142, -88.96061067, -86.6991432 ,\n",
      "       -80.06104528, -82.31658328, -80.92018304, -88.17964354,\n",
      "       -82.28680729, -79.97343334, -83.99473886, -75.88680929,\n",
      "       -78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 , -66.68212524, -75.74305537,\n",
      "       -66.39101273, -59.98106103, -60.00600137, -58.36912915,\n",
      "       -54.03073574, -55.99561946, -60.571603  , -57.03558467,\n",
      "       -60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374, -32.00303527, -23.85200895,\n",
      "       -25.99904734, -32.67204206, -91.08540087, -93.58291408,\n",
      "       -94.442178  , -76.67566442, -77.31861056, -75.85961461])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-48.27996867, -54.81777713, -58.07474259, -61.95743214,\n",
      "       -63.65204917, -50.53126994, -50.72745374, -32.00303527,\n",
      "       -23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296, -70.8054965 , -80.16707854,\n",
      "       -80.39458443, -75.35100815, -74.44415654, -89.09814678,\n",
      "       -98.0311741 , -98.61419852])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-62.34715349, -59.62174819, -55.59474203, -55.91301868,\n",
      "       -53.28067634, -60.50870142, -51.42176633, -48.83467487,\n",
      "       -43.87461974, -41.77510451, -41.76231974, -40.10116611,\n",
      "       -39.6343608 , -38.35825074, -32.48717987, -34.61792532,\n",
      "       -35.35276985, -39.43670351, -34.3888163 , -41.50066848])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-23.85200895, -25.99904734, -32.67204206, -91.08540087,\n",
      "       -93.58291408, -94.442178  , -76.67566442, -77.31861056,\n",
      "       -75.85961461, -82.38460297, -87.15021022, -76.16122644,\n",
      "       -81.42824104, -74.78175296, -70.8054965 , -80.16707854,\n",
      "       -80.39458443, -75.35100815, -74.44415654, -89.09814678])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ,\n",
      "        -99.46212579, -103.12945745, -104.65927788, -102.26987779,\n",
      "       -104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-75.88680929, -78.21148248, -88.64399073, -96.94040946,\n",
      "       -88.58944292, -91.01452335, -77.58356387, -85.71916208,\n",
      "       -75.59568258, -67.71143355, -69.27263486, -72.10504442,\n",
      "       -68.22832895, -66.01308384, -58.08180923, -55.9762909 ,\n",
      "       -56.41729778, -58.86486005, -59.37404117, -56.2158812 ,\n",
      "       -66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.21174847, -56.10689802, -63.4515501 , -55.54593069,\n",
      "       -46.66837136, -44.47899286, -37.42862256, -25.81810964,\n",
      "       -20.42858337, -36.45750241, -48.79422277, -50.49781948,\n",
      "       -47.19062918, -40.97094204, -44.08926332, -42.6887559 ,\n",
      "       -45.100153  , -48.27996867, -54.81777713, -58.07474259])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-37.19729033, -43.91968547, -58.51579112, -62.34715349,\n",
      "       -59.62174819, -55.59474203, -55.91301868, -53.28067634,\n",
      "       -60.50870142, -51.42176633, -48.83467487, -43.87461974,\n",
      "       -41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ,\n",
      "        -38.35825074,  -32.48717987])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-60.50870142, -51.42176633, -48.83467487, -43.87461974,\n",
      "       -41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985,\n",
      "       -39.43670351, -34.3888163 , -41.50066848, -35.53523761,\n",
      "       -37.36452616, -53.40109898, -56.12856105, -60.239366  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-83.99473886, -75.88680929, -78.21148248, -88.64399073,\n",
      "       -96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-57.03558467, -60.21174847, -56.10689802, -63.4515501 ,\n",
      "       -55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-48.83467487, -43.87461974, -41.77510451, -41.76231974,\n",
      "       -40.10116611, -39.6343608 , -38.35825074, -32.48717987,\n",
      "       -34.61792532, -35.35276985, -39.43670351, -34.3888163 ,\n",
      "       -41.50066848, -35.53523761, -37.36452616, -53.40109898,\n",
      "       -56.12856105, -60.239366  , -56.45357977, -60.48873413])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994,\n",
      "       -50.72745374, -32.00303527, -23.85200895, -25.99904734])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.0311741 ,  -98.61419852,  -98.24416983,  -93.6538132 ,\n",
      "        -92.13003401, -102.29584311, -100.77972514,  -94.07718062,\n",
      "        -90.55027054,  -84.57167545,  -80.60730987,  -80.78952407,\n",
      "        -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([26.80256559, 14.89549679, 14.2120442 ,  6.60137577,  2.23218413,\n",
      "       13.22627403, 16.39113981,  8.46271719,  4.14273222, 11.75100712,\n",
      "       10.22413696, 11.96761474, 15.20830462, 12.09216166, 27.45549888,\n",
      "       34.60841127, 17.84155919, 17.03987712, 16.77075776, 23.13223269,\n",
      "       20.48695756, 19.05684612, 24.81353912, 32.07915975, 24.2053383 ,\n",
      "       20.44653167, 19.97016802, 17.34540155, 31.22694707, 37.03838759])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ 26.3225838 ,  31.35001544,  48.24119707,  54.06493159,\n",
      "       -23.12935478, -31.08379428, -21.79316183, -26.11448851,\n",
      "       -26.60234425, -21.11952555, -28.77036928, -31.92780838,\n",
      "       -52.57262215, -59.94663704, -54.39197114, -57.87783181,\n",
      "       -43.84103585, -47.763687  , -51.69679116, -46.4540148 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-40.10116611, -39.6343608 , -38.35825074, -32.48717987,\n",
      "       -34.61792532, -35.35276985, -39.43670351, -34.3888163 ,\n",
      "       -41.50066848, -35.53523761, -37.36452616, -53.40109898,\n",
      "       -56.12856105, -60.239366  , -56.45357977, -60.48873413,\n",
      "       -66.24261061, -78.74060436, -81.72821109, -93.87933053])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.41450358,  -96.21683209, -100.71276019, -104.50060295,\n",
      "       -105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-78.21148248, -88.64399073, -96.94040946, -88.58944292,\n",
      "       -91.01452335, -77.58356387, -85.71916208, -75.59568258,\n",
      "       -67.71143355, -69.27263486, -72.10504442, -68.22832895,\n",
      "       -66.01308384, -58.08180923, -55.9762909 , -56.41729778,\n",
      "       -58.86486005, -59.37404117, -56.2158812 , -66.68212524,\n",
      "       -75.74305537, -66.39101273, -59.98106103, -60.00600137,\n",
      "       -58.36912915, -54.03073574, -55.99561946, -60.571603  ,\n",
      "       -57.03558467, -60.21174847])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-56.10689802, -63.4515501 , -55.54593069, -46.66837136,\n",
      "       -44.47899286, -37.42862256, -25.81810964, -20.42858337,\n",
      "       -36.45750241, -48.79422277, -50.49781948, -47.19062918,\n",
      "       -40.97094204, -44.08926332, -42.6887559 , -45.100153  ,\n",
      "       -48.27996867, -54.81777713, -58.07474259, -61.95743214])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-113.98540129, -114.53371405, -119.25651751, -125.51953719,\n",
      "       -134.33356531, -130.22634478, -135.46308188, -137.78070316,\n",
      "       -140.2979898 , -137.8469443 , -135.00428261, -129.34435275,\n",
      "       -133.95427854, -139.0355469 , -145.91267694, -149.24466127,\n",
      "       -145.07136792, -138.68732465, -145.04957605, -141.07324759,\n",
      "       -130.40193536, -129.2979114 , -120.53126801, -127.97864511,\n",
      "       -142.34991916, -155.33313146, -144.4186376 , -136.12484276,\n",
      "       -138.79844949, -138.78281058])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944, -116.99462932, -111.43554862,\n",
      "       -119.87535554, -132.95830363, -136.15981113, -135.80875716,\n",
      "       -129.27202565, -141.13921427, -134.25915854, -132.36753554])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.78070316, -140.2979898 , -137.8469443 , -135.00428261,\n",
      "       -129.34435275, -133.95427854, -139.0355469 , -145.91267694,\n",
      "       -149.24466127, -145.07136792, -138.68732465, -145.04957605,\n",
      "       -141.07324759, -130.40193536, -129.2979114 , -120.53126801,\n",
      "       -127.97864511, -142.34991916, -155.33313146, -144.4186376 ,\n",
      "       -136.12484276, -138.79844949, -138.78281058, -146.84651478,\n",
      "       -131.99717195, -128.89717436, -133.51447455, -130.65526379,\n",
      "       -129.07056382, -130.4567686 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-138.34797642, -137.45405663, -124.52707944, -116.99462932,\n",
      "       -111.43554862, -119.87535554, -132.95830363, -136.15981113,\n",
      "       -135.80875716, -129.27202565, -141.13921427, -134.25915854,\n",
      "       -132.36753554, -138.32127511, -145.4674055 , -155.94138515,\n",
      "       -148.1744804 , -142.67880484, -150.85458764, -158.44759851])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.16122644,  -81.42824104,  -74.78175296,  -70.8054965 ,\n",
      "        -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-98.69760299, -82.31891513, -88.7869476 , -99.3818732 ,\n",
      "       -94.46403176, -90.86578161, -82.40929113, -81.95070791,\n",
      "       -90.82508376, -91.66475764, -86.62772714, -84.80344775,\n",
      "       -86.37198217, -84.07141657, -80.44599887, -76.5820445 ,\n",
      "       -78.14516986, -86.0663459 , -90.75310742, -86.25398783])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.76231974, -40.10116611, -39.6343608 , -38.35825074,\n",
      "       -32.48717987, -34.61792532, -35.35276985, -39.43670351,\n",
      "       -34.3888163 , -41.50066848, -35.53523761, -37.36452616,\n",
      "       -53.40109898, -56.12856105, -60.239366  , -56.45357977,\n",
      "       -60.48873413, -66.24261061, -78.74060436, -81.72821109])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ,\n",
      "        -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-83.41650142, -88.96061067, -86.6991432 , -80.06104528,\n",
      "       -82.31658328, -80.92018304, -88.17964354, -82.28680729,\n",
      "       -79.97343334, -83.99473886, -75.88680929, -78.21148248,\n",
      "       -88.64399073, -96.94040946, -88.58944292, -91.01452335,\n",
      "       -77.58356387, -85.71916208, -75.59568258, -67.71143355,\n",
      "       -69.27263486, -72.10504442, -68.22832895, -66.01308384,\n",
      "       -58.08180923, -55.9762909 , -56.41729778, -58.86486005,\n",
      "       -59.37404117, -56.2158812 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-66.68212524, -75.74305537, -66.39101273, -59.98106103,\n",
      "       -60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-79.49931031, -86.62124362, -85.43480306, -76.35652934,\n",
      "       -72.48571591, -76.84596948, -85.9586282 , -84.70712254,\n",
      "       -83.36434062, -81.07296465, -80.16538679, -77.82567416,\n",
      "       -85.82540074, -82.89715423, -83.9529078 , -76.15774461,\n",
      "       -84.62604971, -81.4802377 , -83.07145401, -94.97385541])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.00428261, -129.34435275, -133.95427854, -139.0355469 ,\n",
      "       -145.91267694, -149.24466127, -145.07136792, -138.68732465,\n",
      "       -145.04957605, -141.07324759, -130.40193536, -129.2979114 ,\n",
      "       -120.53126801, -127.97864511, -142.34991916, -155.33313146,\n",
      "       -144.4186376 , -136.12484276, -138.79844949, -138.78281058,\n",
      "       -146.84651478, -131.99717195, -128.89717436, -133.51447455,\n",
      "       -130.65526379, -129.07056382, -130.4567686 , -138.34797642,\n",
      "       -137.45405663, -124.52707944])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429,\n",
      "       -126.61002941, -124.9601654 , -113.15904449, -128.12941519,\n",
      "       -122.84680275, -107.74247681, -121.13704527, -125.0144325 ,\n",
      "       -122.19937227, -128.50806931, -130.63433087, -132.38657704,\n",
      "       -115.77977204, -103.25047921,  -94.85500001,  -90.11154958,\n",
      "        -99.41351219, -104.6613764 ,  -99.16721404, -105.12358291,\n",
      "       -100.35538348,  -98.10173527])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.35045898,  -93.91332411,  -88.62087539,  -90.98476108,\n",
      "        -83.41650142,  -88.96061067,  -86.6991432 ,  -80.06104528,\n",
      "        -82.31658328,  -80.92018304,  -88.17964354,  -82.28680729,\n",
      "        -79.97343334,  -83.99473886,  -75.88680929,  -78.21148248,\n",
      "        -88.64399073,  -96.94040946,  -88.58944292,  -91.01452335])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531,\n",
      "       -112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-60.00600137, -58.36912915, -54.03073574, -55.99561946,\n",
      "       -60.571603  , -57.03558467, -60.21174847, -56.10689802,\n",
      "       -63.4515501 , -55.54593069, -46.66837136, -44.47899286,\n",
      "       -37.42862256, -25.81810964, -20.42858337, -36.45750241,\n",
      "       -48.79422277, -50.49781948, -47.19062918, -40.97094204,\n",
      "       -44.08926332, -42.6887559 , -45.100153  , -48.27996867,\n",
      "       -54.81777713, -58.07474259, -61.95743214, -63.65204917,\n",
      "       -50.53126994, -50.72745374])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-32.00303527, -23.85200895, -25.99904734, -32.67204206,\n",
      "       -91.08540087, -93.58291408, -94.442178  , -76.67566442,\n",
      "       -77.31861056, -75.85961461, -82.38460297, -87.15021022,\n",
      "       -76.16122644, -81.42824104, -74.78175296, -70.8054965 ,\n",
      "       -80.16707854, -80.39458443, -75.35100815, -74.44415654])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.29584311, -100.77972514,  -94.07718062,  -90.55027054,\n",
      "        -84.57167545,  -80.60730987,  -80.78952407,  -84.70278704,\n",
      "        -98.75425098,  -97.92646955,  -94.19132634,  -93.3396238 ,\n",
      "       -102.59967298, -111.01875174, -101.79655024,  -98.89514129,\n",
      "        -95.5874101 ,  -95.07892734,  -96.34786221,  -90.66755513,\n",
      "        -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.97546743,  -95.8144843 ,  -93.03529519,  -89.01112296,\n",
      "        -99.94450121, -101.55888823,  -93.65594407,  -93.67700299,\n",
      "        -88.9716024 ,  -93.44408468,  -87.55001573,  -72.55517512,\n",
      "        -78.92068212,  -89.22988161,  -82.2602439 ,  -73.12809523,\n",
      "        -81.55735264,  -90.72989763,  -94.86257193, -105.21755531])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.43123674, -117.15678994, -120.04280073, -117.14670253,\n",
      "       -112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.59474203, -55.91301868, -53.28067634, -60.50870142,\n",
      "       -51.42176633, -48.83467487, -43.87461974, -41.77510451,\n",
      "       -41.76231974, -40.10116611, -39.6343608 , -38.35825074,\n",
      "       -32.48717987, -34.61792532, -35.35276985, -39.43670351,\n",
      "       -34.3888163 , -41.50066848, -35.53523761, -37.36452616])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-27.08150445, -27.67970613, -26.51331433, -22.57067968,\n",
      "       -33.51500603, -35.4411814 , -29.78757381, -45.18113249,\n",
      "       -58.12165896, -70.49083278, -70.63950934, -60.9254664 ,\n",
      "       -48.45111915, -47.80716297, -39.78770894, -49.56079929,\n",
      "       -65.43325541,   3.78591522,   9.90558189,  10.86293222,\n",
      "        -2.93567923,  -3.40104466,  -7.00425836,  -0.72673561,\n",
      "         6.29226408,   0.70467075,  -2.52686044,  -6.85015588,\n",
      "        -5.0551342 ,   4.99640488])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  0.50183483,   2.88721421,   2.00275384,  -3.58885226,\n",
      "        -2.92916911,  -7.44759695, -10.05522455, -14.90553531,\n",
      "         0.5782572 ,   5.22926088,  -2.04980069,  -0.93614931,\n",
      "        -0.29967987,  -2.08760684,   2.05148563,   7.46001859,\n",
      "         2.45016043,  -3.97926603,  -6.03480611, -20.85070636])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-53.28067634, -60.50870142, -51.42176633, -48.83467487,\n",
      "       -43.87461974, -41.77510451, -41.76231974, -40.10116611,\n",
      "       -39.6343608 , -38.35825074, -32.48717987, -34.61792532,\n",
      "       -35.35276985, -39.43670351, -34.3888163 , -41.50066848,\n",
      "       -35.53523761, -37.36452616, -53.40109898, -56.12856105])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.87461974, -41.77510451, -41.76231974, -40.10116611,\n",
      "       -39.6343608 , -38.35825074, -32.48717987, -34.61792532,\n",
      "       -35.35276985, -39.43670351, -34.3888163 , -41.50066848,\n",
      "       -35.53523761, -37.36452616, -53.40109898, -56.12856105,\n",
      "       -60.239366  , -56.45357977, -60.48873413, -66.24261061])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-62.34715349, -59.62174819, -55.59474203, -55.91301868,\n",
      "       -53.28067634, -60.50870142, -51.42176633, -48.83467487,\n",
      "       -43.87461974, -41.77510451, -41.76231974, -40.10116611,\n",
      "       -39.6343608 , -38.35825074, -32.48717987, -34.61792532,\n",
      "       -35.35276985, -39.43670351, -34.3888163 , -41.50066848,\n",
      "       -35.53523761, -37.36452616, -53.40109898, -56.12856105,\n",
      "       -60.239366  , -56.45357977, -60.48873413, -66.24261061,\n",
      "       -78.74060436, -81.72821109])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837, -105.95144008, -102.89858114,\n",
      "       -100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923, -103.32785325, -102.07908117,\n",
      "       -100.10402124,  -97.04452122,  -85.23852449,  -88.67817913,\n",
      "       -100.04198899, -111.60643193, -116.84943078, -115.00870335,\n",
      "       -101.19507451, -103.59748181, -105.77735757, -105.63646997])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221,  -90.66755513,  -94.48193595,\n",
      "        -96.5069192 ,  -99.46212579, -103.12945745, -104.65927788,\n",
      "       -102.26987779, -104.41450358,  -96.21683209, -100.71276019,\n",
      "       -104.50060295, -105.97546743,  -95.8144843 ,  -93.03529519,\n",
      "        -89.01112296,  -99.94450121, -101.55888823,  -93.65594407,\n",
      "        -93.67700299,  -88.9716024 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-43.91968547, -58.51579112, -62.34715349, -59.62174819,\n",
      "       -55.59474203, -55.91301868, -53.28067634, -60.50870142,\n",
      "       -51.42176633, -48.83467487, -43.87461974, -41.77510451,\n",
      "       -41.76231974, -40.10116611, -39.6343608 , -38.35825074,\n",
      "       -32.48717987, -34.61792532, -35.35276985, -39.43670351])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193, -105.21755531, -112.43123674,\n",
      "       -117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789, -101.83380641, -113.25315829,\n",
      "       -104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-43.91968547, -58.51579112, -62.34715349, -59.62174819,\n",
      "       -55.59474203, -55.91301868, -53.28067634, -60.50870142,\n",
      "       -51.42176633, -48.83467487, -43.87461974, -41.77510451,\n",
      "       -41.76231974, -40.10116611, -39.6343608 , -38.35825074,\n",
      "       -32.48717987, -34.61792532, -35.35276985, -39.43670351,\n",
      "       -34.3888163 , -41.50066848, -35.53523761, -37.36452616,\n",
      "       -53.40109898, -56.12856105, -60.239366  , -56.45357977,\n",
      "       -60.48873413, -66.24261061])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -70.8054965 ,  -80.16707854,  -80.39458443,  -75.35100815,\n",
      "        -74.44415654,  -89.09814678,  -98.0311741 ,  -98.61419852,\n",
      "        -98.24416983,  -93.6538132 ,  -92.13003401, -102.29584311,\n",
      "       -100.77972514,  -94.07718062,  -90.55027054,  -84.57167545,\n",
      "        -80.60730987,  -80.78952407,  -84.70278704,  -98.75425098,\n",
      "        -97.92646955,  -94.19132634,  -93.3396238 , -102.59967298,\n",
      "       -111.01875174, -101.79655024,  -98.89514129,  -95.5874101 ,\n",
      "        -95.07892734,  -96.34786221])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-37.19729033, -43.91968547, -58.51579112, -62.34715349,\n",
      "       -59.62174819, -55.59474203, -55.91301868, -53.28067634,\n",
      "       -60.50870142, -51.42176633, -48.83467487, -43.87461974,\n",
      "       -41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985,\n",
      "       -39.43670351, -34.3888163 , -41.50066848, -35.53523761,\n",
      "       -37.36452616, -53.40109898, -56.12856105, -60.239366  ,\n",
      "       -56.45357977, -60.48873413])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496, -181.47284919, -191.29493675])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ,\n",
      "        -96.51965912,  -98.01409273, -104.37528364, -105.72346001])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-85.60462028, -79.49931031, -86.62124362, -85.43480306,\n",
      "       -76.35652934, -72.48571591, -76.84596948, -85.9586282 ,\n",
      "       -84.70712254, -83.36434062, -81.07296465, -80.16538679,\n",
      "       -77.82567416, -85.82540074, -82.89715423, -83.9529078 ,\n",
      "       -76.15774461, -84.62604971, -81.4802377 , -83.07145401])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079, -182.05460496, -181.47284919,\n",
      "       -191.29493675, -185.7509761 , -186.72059532, -199.21692821,\n",
      "       -201.87125439, -188.72595373, -181.12834042, -186.02404137])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825, -185.9824623 , -184.84828079])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 , -184.84828079, -182.05460496,\n",
      "       -181.47284919, -191.29493675, -185.7509761 , -186.72059532])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.91301868, -53.28067634, -60.50870142, -51.42176633,\n",
      "       -48.83467487, -43.87461974, -41.77510451, -41.76231974,\n",
      "       -40.10116611, -39.6343608 , -38.35825074, -32.48717987,\n",
      "       -34.61792532, -35.35276985, -39.43670351, -34.3888163 ,\n",
      "       -41.50066848, -35.53523761, -37.36452616, -53.40109898])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825, -185.9824623 , -184.84828079,\n",
      "       -182.05460496, -181.47284919, -191.29493675, -185.7509761 ,\n",
      "       -186.72059532, -199.21692821, -201.87125439, -188.72595373])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468,\n",
      "        -87.55001573,  -72.55517512,  -78.92068212,  -89.22988161,\n",
      "        -82.2602439 ,  -73.12809523,  -81.55735264,  -90.72989763,\n",
      "        -94.86257193, -105.21755531, -112.43123674, -117.15678994,\n",
      "       -120.04280073, -117.14670253, -112.30322265, -100.10349704,\n",
      "       -105.6064385 , -101.84460717, -101.2853673 , -103.54755456,\n",
      "        -99.07971576, -106.58142837])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919, -102.58141415, -111.49927259])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ,  -73.12809523,  -81.55735264,\n",
      "        -90.72989763,  -94.86257193])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079, -182.05460496, -181.47284919,\n",
      "       -191.29493675, -185.7509761 , -186.72059532, -199.21692821])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113,  -81.95070791,  -90.82508376,\n",
      "        -91.66475764,  -86.62772714,  -84.80344775,  -86.37198217,\n",
      "        -84.07141657,  -80.44599887,  -76.5820445 ,  -78.14516986,\n",
      "        -86.0663459 ,  -90.75310742])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848,  -35.53523761,  -37.36452616,\n",
      "        -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079, -182.05460496, -181.47284919])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-59.62174819, -55.59474203, -55.91301868, -53.28067634,\n",
      "       -60.50870142, -51.42176633, -48.83467487, -43.87461974,\n",
      "       -41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985,\n",
      "       -39.43670351, -34.3888163 , -41.50066848, -35.53523761])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349,\n",
      "        -59.62174819,  -55.59474203,  -55.91301868,  -53.28067634,\n",
      "        -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ,\n",
      "        -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-106.98504366, -114.06518919, -102.58141415, -111.49927259,\n",
      "       -130.90518457, -126.60613729, -124.99821531, -131.3103496 ,\n",
      "       -124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -53.28067634,  -60.50870142,  -51.42176633,  -48.83467487,\n",
      "        -43.87461974,  -41.77510451,  -41.76231974,  -40.10116611,\n",
      "        -39.6343608 ,  -38.35825074,  -32.48717987,  -34.61792532,\n",
      "        -35.35276985,  -39.43670351,  -34.3888163 ,  -41.50066848,\n",
      "        -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496, -181.47284919, -191.29493675,\n",
      "       -185.7509761 , -186.72059532, -199.21692821, -201.87125439,\n",
      "       -188.72595373, -181.12834042, -186.02404137, -191.05990892,\n",
      "       -193.80623408, -180.25162296, -177.38385563, -179.76886535])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496, -181.47284919, -191.29493675,\n",
      "       -185.7509761 , -186.72059532])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-199.21692821, -201.87125439, -188.72595373, -181.12834042,\n",
      "       -186.02404137, -191.05990892, -193.80623408, -180.25162296,\n",
      "       -177.38385563, -179.76886535, -175.93925643, -177.43392718,\n",
      "       -183.79090938, -188.46889347, -190.93235699, -192.7182447 ,\n",
      "       -189.29819282, -190.09860267, -188.08233357, -190.26501477])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 , -184.84828079, -182.05460496,\n",
      "       -181.47284919, -191.29493675])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-185.7509761 , -186.72059532, -199.21692821, -201.87125439,\n",
      "       -188.72595373, -181.12834042, -186.02404137, -191.05990892,\n",
      "       -193.80623408, -180.25162296, -177.38385563, -179.76886535,\n",
      "       -175.93925643, -177.43392718, -183.79090938, -188.46889347,\n",
      "       -190.93235699, -192.7182447 , -189.29819282, -190.09860267])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-181.47284919, -191.29493675, -185.7509761 , -186.72059532,\n",
      "       -199.21692821, -201.87125439, -188.72595373, -181.12834042,\n",
      "       -186.02404137, -191.05990892, -193.80623408, -180.25162296,\n",
      "       -177.38385563, -179.76886535, -175.93925643, -177.43392718,\n",
      "       -183.79090938, -188.46889347, -190.93235699, -192.7182447 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -60.50870142,  -51.42176633,  -48.83467487,  -43.87461974,\n",
      "        -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ,\n",
      "        -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ,\n",
      "        -99.3818732 ,  -94.46403176,  -90.86578161,  -82.40929113,\n",
      "        -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -86.0663459 ,  -90.75310742,  -86.25398783,  -94.93890187,\n",
      "        -98.06049045, -101.8620514 , -104.50749304,  -97.00152211,\n",
      "        -96.8993486 , -100.62979678, -112.01112252, -109.07915382,\n",
      "       -103.00877951,  -90.47637946,  -94.51657908,  -99.32499133,\n",
      "        -99.64659686,  -91.66870834,  -94.5263042 ,  -98.1011956 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ,  -78.14516986,  -86.0663459 ,\n",
      "        -90.75310742,  -86.25398783,  -94.93890187,  -98.06049045,\n",
      "       -101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ,\n",
      "        -98.1011956 ,  -96.51965912,  -98.01409273, -104.37528364,\n",
      "       -105.72346001,  -99.46130538, -107.81948807, -110.75388956,\n",
      "       -114.82509497, -107.99685582, -117.0086853 , -123.71284218])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825, -185.9824623 , -184.84828079,\n",
      "       -182.05460496, -181.47284919])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-191.29493675, -185.7509761 , -186.72059532, -199.21692821,\n",
      "       -201.87125439, -188.72595373, -181.12834042, -186.02404137,\n",
      "       -191.05990892, -193.80623408, -180.25162296, -177.38385563,\n",
      "       -179.76886535, -175.93925643, -177.43392718, -183.79090938,\n",
      "       -188.46889347, -190.93235699, -192.7182447 , -189.29819282])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079, -182.05460496, -181.47284919,\n",
      "       -191.29493675, -185.7509761 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-186.72059532, -199.21692821, -201.87125439, -188.72595373,\n",
      "       -181.12834042, -186.02404137, -191.05990892, -193.80623408,\n",
      "       -180.25162296, -177.38385563, -179.76886535, -175.93925643,\n",
      "       -177.43392718, -183.79090938, -188.46889347, -190.93235699,\n",
      "       -192.7182447 , -189.29819282, -190.09860267, -188.08233357])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-96.94040946, -88.58944292, -91.01452335, -77.58356387,\n",
      "       -85.71916208, -75.59568258, -67.71143355, -69.27263486,\n",
      "       -72.10504442, -68.22832895, -66.01308384, -58.08180923,\n",
      "       -55.9762909 , -56.41729778, -58.86486005, -59.37404117,\n",
      "       -56.2158812 , -66.68212524, -75.74305537, -66.39101273,\n",
      "       -59.98106103, -60.00600137, -58.36912915, -54.03073574,\n",
      "       -55.99561946, -60.571603  , -57.03558467, -60.21174847,\n",
      "       -56.10689802, -63.4515501 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-55.54593069, -46.66837136, -44.47899286, -37.42862256,\n",
      "       -25.81810964, -20.42858337, -36.45750241, -48.79422277,\n",
      "       -50.49781948, -47.19062918, -40.97094204, -44.08926332,\n",
      "       -42.6887559 , -45.100153  , -48.27996867, -54.81777713,\n",
      "       -58.07474259, -61.95743214, -63.65204917, -50.53126994])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-117.15678994, -120.04280073, -117.14670253, -112.30322265,\n",
      "       -100.10349704, -105.6064385 , -101.84460717, -101.2853673 ,\n",
      "       -103.54755456,  -99.07971576, -106.58142837, -105.95144008,\n",
      "       -102.89858114, -100.21592727,  -98.72701454,  -83.81676308,\n",
      "        -89.05788793,  -99.17531917, -104.5140478 , -108.67622851,\n",
      "       -112.43871777, -103.60824576,  -92.3617035 ,  -98.11174145,\n",
      "       -107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-104.11831579,  -89.05497129,  -95.79548923, -103.32785325,\n",
      "       -102.07908117, -100.10402124,  -97.04452122,  -85.23852449,\n",
      "        -88.67817913, -100.04198899, -111.60643193, -116.84943078,\n",
      "       -115.00870335, -101.19507451, -103.59748181, -105.77735757,\n",
      "       -105.63646997,  -98.69760299,  -82.31891513,  -88.7869476 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-112.30322265, -100.10349704, -105.6064385 , -101.84460717,\n",
      "       -101.2853673 , -103.54755456,  -99.07971576, -106.58142837,\n",
      "       -105.95144008, -102.89858114, -100.21592727,  -98.72701454,\n",
      "        -83.81676308,  -89.05788793,  -99.17531917, -104.5140478 ,\n",
      "       -108.67622851, -112.43871777, -103.60824576,  -92.3617035 ,\n",
      "        -98.11174145, -107.48234611, -104.66669002, -107.13923502,\n",
      "       -104.12844789, -101.83380641, -113.25315829, -104.11831579,\n",
      "        -89.05497129,  -95.79548923])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-184.84828079, -182.05460496, -181.47284919, -191.29493675,\n",
      "       -185.7509761 , -186.72059532, -199.21692821, -201.87125439,\n",
      "       -188.72595373, -181.12834042, -186.02404137, -191.05990892,\n",
      "       -193.80623408, -180.25162296, -177.38385563, -179.76886535,\n",
      "       -175.93925643, -177.43392718, -183.79090938, -188.46889347])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825, -185.9824623 , -184.84828079,\n",
      "       -182.05460496, -181.47284919, -191.29493675, -185.7509761 ,\n",
      "       -186.72059532, -199.21692821, -201.87125439, -188.72595373,\n",
      "       -181.12834042, -186.02404137, -191.05990892, -193.80623408])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407,  -93.67700299,  -88.9716024 ,\n",
      "        -93.44408468,  -87.55001573,  -72.55517512,  -78.92068212,\n",
      "        -89.22988161,  -82.2602439 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 , -184.84828079, -182.05460496])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-185.9824623 , -184.84828079, -182.05460496, -181.47284919,\n",
      "       -191.29493675, -185.7509761 , -186.72059532, -199.21692821,\n",
      "       -201.87125439, -188.72595373, -181.12834042, -186.02404137,\n",
      "       -191.05990892, -193.80623408, -180.25162296, -177.38385563,\n",
      "       -179.76886535, -175.93925643, -177.43392718, -183.79090938])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -92.82438722,  -94.0739295 ,  -98.26183131, -101.50432175,\n",
      "        -97.75337168, -100.63389467, -102.05984445,  -92.61575456,\n",
      "        -94.31047046,  -90.22673921,  -96.53003153,  -95.09701277,\n",
      "        -83.74085993, -101.2500878 , -110.9058207 , -103.35499144,\n",
      "       -102.59232199, -100.94954263, -104.67163394, -105.29081196,\n",
      "       -105.62399864,  -98.42781302,  -96.79147826,  -97.8009911 ,\n",
      "       -102.68785185, -108.47661262, -112.31184448, -110.00129287,\n",
      "       -112.67157991, -112.33742743])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -98.58009557,  -93.92766603, -101.83772101,  -98.63623694,\n",
      "       -103.50943296, -122.29518075, -131.37125041, -141.47815813,\n",
      "       -142.09928023, -137.33153445, -123.79453514, -120.04980249,\n",
      "       -124.40751793, -120.4174866 , -135.45531333, -136.87163569,\n",
      "       -127.99757245, -137.77564821, -132.10880561, -126.9691448 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193,\n",
      "       -188.43970807, -187.26565825, -185.9824623 , -184.84828079,\n",
      "       -182.05460496, -181.47284919, -191.29493675, -185.7509761 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 , -184.84828079, -182.05460496,\n",
      "       -181.47284919, -191.29493675, -185.7509761 , -186.72059532,\n",
      "       -199.21692821, -201.87125439, -188.72595373, -181.12834042,\n",
      "       -186.02404137, -191.05990892, -193.80623408, -180.25162296])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306,\n",
      "        -76.35652934,  -72.48571591,  -76.84596948,  -85.9586282 ,\n",
      "        -84.70712254,  -83.36434062,  -81.07296465,  -80.16538679,\n",
      "        -77.82567416,  -85.82540074])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362,  -85.43480306,  -76.35652934,\n",
      "        -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-188.43970807, -187.26565825, -185.9824623 , -184.84828079,\n",
      "       -182.05460496, -181.47284919, -191.29493675, -185.7509761 ,\n",
      "       -186.72059532, -199.21692821, -201.87125439, -188.72595373,\n",
      "       -181.12834042, -186.02404137, -191.05990892, -193.80623408,\n",
      "       -180.25162296, -177.38385563, -179.76886535, -175.93925643])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079, -182.05460496, -181.47284919,\n",
      "       -191.29493675, -185.7509761 , -186.72059532, -199.21692821,\n",
      "       -201.87125439, -188.72595373, -181.12834042, -186.02404137,\n",
      "       -191.05990892, -193.80623408, -180.25162296, -177.38385563])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.70278704,  -98.75425098,  -97.92646955,  -94.19132634,\n",
      "        -93.3396238 , -102.59967298, -111.01875174, -101.79655024,\n",
      "        -98.89514129,  -95.5874101 ,  -95.07892734,  -96.34786221,\n",
      "        -90.66755513,  -94.48193595,  -96.5069192 ,  -99.46212579,\n",
      "       -103.12945745, -104.65927788, -102.26987779, -104.41450358,\n",
      "        -96.21683209, -100.71276019, -104.50060295, -105.97546743,\n",
      "        -95.8144843 ,  -93.03529519,  -89.01112296,  -99.94450121,\n",
      "       -101.55888823,  -93.65594407])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -93.67700299,  -88.9716024 ,  -93.44408468,  -87.55001573,\n",
      "        -72.55517512,  -78.92068212,  -89.22988161,  -82.2602439 ,\n",
      "        -73.12809523,  -81.55735264,  -90.72989763,  -94.86257193,\n",
      "       -105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-128.89717436, -133.51447455, -130.65526379, -129.07056382,\n",
      "       -130.4567686 , -138.34797642, -137.45405663, -124.52707944,\n",
      "       -116.99462932, -111.43554862, -119.87535554, -132.95830363,\n",
      "       -136.15981113, -135.80875716, -129.27202565, -141.13921427,\n",
      "       -134.25915854, -132.36753554, -138.32127511, -145.4674055 ,\n",
      "       -155.94138515, -148.1744804 , -142.67880484, -150.85458764,\n",
      "       -158.44759851, -156.67339275, -140.53271536, -138.40408521,\n",
      "       -149.57807405, -149.77749657])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-146.93445364, -161.96197719, -159.78265152, -152.82811348,\n",
      "       -144.0131632 , -127.61249868, -118.36294649, -122.16191107,\n",
      "       -131.73654375, -114.59089697, -111.26176061, -116.10288173,\n",
      "       -117.43808447, -116.88679865, -118.19621787, -122.63837758,\n",
      "       -126.10491965, -124.83739507, -126.34744973, -129.76824429])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ,\n",
      "       -182.23483938, -187.32109942, -191.65993586, -199.07454193])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-114.82509497, -107.99685582, -117.0086853 , -123.71284218,\n",
      "       -118.71631505, -106.59503799, -106.98504366, -114.06518919,\n",
      "       -102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868,\n",
      "        -53.28067634,  -60.50870142])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-51.42176633, -48.83467487, -43.87461974, -41.77510451,\n",
      "       -41.76231974, -40.10116611, -39.6343608 , -38.35825074,\n",
      "       -32.48717987, -34.61792532, -35.35276985, -39.43670351,\n",
      "       -34.3888163 , -41.50066848, -35.53523761, -37.36452616,\n",
      "       -53.40109898, -56.12856105, -60.239366  , -56.45357977])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ,\n",
      "       -134.30857069, -132.66014343])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764,\n",
      "       -146.49596814, -145.15468045, -146.82332658, -154.20234242,\n",
      "       -162.07251474, -163.69514454, -156.29344924, -153.748083  ,\n",
      "       -160.10642117, -158.46672268, -178.78900737, -175.1773335 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -41.77510451,  -41.76231974,  -40.10116611,  -39.6343608 ,\n",
      "        -38.35825074,  -32.48717987,  -34.61792532,  -35.35276985,\n",
      "        -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 , -134.30857069, -132.66014343,\n",
      "       -134.54928676, -140.40696989, -137.37597375, -135.11366568,\n",
      "       -149.74601259, -144.41318585, -134.3972126 , -143.23969764])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-187.26565825, -185.9824623 , -184.84828079, -182.05460496,\n",
      "       -181.47284919, -191.29493675, -185.7509761 , -186.72059532,\n",
      "       -199.21692821, -201.87125439, -188.72595373, -181.12834042,\n",
      "       -186.02404137, -191.05990892, -193.80623408, -180.25162296,\n",
      "       -177.38385563, -179.76886535, -175.93925643, -177.43392718])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ 10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ,   4.99640488,   0.50183483,\n",
      "         2.88721421,   2.00275384,  -3.58885226,  -2.92916911,\n",
      "        -7.44759695, -10.05522455, -14.90553531,   0.5782572 ,\n",
      "         5.22926088,  -2.04980069,  -0.93614931,  -0.29967987,\n",
      "        -2.08760684,   2.05148563,   7.46001859,   2.45016043,\n",
      "        -3.97926603,  -6.03480611])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-20.85070636, -30.92716376, -16.93006873,  -0.85368511,\n",
      "        -3.27830389,  -2.81881203,  -1.20381649,  16.99724166,\n",
      "        22.65474028,  13.1313578 ,   0.1638875 , -14.65412608,\n",
      "       -14.89898574, -18.51630509, -29.35671154, -33.09912348,\n",
      "       -37.46923045, -24.33439739, -14.99583548, -17.62586095])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -39.43670351,  -34.3888163 ,  -41.50066848,  -35.53523761,\n",
      "        -37.36452616,  -53.40109898,  -56.12856105,  -60.239366  ,\n",
      "        -56.45357977,  -60.48873413,  -66.24261061,  -78.74060436,\n",
      "        -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -96.51965912,  -98.01409273, -104.37528364, -105.72346001,\n",
      "        -99.46130538, -107.81948807, -110.75388956, -114.82509497,\n",
      "       -107.99685582, -117.0086853 , -123.71284218, -118.71631505,\n",
      "       -106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-58.51579112, -62.34715349, -59.62174819, -55.59474203,\n",
      "       -55.91301868, -53.28067634, -60.50870142, -51.42176633,\n",
      "       -48.83467487, -43.87461974, -41.77510451, -41.76231974,\n",
      "       -40.10116611, -39.6343608 , -38.35825074, -32.48717987,\n",
      "       -34.61792532, -35.35276985, -39.43670351, -34.3888163 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-59.62174819, -55.59474203, -55.91301868, -53.28067634,\n",
      "       -60.50870142, -51.42176633, -48.83467487, -43.87461974,\n",
      "       -41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985,\n",
      "       -39.43670351, -34.3888163 , -41.50066848, -35.53523761,\n",
      "       -37.36452616, -53.40109898, -56.12856105, -60.239366  ,\n",
      "       -56.45357977, -60.48873413, -66.24261061, -78.74060436,\n",
      "       -81.72821109, -93.87933053])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -50.53126994,  -50.72745374,  -32.00303527,  -23.85200895,\n",
      "        -25.99904734,  -32.67204206,  -91.08540087,  -93.58291408,\n",
      "        -94.442178  ,  -76.67566442,  -77.31861056,  -75.85961461,\n",
      "        -82.38460297,  -87.15021022,  -76.16122644,  -81.42824104,\n",
      "        -74.78175296,  -70.8054965 ,  -80.16707854,  -80.39458443,\n",
      "        -75.35100815,  -74.44415654,  -89.09814678,  -98.0311741 ,\n",
      "        -98.61419852,  -98.24416983,  -93.6538132 ,  -92.13003401,\n",
      "       -102.29584311, -100.77972514])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513,  -94.48193595,  -96.5069192 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496, -181.47284919, -191.29493675,\n",
      "       -185.7509761 , -186.72059532, -199.21692821, -201.87125439])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036,\n",
      "       -118.85403276, -125.49513701, -137.68545934, -136.90163364,\n",
      "       -130.54726005, -135.04933499, -127.13039718, -135.4803636 ,\n",
      "       -150.1314307 , -148.37437738, -139.20952035, -128.5208055 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-102.6073755 ,  -91.06766142,  -79.45127579,  -75.09936215,\n",
      "        -81.48172108,  -82.25550634,  -80.02383443,  -87.00144532,\n",
      "        -76.84660771,  -68.08246931,  -72.18691562,  -74.88508262,\n",
      "        -74.55199582,  -89.42869932,  -93.09060264,  -94.29022247,\n",
      "       -100.15476299, -100.3305874 ,  -85.60462028,  -79.49931031,\n",
      "        -86.62124362,  -85.43480306,  -76.35652934,  -72.48571591,\n",
      "        -76.84596948,  -85.9586282 ,  -84.70712254,  -83.36434062,\n",
      "        -81.07296465,  -80.16538679])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -77.82567416,  -85.82540074,  -82.89715423,  -83.9529078 ,\n",
      "        -76.15774461,  -84.62604971,  -81.4802377 ,  -83.07145401,\n",
      "        -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.8620514 , -104.50749304,  -97.00152211,  -96.8993486 ,\n",
      "       -100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582,\n",
      "       -117.0086853 , -123.71284218, -118.71631505, -106.59503799,\n",
      "       -106.98504366, -114.06518919])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-102.58141415, -111.49927259, -130.90518457, -126.60613729,\n",
      "       -124.99821531, -131.3103496 , -124.67909558, -119.48577425,\n",
      "       -123.15339439, -131.48594163, -124.10781984, -115.91583469,\n",
      "       -116.89213864,  -37.19729033,  -43.91968547,  -58.51579112,\n",
      "        -62.34715349,  -59.62174819,  -55.59474203,  -55.91301868])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-105.21755531, -112.43123674, -117.15678994, -120.04280073,\n",
      "       -117.14670253, -112.30322265, -100.10349704, -105.6064385 ,\n",
      "       -101.84460717, -101.2853673 , -103.54755456,  -99.07971576,\n",
      "       -106.58142837, -105.95144008, -102.89858114, -100.21592727,\n",
      "        -98.72701454,  -83.81676308,  -89.05788793,  -99.17531917,\n",
      "       -104.5140478 , -108.67622851, -112.43871777, -103.60824576,\n",
      "        -92.3617035 ,  -98.11174145, -107.48234611, -104.66669002,\n",
      "       -107.13923502, -104.12844789])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-19.34332875, -27.08150445, -27.67970613, -26.51331433,\n",
      "       -22.57067968, -33.51500603, -35.4411814 , -29.78757381,\n",
      "       -45.18113249, -58.12165896, -70.49083278, -70.63950934,\n",
      "       -60.9254664 , -48.45111915, -47.80716297, -39.78770894,\n",
      "       -49.56079929, -65.43325541,   3.78591522,   9.90558189,\n",
      "        10.86293222,  -2.93567923,  -3.40104466,  -7.00425836,\n",
      "        -0.72673561,   6.29226408,   0.70467075,  -2.52686044,\n",
      "        -6.85015588,  -5.0551342 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([  4.99640488,   0.50183483,   2.88721421,   2.00275384,\n",
      "        -3.58885226,  -2.92916911,  -7.44759695, -10.05522455,\n",
      "       -14.90553531,   0.5782572 ,   5.22926088,  -2.04980069,\n",
      "        -0.93614931,  -0.29967987,  -2.08760684,   2.05148563,\n",
      "         7.46001859,   2.45016043,  -3.97926603,  -6.03480611])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -94.97385541, -103.26593462, -108.03214049, -107.19835848,\n",
      "       -105.29914903, -111.9574026 , -115.57824849, -102.48719504,\n",
      "        -92.52113119,  -96.15139019, -103.28609929, -107.92954176,\n",
      "       -108.15024036, -118.85403276, -125.49513701, -137.68545934,\n",
      "       -136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117, -158.46672268, -178.78900737,\n",
      "       -175.1773335 , -182.23483938, -187.32109942, -191.65993586])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268,\n",
      "       -178.78900737, -175.1773335 , -182.23483938, -187.32109942,\n",
      "       -191.65993586, -199.07454193, -188.43970807, -187.26565825,\n",
      "       -185.9824623 , -184.84828079])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-182.05460496, -181.47284919, -191.29493675, -185.7509761 ,\n",
      "       -186.72059532, -199.21692821, -201.87125439, -188.72595373,\n",
      "       -181.12834042, -186.02404137, -191.05990892, -193.80623408,\n",
      "       -180.25162296, -177.38385563, -179.76886535, -175.93925643,\n",
      "       -177.43392718, -183.79090938, -188.46889347, -190.93235699])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678,\n",
      "       -112.01112252, -109.07915382, -103.00877951,  -90.47637946,\n",
      "        -94.51657908,  -99.32499133,  -99.64659686,  -91.66870834,\n",
      "        -94.5263042 ,  -98.1011956 ,  -96.51965912,  -98.01409273,\n",
      "       -104.37528364, -105.72346001,  -99.46130538, -107.81948807,\n",
      "       -110.75388956, -114.82509497, -107.99685582, -117.0086853 ,\n",
      "       -123.71284218, -118.71631505])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-106.59503799, -106.98504366, -114.06518919, -102.58141415,\n",
      "       -111.49927259, -130.90518457, -126.60613729, -124.99821531,\n",
      "       -131.3103496 , -124.67909558, -119.48577425, -123.15339439,\n",
      "       -131.48594163, -124.10781984, -115.91583469, -116.89213864,\n",
      "        -37.19729033,  -43.91968547,  -58.51579112,  -62.34715349])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335, -101.19507451, -103.59748181,\n",
      "       -105.77735757, -105.63646997,  -98.69760299,  -82.31891513,\n",
      "        -88.7869476 ,  -99.3818732 ,  -94.46403176,  -90.86578161,\n",
      "        -82.40929113,  -81.95070791,  -90.82508376,  -91.66475764,\n",
      "        -86.62772714,  -84.80344775,  -86.37198217,  -84.07141657,\n",
      "        -80.44599887,  -76.5820445 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 , -100.62979678, -112.01112252,\n",
      "       -109.07915382, -103.00877951,  -90.47637946,  -94.51657908,\n",
      "        -99.32499133,  -99.64659686,  -91.66870834,  -94.5263042 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -80.16707854,  -80.39458443,  -75.35100815,  -74.44415654,\n",
      "        -89.09814678,  -98.0311741 ,  -98.61419852,  -98.24416983,\n",
      "        -93.6538132 ,  -92.13003401, -102.29584311, -100.77972514,\n",
      "        -94.07718062,  -90.55027054,  -84.57167545,  -80.60730987,\n",
      "        -80.78952407,  -84.70278704,  -98.75425098,  -97.92646955,\n",
      "        -94.19132634,  -93.3396238 , -102.59967298, -111.01875174,\n",
      "       -101.79655024,  -98.89514129,  -95.5874101 ,  -95.07892734,\n",
      "        -96.34786221,  -90.66755513])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -94.48193595,  -96.5069192 ,  -99.46212579, -103.12945745,\n",
      "       -104.65927788, -102.26987779, -104.41450358,  -96.21683209,\n",
      "       -100.71276019, -104.50060295, -105.97546743,  -95.8144843 ,\n",
      "        -93.03529519,  -89.01112296,  -99.94450121, -101.55888823,\n",
      "        -93.65594407,  -93.67700299,  -88.9716024 ,  -93.44408468])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -81.07296465,  -80.16538679,  -77.82567416,  -85.82540074,\n",
      "        -82.89715423,  -83.9529078 ,  -76.15774461,  -84.62604971,\n",
      "        -81.4802377 ,  -83.07145401,  -94.97385541, -103.26593462,\n",
      "       -108.03214049, -107.19835848, -105.29914903, -111.9574026 ,\n",
      "       -115.57824849, -102.48719504,  -92.52113119,  -96.15139019,\n",
      "       -103.28609929, -107.92954176, -108.15024036, -118.85403276,\n",
      "       -125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049,\n",
      "       -107.19835848, -105.29914903, -111.9574026 , -115.57824849,\n",
      "       -102.48719504,  -92.52113119,  -96.15139019, -103.28609929,\n",
      "       -107.92954176, -108.15024036, -118.85403276, -125.49513701,\n",
      "       -137.68545934, -136.90163364, -130.54726005, -135.04933499,\n",
      "       -127.13039718, -135.4803636 , -150.1314307 , -148.37437738,\n",
      "       -139.20952035, -128.5208055 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-134.30857069, -132.66014343, -134.54928676, -140.40696989,\n",
      "       -137.37597375, -135.11366568, -149.74601259, -144.41318585,\n",
      "       -134.3972126 , -143.23969764, -146.49596814, -145.15468045,\n",
      "       -146.82332658, -154.20234242, -162.07251474, -163.69514454,\n",
      "       -156.29344924, -153.748083  , -160.10642117, -158.46672268])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-124.67909558, -119.48577425, -123.15339439, -131.48594163,\n",
      "       -124.10781984, -115.91583469, -116.89213864,  -37.19729033,\n",
      "        -43.91968547,  -58.51579112,  -62.34715349,  -59.62174819,\n",
      "        -55.59474203,  -55.91301868,  -53.28067634,  -60.50870142,\n",
      "        -51.42176633,  -48.83467487,  -43.87461974,  -41.77510451,\n",
      "        -41.76231974,  -40.10116611,  -39.6343608 ,  -38.35825074,\n",
      "        -32.48717987,  -34.61792532,  -35.35276985,  -39.43670351,\n",
      "        -34.3888163 ,  -41.50066848])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -35.53523761,  -37.36452616,  -53.40109898,  -56.12856105,\n",
      "        -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-58.51579112, -62.34715349, -59.62174819, -55.59474203,\n",
      "       -55.91301868, -53.28067634, -60.50870142, -51.42176633,\n",
      "       -48.83467487, -43.87461974, -41.77510451, -41.76231974,\n",
      "       -40.10116611, -39.6343608 , -38.35825074, -32.48717987,\n",
      "       -34.61792532, -35.35276985, -39.43670351, -34.3888163 ,\n",
      "       -41.50066848, -35.53523761, -37.36452616, -53.40109898,\n",
      "       -56.12856105, -60.239366  , -56.45357977, -60.48873413,\n",
      "       -66.24261061, -78.74060436])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.72821109,  -93.87933053, -102.6073755 ,  -91.06766142,\n",
      "        -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-125.49513701, -137.68545934, -136.90163364, -130.54726005,\n",
      "       -135.04933499, -127.13039718, -135.4803636 , -150.1314307 ,\n",
      "       -148.37437738, -139.20952035, -128.5208055 , -134.30857069,\n",
      "       -132.66014343, -134.54928676, -140.40696989, -137.37597375,\n",
      "       -135.11366568, -149.74601259, -144.41318585, -134.3972126 ,\n",
      "       -143.23969764, -146.49596814, -145.15468045, -146.82332658,\n",
      "       -154.20234242, -162.07251474, -163.69514454, -156.29344924,\n",
      "       -153.748083  , -160.10642117])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-158.46672268, -178.78900737, -175.1773335 , -182.23483938,\n",
      "       -187.32109942, -191.65993586, -199.07454193, -188.43970807,\n",
      "       -187.26565825, -185.9824623 , -184.84828079, -182.05460496,\n",
      "       -181.47284919, -191.29493675, -185.7509761 , -186.72059532,\n",
      "       -199.21692821, -201.87125439, -188.72595373, -181.12834042])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -60.239366  ,  -56.45357977,  -60.48873413,  -66.24261061,\n",
      "        -78.74060436,  -81.72821109,  -93.87933053, -102.6073755 ,\n",
      "        -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -72.48571591,  -76.84596948,  -85.9586282 ,  -84.70712254,\n",
      "        -83.36434062,  -81.07296465,  -80.16538679,  -77.82567416,\n",
      "        -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-100.21592727,  -98.72701454,  -83.81676308,  -89.05788793,\n",
      "        -99.17531917, -104.5140478 , -108.67622851, -112.43871777,\n",
      "       -103.60824576,  -92.3617035 ,  -98.11174145, -107.48234611,\n",
      "       -104.66669002, -107.13923502, -104.12844789, -101.83380641,\n",
      "       -113.25315829, -104.11831579,  -89.05497129,  -95.79548923,\n",
      "       -103.32785325, -102.07908117, -100.10402124,  -97.04452122,\n",
      "        -85.23852449,  -88.67817913, -100.04198899, -111.60643193,\n",
      "       -116.84943078, -115.00870335])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-123.71284218, -118.71631505, -106.59503799, -106.98504366,\n",
      "       -114.06518919, -102.58141415, -111.49927259, -130.90518457,\n",
      "       -126.60613729, -124.99821531, -131.3103496 , -124.67909558,\n",
      "       -119.48577425, -123.15339439, -131.48594163, -124.10781984,\n",
      "       -115.91583469, -116.89213864,  -37.19729033,  -43.91968547,\n",
      "        -58.51579112,  -62.34715349,  -59.62174819,  -55.59474203,\n",
      "        -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-41.77510451, -41.76231974, -40.10116611, -39.6343608 ,\n",
      "       -38.35825074, -32.48717987, -34.61792532, -35.35276985,\n",
      "       -39.43670351, -34.3888163 , -41.50066848, -35.53523761,\n",
      "       -37.36452616, -53.40109898, -56.12856105, -60.239366  ,\n",
      "       -56.45357977, -60.48873413, -66.24261061, -78.74060436])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -53.40109898,  -56.12856105,  -60.239366  ,  -56.45357977,\n",
      "        -60.48873413,  -66.24261061,  -78.74060436,  -81.72821109,\n",
      "        -93.87933053, -102.6073755 ,  -91.06766142,  -79.45127579,\n",
      "        -75.09936215,  -81.48172108,  -82.25550634,  -80.02383443,\n",
      "        -87.00144532,  -76.84660771,  -68.08246931,  -72.18691562,\n",
      "        -74.88508262,  -74.55199582,  -89.42869932,  -93.09060264,\n",
      "        -94.29022247, -100.15476299, -100.3305874 ,  -85.60462028,\n",
      "        -79.49931031,  -86.62124362])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416,  -85.82540074,  -82.89715423,\n",
      "        -83.9529078 ,  -76.15774461,  -84.62604971,  -81.4802377 ,\n",
      "        -83.07145401,  -94.97385541, -103.26593462, -108.03214049])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -55.91301868,  -53.28067634,  -60.50870142,  -51.42176633,\n",
      "        -48.83467487,  -43.87461974,  -41.77510451,  -41.76231974,\n",
      "        -40.10116611,  -39.6343608 ,  -38.35825074,  -32.48717987,\n",
      "        -34.61792532,  -35.35276985,  -39.43670351,  -34.3888163 ,\n",
      "        -41.50066848,  -35.53523761,  -37.36452616,  -53.40109898,\n",
      "        -56.12856105,  -60.239366  ,  -56.45357977,  -60.48873413,\n",
      "        -66.24261061,  -78.74060436,  -81.72821109,  -93.87933053,\n",
      "       -102.6073755 ,  -91.06766142])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -79.45127579,  -75.09936215,  -81.48172108,  -82.25550634,\n",
      "        -80.02383443,  -87.00144532,  -76.84660771,  -68.08246931,\n",
      "        -72.18691562,  -74.88508262,  -74.55199582,  -89.42869932,\n",
      "        -93.09060264,  -94.29022247, -100.15476299, -100.3305874 ,\n",
      "        -85.60462028,  -79.49931031,  -86.62124362,  -85.43480306])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-136.90163364, -130.54726005, -135.04933499, -127.13039718,\n",
      "       -135.4803636 , -150.1314307 , -148.37437738, -139.20952035,\n",
      "       -128.5208055 , -134.30857069, -132.66014343, -134.54928676,\n",
      "       -140.40696989, -137.37597375, -135.11366568, -149.74601259,\n",
      "       -144.41318585, -134.3972126 , -143.23969764, -146.49596814,\n",
      "       -145.15468045, -146.82332658, -154.20234242, -162.07251474,\n",
      "       -163.69514454, -156.29344924, -153.748083  , -160.10642117,\n",
      "       -158.46672268, -178.78900737])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-175.1773335 , -182.23483938, -187.32109942, -191.65993586,\n",
      "       -199.07454193, -188.43970807, -187.26565825, -185.9824623 ,\n",
      "       -184.84828079, -182.05460496, -181.47284919, -191.29493675,\n",
      "       -185.7509761 , -186.72059532, -199.21692821, -201.87125439,\n",
      "       -188.72595373, -181.12834042, -186.02404137, -191.05990892])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([ -91.06766142,  -79.45127579,  -75.09936215,  -81.48172108,\n",
      "        -82.25550634,  -80.02383443,  -87.00144532,  -76.84660771,\n",
      "        -68.08246931,  -72.18691562,  -74.88508262,  -74.55199582,\n",
      "        -89.42869932,  -93.09060264,  -94.29022247, -100.15476299,\n",
      "       -100.3305874 ,  -85.60462028,  -79.49931031,  -86.62124362,\n",
      "        -85.43480306,  -76.35652934,  -72.48571591,  -76.84596948,\n",
      "        -85.9586282 ,  -84.70712254,  -83.36434062,  -81.07296465,\n",
      "        -80.16538679,  -77.82567416])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -85.82540074,  -82.89715423,  -83.9529078 ,  -76.15774461,\n",
      "        -84.62604971,  -81.4802377 ,  -83.07145401,  -94.97385541,\n",
      "       -103.26593462, -108.03214049, -107.19835848, -105.29914903,\n",
      "       -111.9574026 , -115.57824849, -102.48719504,  -92.52113119,\n",
      "        -96.15139019, -103.28609929, -107.92954176, -108.15024036])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-101.19507451, -103.59748181, -105.77735757, -105.63646997,\n",
      "        -98.69760299,  -82.31891513,  -88.7869476 ,  -99.3818732 ,\n",
      "        -94.46403176,  -90.86578161,  -82.40929113,  -81.95070791,\n",
      "        -90.82508376,  -91.66475764,  -86.62772714,  -84.80344775,\n",
      "        -86.37198217,  -84.07141657,  -80.44599887,  -76.5820445 ,\n",
      "        -78.14516986,  -86.0663459 ,  -90.75310742,  -86.25398783,\n",
      "        -94.93890187,  -98.06049045, -101.8620514 , -104.50749304,\n",
      "        -97.00152211,  -96.8993486 ])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-100.62979678, -112.01112252, -109.07915382, -103.00877951,\n",
      "        -90.47637946,  -94.51657908,  -99.32499133,  -99.64659686,\n",
      "        -91.66870834,  -94.5263042 ,  -98.1011956 ,  -96.51965912,\n",
      "        -98.01409273, -104.37528364, -105.72346001,  -99.46130538,\n",
      "       -107.81948807, -110.75388956, -114.82509497, -107.99685582])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-148.1744804 , -142.67880484, -150.85458764, -158.44759851,\n",
      "       -156.67339275, -140.53271536, -138.40408521, -149.57807405,\n",
      "       -149.77749657, -146.93445364, -161.96197719, -159.78265152,\n",
      "       -152.82811348, -144.0131632 , -127.61249868, -118.36294649,\n",
      "       -122.16191107, -131.73654375, -114.59089697, -111.26176061,\n",
      "       -116.10288173, -117.43808447, -116.88679865, -118.19621787,\n",
      "       -122.63837758, -126.10491965, -124.83739507, -126.34744973,\n",
      "       -129.76824429, -126.61002941])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([-124.9601654 , -113.15904449, -128.12941519, -122.84680275,\n",
      "       -107.74247681, -121.13704527, -125.0144325 , -122.19937227,\n",
      "       -128.50806931, -130.63433087, -132.38657704, -115.77977204,\n",
      "       -103.25047921,  -94.85500001,  -90.11154958,  -99.41351219,\n",
      "       -104.6613764 ,  -99.16721404, -105.12358291, -100.35538348])>)\n",
      "(<tf.Tensor: shape=(30,), dtype=float64, numpy=\n",
      "array([-107.48234611, -104.66669002, -107.13923502, -104.12844789,\n",
      "       -101.83380641, -113.25315829, -104.11831579,  -89.05497129,\n",
      "        -95.79548923, -103.32785325, -102.07908117, -100.10402124,\n",
      "        -97.04452122,  -85.23852449,  -88.67817913, -100.04198899,\n",
      "       -111.60643193, -116.84943078, -115.00870335, -101.19507451,\n",
      "       -103.59748181, -105.77735757, -105.63646997,  -98.69760299,\n",
      "        -82.31891513,  -88.7869476 ,  -99.3818732 ,  -94.46403176,\n",
      "        -90.86578161,  -82.40929113])>, <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
      "array([ -81.95070791,  -90.82508376,  -91.66475764,  -86.62772714,\n",
      "        -84.80344775,  -86.37198217,  -84.07141657,  -80.44599887,\n",
      "        -76.5820445 ,  -78.14516986,  -86.0663459 ,  -90.75310742,\n",
      "        -86.25398783,  -94.93890187,  -98.06049045, -101.8620514 ,\n",
      "       -104.50749304,  -97.00152211,  -96.8993486 , -100.62979678])>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for element in dataset:\n",
    "  print(element)\n",
    "  i = i + 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c41df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "#     Conv1D(filters=32, kernel_size=3, activation='relu', batch_input_shape=(window_size, 1)),\n",
    "    LSTM(32, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(nforecast)\n",
    "])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b5537b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ts = tf.convert_to_tensor(inp)\n",
    "t_ts = tf.convert_to_tensor(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c259daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 07:02:19.362131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:19.364200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:19.365651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:02:19.607723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:19.614436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:19.617011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:02:19.895657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:19.897605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:19.899200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:02:20.147849: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:20.150930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:20.154286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:02:21.497362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:21.499517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:21.501033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:02:21.809428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:02:21.811747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:02:21.813280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 5s 25ms/step - loss: 7313.3335 - mae: 74.1644 - mse: 7313.3335\n",
      "Epoch 2/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 7116.0811 - mae: 72.9373 - mse: 7116.0811\n",
      "Epoch 3/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 6915.8262 - mae: 71.6846 - mse: 6915.8262\n",
      "Epoch 4/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 6751.0586 - mae: 70.6422 - mse: 6751.0586\n",
      "Epoch 5/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 6597.4243 - mae: 69.6648 - mse: 6597.4243\n",
      "Epoch 6/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 6447.3096 - mae: 68.6900 - mse: 6447.3096\n",
      "Epoch 7/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 6302.0776 - mae: 67.7152 - mse: 6302.0776\n",
      "Epoch 8/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 6157.2153 - mae: 66.7393 - mse: 6157.2153\n",
      "Epoch 9/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 6014.5317 - mae: 65.7459 - mse: 6014.5317\n",
      "Epoch 10/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 5875.3491 - mae: 64.7532 - mse: 5875.3491\n",
      "Epoch 11/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 5738.1157 - mae: 63.7523 - mse: 5738.1157\n",
      "Epoch 12/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 5607.3574 - mae: 62.8717 - mse: 5607.3574\n",
      "Epoch 13/5000\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 5468.5957 - mae: 61.7876 - mse: 5468.5957\n",
      "Epoch 14/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 5340.6284 - mae: 60.8464 - mse: 5340.6284\n",
      "Epoch 15/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 5208.1392 - mae: 59.8066 - mse: 5208.1392\n",
      "Epoch 16/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 5084.5044 - mae: 58.9122 - mse: 5084.5044\n",
      "Epoch 17/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 4960.5718 - mae: 57.9280 - mse: 4960.5718\n",
      "Epoch 18/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 4841.2568 - mae: 56.9781 - mse: 4841.2568\n",
      "Epoch 19/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 4719.0645 - mae: 55.9902 - mse: 4719.0645\n",
      "Epoch 20/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 4604.3296 - mae: 55.1246 - mse: 4604.3296\n",
      "Epoch 21/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 4486.8838 - mae: 54.1545 - mse: 4486.8838\n",
      "Epoch 22/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 4375.3062 - mae: 53.2645 - mse: 4375.3062\n",
      "Epoch 23/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 4265.4302 - mae: 52.3723 - mse: 4265.4302\n",
      "Epoch 24/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 4157.1958 - mae: 51.5261 - mse: 4157.1958\n",
      "Epoch 25/5000\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 4051.7664 - mae: 50.6833 - mse: 4051.7664\n",
      "Epoch 26/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 3947.2993 - mae: 49.8084 - mse: 3947.2993\n",
      "Epoch 27/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 3844.0784 - mae: 48.9542 - mse: 3844.0784\n",
      "Epoch 28/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 3740.1177 - mae: 48.0810 - mse: 3740.1177\n",
      "Epoch 29/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 3644.1609 - mae: 47.3095 - mse: 3644.1609\n",
      "Epoch 30/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 3546.2483 - mae: 46.4735 - mse: 3546.2483\n",
      "Epoch 31/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 3450.6301 - mae: 45.6722 - mse: 3450.6301\n",
      "Epoch 32/5000\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 3360.6670 - mae: 44.9373 - mse: 3360.6670\n",
      "Epoch 33/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 3271.3813 - mae: 44.2213 - mse: 3271.3813\n",
      "Epoch 34/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 3187.7671 - mae: 43.5279 - mse: 3187.7671\n",
      "Epoch 35/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 3098.3760 - mae: 42.7678 - mse: 3098.3760\n",
      "Epoch 36/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 3021.7437 - mae: 42.1994 - mse: 3021.7437\n",
      "Epoch 37/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 2952.3516 - mae: 41.7499 - mse: 2952.3516\n",
      "Epoch 38/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2860.3298 - mae: 40.8890 - mse: 2860.3298\n",
      "Epoch 39/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 2781.7888 - mae: 40.2276 - mse: 2781.7888\n",
      "Epoch 40/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2708.7075 - mae: 39.6139 - mse: 2708.7075\n",
      "Epoch 41/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 2633.0603 - mae: 38.9789 - mse: 2633.0603\n",
      "Epoch 42/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 2555.7173 - mae: 38.2506 - mse: 2555.7173\n",
      "Epoch 43/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 2486.1121 - mae: 37.6413 - mse: 2486.1121\n",
      "Epoch 44/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 2424.3506 - mae: 37.1499 - mse: 2424.3506\n",
      "Epoch 45/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2349.9324 - mae: 36.4606 - mse: 2349.9324\n",
      "Epoch 46/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2288.0989 - mae: 35.9703 - mse: 2288.0989\n",
      "Epoch 47/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 2223.5879 - mae: 35.4036 - mse: 2223.5879\n",
      "Epoch 48/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2157.0425 - mae: 34.7573 - mse: 2157.0425\n",
      "Epoch 49/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 2094.8633 - mae: 34.1615 - mse: 2094.8633\n",
      "Epoch 50/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 2039.3119 - mae: 33.6414 - mse: 2039.3119\n",
      "Epoch 51/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1976.5388 - mae: 33.0814 - mse: 1976.5388\n",
      "Epoch 52/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 1921.0558 - mae: 32.5368 - mse: 1921.0558\n",
      "Epoch 53/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 1869.5905 - mae: 32.0813 - mse: 1869.5905\n",
      "Epoch 54/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1808.4071 - mae: 31.3871 - mse: 1808.4071\n",
      "Epoch 55/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1753.2609 - mae: 30.8321 - mse: 1753.2609\n",
      "Epoch 56/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1700.0405 - mae: 30.2300 - mse: 1700.0405\n",
      "Epoch 57/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1646.5326 - mae: 29.6776 - mse: 1646.5326\n",
      "Epoch 58/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1598.4966 - mae: 29.1710 - mse: 1598.4966\n",
      "Epoch 59/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1547.4915 - mae: 28.6018 - mse: 1547.4915\n",
      "Epoch 60/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1501.0267 - mae: 28.1470 - mse: 1501.0267\n",
      "Epoch 61/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1456.6251 - mae: 27.6224 - mse: 1456.6251\n",
      "Epoch 62/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1410.1849 - mae: 27.1207 - mse: 1410.1849\n",
      "Epoch 63/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 1364.0680 - mae: 26.5141 - mse: 1364.0680\n",
      "Epoch 64/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1322.2977 - mae: 26.0824 - mse: 1322.2977\n",
      "Epoch 65/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 1284.2731 - mae: 25.6499 - mse: 1284.2731\n",
      "Epoch 66/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1240.1793 - mae: 25.1395 - mse: 1240.1793\n",
      "Epoch 67/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 1198.5812 - mae: 24.5640 - mse: 1198.5812\n",
      "Epoch 68/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 1160.4955 - mae: 24.1158 - mse: 1160.4955\n",
      "Epoch 69/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 1129.7371 - mae: 23.7967 - mse: 1129.7371\n",
      "Epoch 70/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1103.1699 - mae: 23.5092 - mse: 1103.1699\n",
      "Epoch 71/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1058.4923 - mae: 22.8465 - mse: 1058.4923\n",
      "Epoch 72/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 1046.7500 - mae: 22.7427 - mse: 1046.7500\n",
      "Epoch 73/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 1007.1551 - mae: 22.2979 - mse: 1007.1551\n",
      "Epoch 74/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 973.5352 - mae: 21.7980 - mse: 973.5352\n",
      "Epoch 75/5000\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 934.3405 - mae: 21.2272 - mse: 934.3405\n",
      "Epoch 76/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 912.5623 - mae: 21.0208 - mse: 912.5623\n",
      "Epoch 77/5000\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 886.7566 - mae: 20.6442 - mse: 886.7566\n",
      "Epoch 78/5000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 852.6145 - mae: 20.2178 - mse: 852.6145\n",
      "Epoch 79/5000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 828.8655 - mae: 19.8927 - mse: 828.8655\n",
      "Epoch 80/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 807.8994 - mae: 19.5672 - mse: 807.8994\n",
      "Epoch 81/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 787.1565 - mae: 19.3302 - mse: 787.1565\n",
      "Epoch 82/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 759.5618 - mae: 18.9051 - mse: 759.5618\n",
      "Epoch 83/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 745.4219 - mae: 18.7809 - mse: 745.4219\n",
      "Epoch 84/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 727.3137 - mae: 18.4630 - mse: 727.3137\n",
      "Epoch 85/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 703.3909 - mae: 18.0838 - mse: 703.3909\n",
      "Epoch 86/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 697.3384 - mae: 18.1920 - mse: 697.3384\n",
      "Epoch 87/5000\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 667.2194 - mae: 17.5787 - mse: 667.2194\n",
      "Epoch 88/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 660.5080 - mae: 17.5697 - mse: 660.5080\n",
      "Epoch 89/5000\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 645.9067 - mae: 17.3544 - mse: 645.9067\n",
      "Epoch 90/5000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 644.0792 - mae: 17.4034 - mse: 644.0792\n",
      "Epoch 91/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 646.6738 - mae: 17.5515 - mse: 646.6738\n",
      "Epoch 92/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 613.3647 - mae: 16.9604 - mse: 613.3647\n",
      "Epoch 93/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 604.6022 - mae: 16.8499 - mse: 604.6022\n",
      "Epoch 94/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 595.1358 - mae: 16.7057 - mse: 595.1358\n",
      "Epoch 95/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 585.2791 - mae: 16.5887 - mse: 585.2791\n",
      "Epoch 96/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 589.7307 - mae: 16.8091 - mse: 589.7307\n",
      "Epoch 97/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 587.9499 - mae: 16.8215 - mse: 587.9499\n",
      "Epoch 98/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 565.4589 - mae: 16.4578 - mse: 565.4589\n",
      "Epoch 99/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 555.0811 - mae: 16.2725 - mse: 555.0811\n",
      "Epoch 100/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 540.8602 - mae: 16.0344 - mse: 540.8602\n",
      "Epoch 101/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 539.9358 - mae: 16.1401 - mse: 539.9358\n",
      "Epoch 102/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 520.5024 - mae: 15.7807 - mse: 520.5024\n",
      "Epoch 103/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 635.1263 - mae: 18.2560 - mse: 635.1263\n",
      "Epoch 104/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 591.4763 - mae: 17.5455 - mse: 591.4763\n",
      "Epoch 105/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 553.7025 - mae: 16.7300 - mse: 553.7025\n",
      "Epoch 106/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 535.9161 - mae: 16.3736 - mse: 535.9161\n",
      "Epoch 107/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 539.9393 - mae: 16.4342 - mse: 539.9393\n",
      "Epoch 108/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 508.6147 - mae: 16.0201 - mse: 508.6147\n",
      "Epoch 109/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 499.9196 - mae: 15.7361 - mse: 499.9196\n",
      "Epoch 110/5000\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 486.2112 - mae: 15.5463 - mse: 486.2112\n",
      "Epoch 111/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 477.0458 - mae: 15.3066 - mse: 477.0458\n",
      "Epoch 112/5000\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 472.0883 - mae: 15.2508 - mse: 472.0883\n",
      "Epoch 113/5000\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 461.3831 - mae: 15.0265 - mse: 461.3831\n",
      "Epoch 114/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 464.6209 - mae: 15.1798 - mse: 464.6209\n",
      "Epoch 115/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 453.3088 - mae: 14.9142 - mse: 453.3088\n",
      "Epoch 116/5000\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 451.6602 - mae: 14.8779 - mse: 451.6602\n",
      "Epoch 117/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 441.5789 - mae: 14.7223 - mse: 441.5789\n",
      "Epoch 118/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 438.4459 - mae: 14.5903 - mse: 438.4459\n",
      "Epoch 119/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 436.1908 - mae: 14.6680 - mse: 436.1908\n",
      "Epoch 120/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 424.8833 - mae: 14.4200 - mse: 424.8833\n",
      "Epoch 121/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 420.4561 - mae: 14.2479 - mse: 420.4561\n",
      "Epoch 122/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 416.7650 - mae: 14.2006 - mse: 416.7650\n",
      "Epoch 123/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 408.3759 - mae: 14.0837 - mse: 408.3759\n",
      "Epoch 124/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 410.8038 - mae: 14.1741 - mse: 410.8038\n",
      "Epoch 125/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 414.1251 - mae: 14.3525 - mse: 414.1251\n",
      "Epoch 126/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 405.2462 - mae: 14.0885 - mse: 405.2462\n",
      "Epoch 127/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 396.4362 - mae: 13.9214 - mse: 396.4362\n",
      "Epoch 128/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 394.5599 - mae: 13.8202 - mse: 394.5599\n",
      "Epoch 129/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 393.4822 - mae: 13.9558 - mse: 393.4822\n",
      "Epoch 130/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 396.8393 - mae: 14.0829 - mse: 396.8393\n",
      "Epoch 131/5000\n",
      "33/33 [==============================] - 1s 25ms/step - loss: 385.0420 - mae: 13.8037 - mse: 385.0420\n",
      "Epoch 132/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 384.9497 - mae: 13.8355 - mse: 384.9497\n",
      "Epoch 133/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 391.9591 - mae: 13.9301 - mse: 391.9591\n",
      "Epoch 134/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 380.9555 - mae: 13.6558 - mse: 380.9555\n",
      "Epoch 135/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 375.6129 - mae: 13.6000 - mse: 375.6129\n",
      "Epoch 136/5000\n",
      "33/33 [==============================] - 1s 27ms/step - loss: 368.7829 - mae: 13.4904 - mse: 368.7829\n",
      "Epoch 137/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 362.6631 - mae: 13.3102 - mse: 362.6631\n",
      "Epoch 138/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 353.8419 - mae: 13.1342 - mse: 353.8419\n",
      "Epoch 139/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 356.5495 - mae: 13.2038 - mse: 356.5495\n",
      "Epoch 140/5000\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 348.9164 - mae: 13.0152 - mse: 348.9164\n",
      "Epoch 141/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 346.7711 - mae: 12.9160 - mse: 346.7711\n",
      "Epoch 142/5000\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 353.5536 - mae: 13.0193 - mse: 353.5536\n",
      "Epoch 143/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 352.1667 - mae: 13.0909 - mse: 352.1667\n",
      "Epoch 144/5000\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 351.5283 - mae: 13.1436 - mse: 351.5283\n",
      "Epoch 145/5000\n",
      "33/33 [==============================] - 2s 53ms/step - loss: 340.6066 - mae: 12.9542 - mse: 340.6066\n",
      "Epoch 146/5000\n",
      "33/33 [==============================] - 2s 46ms/step - loss: 352.5750 - mae: 13.1947 - mse: 352.5750\n",
      "Epoch 147/5000\n",
      "33/33 [==============================] - 2s 47ms/step - loss: 336.7120 - mae: 12.7096 - mse: 336.7120\n",
      "Epoch 148/5000\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 325.7585 - mae: 12.5208 - mse: 325.7585\n",
      "Epoch 149/5000\n",
      "33/33 [==============================] - 2s 50ms/step - loss: 320.3271 - mae: 12.3463 - mse: 320.3271\n",
      "Epoch 150/5000\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 339.7778 - mae: 12.9213 - mse: 339.7778\n",
      "Epoch 151/5000\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 333.3114 - mae: 12.8226 - mse: 333.3114\n",
      "Epoch 152/5000\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 338.3064 - mae: 12.8429 - mse: 338.3064\n",
      "Epoch 153/5000\n",
      "33/33 [==============================] - 2s 47ms/step - loss: 329.3930 - mae: 12.6954 - mse: 329.3930\n",
      "Epoch 154/5000\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 318.6145 - mae: 12.3693 - mse: 318.6145\n",
      "Epoch 155/5000\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 329.7209 - mae: 12.7392 - mse: 329.7209\n",
      "Epoch 156/5000\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 360.2586 - mae: 13.2098 - mse: 360.2586\n",
      "Epoch 157/5000\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 324.0288 - mae: 12.5767 - mse: 324.0288\n",
      "Epoch 158/5000\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 329.9163 - mae: 12.7670 - mse: 329.9163\n",
      "Epoch 159/5000\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 308.7643 - mae: 12.1573 - mse: 308.7643\n",
      "Epoch 160/5000\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 309.9090 - mae: 12.1641 - mse: 309.9090\n",
      "Epoch 161/5000\n",
      "33/33 [==============================] - 2s 54ms/step - loss: 329.2123 - mae: 12.6400 - mse: 329.2123\n",
      "Epoch 162/5000\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 319.6447 - mae: 12.3812 - mse: 319.6447\n",
      "Epoch 163/5000\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 311.9695 - mae: 12.3223 - mse: 311.9695\n",
      "Epoch 164/5000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 302.6811 - mae: 12.1122 - mse: 302.6811\n",
      "Epoch 165/5000\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 302.5248 - mae: 12.0292 - mse: 302.5248\n",
      "Epoch 166/5000\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 295.6987 - mae: 12.0789 - mse: 295.6987\n",
      "Epoch 167/5000\n",
      "33/33 [==============================] - 2s 53ms/step - loss: 299.8069 - mae: 12.1599 - mse: 299.8069\n",
      "Epoch 168/5000\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 288.3035 - mae: 11.9408 - mse: 288.3035\n",
      "Epoch 169/5000\n",
      "33/33 [==============================] - 2s 50ms/step - loss: 286.1492 - mae: 11.8377 - mse: 286.1492\n",
      "Epoch 170/5000\n",
      "33/33 [==============================] - 2s 53ms/step - loss: 289.2209 - mae: 11.9314 - mse: 289.2209\n",
      "Epoch 171/5000\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 284.7837 - mae: 11.7233 - mse: 284.7837\n",
      "Epoch 172/5000\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 283.1111 - mae: 11.7897 - mse: 283.1111\n",
      "Epoch 173/5000\n",
      "33/33 [==============================] - 2s 51ms/step - loss: 289.5331 - mae: 11.8327 - mse: 289.5331\n",
      "Epoch 174/5000\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 285.0278 - mae: 11.8646 - mse: 285.0278\n",
      "Epoch 175/5000\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 286.6693 - mae: 11.9293 - mse: 286.6693\n",
      "Epoch 176/5000\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 283.3143 - mae: 11.7112 - mse: 283.3143\n",
      "Epoch 177/5000\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 276.6922 - mae: 11.7060 - mse: 276.6922\n",
      "Epoch 178/5000\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 269.0599 - mae: 11.5216 - mse: 269.0599\n",
      "Epoch 179/5000\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 275.2308 - mae: 11.6497 - mse: 275.2308\n",
      "Epoch 180/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 270.2670 - mae: 11.6746 - mse: 270.2670\n",
      "Epoch 181/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 281.8150 - mae: 11.8050 - mse: 281.8150\n",
      "Epoch 182/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 272.7620 - mae: 11.5988 - mse: 272.7620\n",
      "Epoch 183/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 264.9236 - mae: 11.4442 - mse: 264.9236\n",
      "Epoch 184/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 274.0049 - mae: 11.6069 - mse: 274.0049\n",
      "Epoch 185/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 283.0466 - mae: 11.8515 - mse: 283.0466\n",
      "Epoch 186/5000\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 268.2791 - mae: 11.5177 - mse: 268.2791\n",
      "Epoch 187/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 261.4487 - mae: 11.4386 - mse: 261.4487\n",
      "Epoch 188/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 258.0700 - mae: 11.3055 - mse: 258.0700\n",
      "Epoch 189/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 261.0481 - mae: 11.3089 - mse: 261.0481\n",
      "Epoch 190/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 256.2157 - mae: 11.2965 - mse: 256.2157\n",
      "Epoch 191/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 286.2803 - mae: 11.9467 - mse: 286.2803\n",
      "Epoch 192/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 258.1324 - mae: 11.2703 - mse: 258.1324\n",
      "Epoch 193/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 255.4245 - mae: 11.3677 - mse: 255.4245\n",
      "Epoch 194/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 255.9490 - mae: 11.2214 - mse: 255.9490\n",
      "Epoch 195/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 248.7245 - mae: 11.0126 - mse: 248.7245\n",
      "Epoch 196/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 256.9782 - mae: 11.2701 - mse: 256.9782\n",
      "Epoch 197/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 267.7390 - mae: 11.5553 - mse: 267.7390\n",
      "Epoch 198/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 256.1593 - mae: 11.3001 - mse: 256.1593\n",
      "Epoch 199/5000\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 260.1243 - mae: 11.3594 - mse: 260.1243\n",
      "Epoch 200/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 264.9119 - mae: 11.4657 - mse: 264.9119\n",
      "Epoch 201/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 253.3093 - mae: 11.2893 - mse: 253.3093\n",
      "Epoch 202/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 246.2149 - mae: 11.1094 - mse: 246.2149\n",
      "Epoch 203/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 253.0215 - mae: 11.2170 - mse: 253.0215\n",
      "Epoch 204/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 243.8298 - mae: 10.9861 - mse: 243.8298\n",
      "Epoch 205/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 255.2560 - mae: 11.3277 - mse: 255.2560\n",
      "Epoch 206/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 258.8158 - mae: 11.3006 - mse: 258.8158\n",
      "Epoch 207/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 263.1352 - mae: 11.2942 - mse: 263.1352\n",
      "Epoch 208/5000\n",
      "33/33 [==============================] - 1s 36ms/step - loss: 251.5771 - mae: 11.1006 - mse: 251.5771\n",
      "Epoch 209/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 249.9209 - mae: 11.1989 - mse: 249.9209\n",
      "Epoch 210/5000\n",
      "33/33 [==============================] - 1s 35ms/step - loss: 250.9494 - mae: 11.2857 - mse: 250.9494\n",
      "Epoch 211/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 238.6545 - mae: 10.9181 - mse: 238.6545\n",
      "Epoch 212/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 253.0288 - mae: 11.1915 - mse: 253.0288\n",
      "Epoch 213/5000\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 266.6996 - mae: 11.3348 - mse: 266.6996\n",
      "Epoch 214/5000\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 256.8407 - mae: 11.3411 - mse: 256.8407\n",
      "Epoch 215/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 240.0611 - mae: 10.8767 - mse: 240.0611\n",
      "Epoch 216/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 271.7269 - mae: 11.5179 - mse: 271.7269\n",
      "Epoch 217/5000\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 273.1066 - mae: 11.5295 - mse: 273.1066\n",
      "Epoch 218/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 243.5638 - mae: 11.0263 - mse: 243.5638\n",
      "Epoch 219/5000\n",
      "33/33 [==============================] - 1s 30ms/step - loss: 240.9481 - mae: 10.9466 - mse: 240.9481\n",
      "Epoch 220/5000\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 240.7291 - mae: 11.0096 - mse: 240.7291\n",
      "Epoch 221/5000\n",
      "33/33 [==============================] - 1s 29ms/step - loss: 251.0890 - mae: 11.1392 - mse: 251.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba01e17c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-8,\n",
    "    clipvalue=1.0\n",
    ")\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(inp_ts, t_ts, batch_size=batch_size, epochs=5000, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09aeb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(dataset)\n",
    "    return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7ff4911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 07:07:08.778941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1095]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-25 07:07:08.779401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1095]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-25 07:07:09.210925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:07:09.213078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:07:09.214794: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-25 07:07:09.540235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-25 07:07:09.544379: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-25 07:07:09.548652: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast = model_forecast(model, series, window_size, batch_size)\n",
    "results = forecast.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a576d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x800>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_handler.plot_all(\n",
    "    series_lines = [\n",
    "        (time_data[0:window_size+nforecast], series[0:window_size+nforecast]),\n",
    "        (time_data[window_size:window_size+nforecast], series[window_size:window_size+nforecast])\n",
    "    ],\n",
    "    series_points = [(time_data[window_size:window_size+nforecast], results[0]),],\n",
    "    labels_lines = [\"series\", \"window\"],\n",
    "    labels_points = [\"forecast\"],\n",
    "    xy_label = [\"Time\", \"Value\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6398e68e-a46d-4ee8-9c59-1f164bf759f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-921.6286 , -922.06055, -923.11835, -924.3282 , -924.42053,\n",
       "        -925.5126 , -926.62976, -927.813  , -928.36957, -929.7471 ,\n",
       "        -929.818  , -931.5019 , -931.9075 , -932.87415, -934.0895 ,\n",
       "        -933.885  , -934.72815, -936.39526, -937.5441 , -938.8192 ],\n",
       "       dtype=float32),\n",
       " array([-921.6286 , -922.06055, -923.11835, -924.32825, -924.4204 ,\n",
       "        -925.5126 , -926.62976, -927.813  , -928.3695 , -929.7471 ,\n",
       "        -929.818  , -931.5019 , -931.9075 , -932.8741 , -934.0895 ,\n",
       "        -933.885  , -934.72815, -936.39526, -937.5441 , -938.8192 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[-2], results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72559054-0188-4f66-b874-0c314037b86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x800>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_handler.plot_all(\n",
    "    series_lines = [\n",
    "        (time_data[-(window_size+nforecast):], series[-(window_size+nforecast):]),\n",
    "        (time_data[-(window_size+nforecast):-nforecast], series[-(window_size+nforecast):-nforecast])\n",
    "    ],\n",
    "    series_points = [(time_data[-nforecast:], results[-1]),],\n",
    "    labels_lines = [\"series\", \"window\"],\n",
    "    labels_points = [\"forecast\"],\n",
    "    xy_label = [\"Time\", \"Value\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11db7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_compra_comigo.data_handler import Visualizer\n",
    "\n",
    "visualizer = Visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9fd3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = visualizer.create_gif(\n",
    "    time_data=time_data[:365],\n",
    "    series=series[:365],\n",
    "    forecast=results[:365],\n",
    "    batch_size=batch_size,\n",
    "    window_size=window_size,\n",
    "    nforecast=nforecast,\n",
    "    gif_window=70\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3713c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[0].save('./tmp/k_nn.gif',\n",
    "             save_all = True, append_images = plots[1:100], \n",
    "             optimize = False, duration = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62e2a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488101"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "plots = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9d17b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = visualizer.create_gif(\n",
    "    time_data=time_data[-365:],\n",
    "    series=series[-365:],\n",
    "    forecast=results[-365:],\n",
    "    batch_size=batch_size,\n",
    "    window_size=window_size,\n",
    "    nforecast=nforecast,\n",
    "    gif_window=70\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54843fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[0].save('./tmp/k_nn_end.gif',\n",
    "             save_all = True, append_images = plots, \n",
    "             optimize = False, duration = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49cdf0",
   "metadata": {},
   "source": [
    "## Lessons\n",
    "Most promising approach, will need to see how to automate the selection of these hyperparameters (and make it robust in an application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff69eab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./time_series_forecaster/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"levelname\": \"INFO\", \"asctime\": \"2023-07-13 01:21:51,447\", \"filename\": \"tuner.py\", \"funcName\": \"__init__\", \"lineno\": 113, \"message\": \"Reloading Tuner from ./time_series_forecaster/tuner0.json\"}\n",
      "2023-07-13 01:21:51.455703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-13 01:21:51.455881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-13 01:21:51.503109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-13 01:21:51.503244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-13 01:21:52.120983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:52.121841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:52.122425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:52.194363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:52.218850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:52.219498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:52.220064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 01:21:52.330895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:52.331712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:52.332298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:52.408171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:52.433156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:52.433792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:52.434401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "{\"levelname\": \"INFO\", \"asctime\": \"2023-07-13 01:21:52,457\", \"filename\": \"tuner.py\", \"funcName\": \"search\", \"lineno\": 193, \"message\": \"Oracle triggered exit\"}\n",
      "2023-07-13 01:21:52.907796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:52.908683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:52.909303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:52.980903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:53.005285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.005901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.006475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 01:21:53.112950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.113714: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.114289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:53.189302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:53.213610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.214229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.214801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:53.268001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_59' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_59}}]]\n",
      "2023-07-13 01:21:53.268300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_46' with dtype double and shape [1017,20]\n",
      "\t [[{{node Placeholder/_46}}]]\n",
      "2023-07-13 01:21:53.422082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.423007: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.423645: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:53.500624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:53.528886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.529583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.530215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:53.634851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.635722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.636358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:53.713306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:53.739999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:53.740724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:53.741374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 01:21:54.003697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:54.235814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:54.414018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:54.414732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:54.415371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:54.494188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:54.522188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:54.522993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:54.523653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:54.628660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:54.629386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:54.630022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:54.707788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:54.735370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 01:21:54.736090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 01:21:54.736727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 01:21:54.998124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 01:21:55.231975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31/Unknown - 3s 11ms/step - loss: 1249864.2500 - mean_squared_error: 1249864.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 01:21:56.186439: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: Incompatible shapes: [25,20] vs. [3,20]\n",
      "\t [[{{node mean_squared_error/SquaredDifference}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2453486/2413807421.py\", line 16, in <module>\n      clf.fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py\", line 268, in fit\n      super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py\", line 88, in fit\n      history = super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/structured_data.py\", line 139, in fit\n      history = super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/auto_model.py\", line 292, in fit\n      history = self.tuner.search(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py\", line 220, in search\n      pipeline, model, history = self.final_fit(**copied_fit_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py\", line 270, in final_fit\n      model, history = utils.fit_with_adaptive_batch_size(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 88, in fit_with_adaptive_batch_size\n      history = run_with_adaptive_batch_size(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 101, in run_with_adaptive_batch_size\n      history = func(x=x, validation_data=validation_data, **fit_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 89, in <lambda>\n      batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nIncompatible shapes: [25,20] vs. [3,20]\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_16050]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m clf \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mTimeseriesForecaster(\n\u001b[1;32m      9\u001b[0m     lookback\u001b[38;5;241m=\u001b[39mlookback,\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     predict_from=predict_from,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train the TimeSeriesForecaster with train data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;43;03m#     validation_data=(inputs, targets),\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;43;03m#     batch_size=32,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Predict with the best model(includes original training data).\u001b[39;00m\n\u001b[1;32m     24\u001b[0m predictions \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py:268\u001b[0m, in \u001b[0;36mTimeseriesForecaster.fit\u001b[0;34m(self, x, y, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search for the best model and hyperparameters for the AutoModel.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m            [keras.Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py:88\u001b[0m, in \u001b[0;36mSupervisedTimeseriesDataPipeline.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     y_val \u001b[38;5;241m=\u001b[39m y_val[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookback \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n\u001b[1;32m     86\u001b[0m     validation_data \u001b[38;5;241m=\u001b[39m x_val, y_val\n\u001b[0;32m---> 88\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/tasks/structured_data.py:139\u001b[0m, in \u001b[0;36mBaseStructuredDataPipeline.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         validation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_from_csv(x_val, y_val)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_in_fit(x)\n\u001b[0;32m--> 139\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m validation_split:\n\u001b[1;32m    288\u001b[0m     dataset, validation_data \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39msplit_dataset(\n\u001b[1;32m    289\u001b[0m         dataset, validation_split\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 292\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py:220\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mset_fit_args(\u001b[38;5;241m0\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mcopied_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    219\u001b[0m     copied_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m--> 220\u001b[0m     pipeline, model, history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# TODO: Add return history functionality in Keras Tuner\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_models()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py:270\u001b[0m, in \u001b[0;36mAutoTuner.final_fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_best_model()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt(model, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_with_adaptive_batch_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline, model, history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/utils/utils.py:88\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m---> 88\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_with_adaptive_batch_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/utils/utils.py:101\u001b[0m, in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m batch_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mResourceExhaustedError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/utils/utils.py:89\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m     88\u001b[0m     history \u001b[38;5;241m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[0;32m---> 89\u001b[0m         batch_size, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2453486/2413807421.py\", line 16, in <module>\n      clf.fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py\", line 268, in fit\n      super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/time_series_forecaster.py\", line 88, in fit\n      history = super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/tasks/structured_data.py\", line 139, in fit\n      history = super().fit(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/auto_model.py\", line 292, in fit\n      history = self.tuner.search(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py\", line 220, in search\n      pipeline, model, history = self.final_fit(**copied_fit_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py\", line 270, in final_fit\n      model, history = utils.fit_with_adaptive_batch_size(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 88, in fit_with_adaptive_batch_size\n      history = run_with_adaptive_batch_size(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 101, in run_with_adaptive_batch_size\n      history = func(x=x, validation_data=validation_data, **fit_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/autokeras/utils/utils.py\", line 89, in <lambda>\n      batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/ffreis/.local/lib/python3.8/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nIncompatible shapes: [25,20] vs. [3,20]\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_16050]"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "\n",
    "predict_from = 1\n",
    "predict_until = nforecast\n",
    "lookback = window_size\n",
    "\n",
    "clf = ak.TimeseriesForecaster(\n",
    "    lookback=lookback,\n",
    "#     predict_from=predict_from,\n",
    "#     predict_until=predict_until,\n",
    "    max_trials=1,\n",
    "    objective=\"mse\",\n",
    ")\n",
    "# Train the TimeSeriesForecaster with train data\n",
    "clf.fit(\n",
    "    x=np.array(inputs),\n",
    "    y=np.array(targets),\n",
    "#     validation_data=(inputs, targets),\n",
    "#     batch_size=32,\n",
    "    epochs=1000,\n",
    ")\n",
    "# Predict with the best model(includes original training data).\n",
    "predictions = clf.predict(inputs)\n",
    "print(predictions.shape)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(predictions, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe26daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "\n",
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(100, window_size, 1)\n",
    "    y_train = np.random.rand(100, n_forecast, 1)\n",
    "    \n",
    "    # Initialize the time series regressor\n",
    "    input_node = ak.Input()\n",
    "    output_node = ak.TemporalConvBlock()(input_node)\n",
    "    output_node = ak.RegressionHead()(output_node)\n",
    "    regressor = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "    \n",
    "    # Search for the best model architecture\n",
    "    regressor.fit(X_train, y_train, epochs=10)\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ece18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(100, window_size, 1)\n",
    "    y_train = np.random.rand(100, n_forecast, 1)\n",
    "    \n",
    "    # Initialize the time series regressor\n",
    "    input_node = ak.Input()\n",
    "    output_node = ak.TCNBlock()(input_node)\n",
    "    output_node = ak.RegressionHead()(output_node)\n",
    "    regressor = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "    \n",
    "    # Search for the best model architecture\n",
    "    regressor.fit(X_train, y_train, epochs=10)\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(100, window_size, 1)\n",
    "    y_train = np.random.rand(100, n_forecast, 1)\n",
    "\n",
    "    # Initialize the time series forecaster\n",
    "    input_node = ak.Input()\n",
    "    output_node = ak.TimeseriesForecaster(output_dim=n_forecast)(input_node)\n",
    "    forecaster = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "\n",
    "    # Search for the best model architecture\n",
    "    forecaster.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723513c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install autokeras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f37b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(100, window_size, 1)\n",
    "    y_train = np.random.rand(100, n_forecast, 1)\n",
    "\n",
    "    # Initialize the time series forecaster\n",
    "    input_node = ak.Input()\n",
    "    output_node = ak.TimeseriesForecaster(block_type='dense', output_dim=n_forecast)(input_node)\n",
    "    forecaster = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "\n",
    "    # Search for the best model architecture\n",
    "    forecaster.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfa8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(100, window_size, 1)\n",
    "    y_train = np.random.rand(100, n_forecast, 1)\n",
    "\n",
    "    # Initialize the time series forecaster\n",
    "    input_node = ak.Input()\n",
    "    output_node = ak.AutoRegressor()(input_node)\n",
    "    forecaster = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "\n",
    "    # Search for the best model architecture\n",
    "    forecaster.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56d8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fa3e7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   46.38905809,    37.72480807,    61.36841567, ...,\n",
       "          -59.55122336,   -53.17773076,     4.52852933],\n",
       "       [  -69.79983062,   -10.49298299,   -25.06042815, ...,\n",
       "          -48.28977641,   -66.98967473,   -57.45410727],\n",
       "       [ -104.34262985,  -152.18642696,  -126.30070405, ...,\n",
       "         -163.76274733,  -172.1042314 ,  -149.0348571 ],\n",
       "       ...,\n",
       "       [-1465.02020035, -1491.09848926, -1427.77907774, ...,\n",
       "        -1504.29182392, -1521.07068844, -1504.03149251],\n",
       "       [-1244.60983883, -1270.1261529 , -1240.48107783, ...,\n",
       "        -1317.2535713 , -1307.15381528, -1313.97239863],\n",
       "       [-1735.04961371, -1678.60077067, -1637.572154  , ...,\n",
       "        -1748.89944507, -1770.95367832, -1784.05375528]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.array(inputs)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3aae189e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[   46.38905809],\n",
       "         [   37.72480807],\n",
       "         [   61.36841567],\n",
       "         ...,\n",
       "         [  -59.55122336],\n",
       "         [  -53.17773076],\n",
       "         [    4.52852933]],\n",
       " \n",
       "        [[  -69.79983062],\n",
       "         [  -10.49298299],\n",
       "         [  -25.06042815],\n",
       "         ...,\n",
       "         [  -48.28977641],\n",
       "         [  -66.98967473],\n",
       "         [  -57.45410727]],\n",
       " \n",
       "        [[ -104.34262985],\n",
       "         [ -152.18642696],\n",
       "         [ -126.30070405],\n",
       "         ...,\n",
       "         [ -163.76274733],\n",
       "         [ -172.1042314 ],\n",
       "         [ -149.0348571 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1465.02020035],\n",
       "         [-1491.09848926],\n",
       "         [-1427.77907774],\n",
       "         ...,\n",
       "         [-1504.29182392],\n",
       "         [-1521.07068844],\n",
       "         [-1504.03149251]],\n",
       " \n",
       "        [[-1244.60983883],\n",
       "         [-1270.1261529 ],\n",
       "         [-1240.48107783],\n",
       "         ...,\n",
       "         [-1317.2535713 ],\n",
       "         [-1307.15381528],\n",
       "         [-1313.97239863]],\n",
       " \n",
       "        [[-1735.04961371],\n",
       "         [-1678.60077067],\n",
       "         [-1637.572154  ],\n",
       "         ...,\n",
       "         [-1748.89944507],\n",
       "         [-1770.95367832],\n",
       "         [-1784.05375528]]]),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(\n",
    "            i, (-1,window_size, 1)\n",
    "        ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "006b4f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 14m 41s]\n",
      "val_loss: 794593.75\n",
      "\n",
      "Best val_loss So Far: 620760.5\n",
      "Total elapsed time: 00h 47m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"levelname\": \"INFO\", \"asctime\": \"2023-07-13 02:11:03,539\", \"filename\": \"tuner.py\", \"funcName\": \"search\", \"lineno\": 193, \"message\": \"Oracle triggered exit\"}\n",
      "2023-07-13 02:11:03.990539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:03.991395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:03.991992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.065484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:04.090556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.091191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.091796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.201575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.202363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.202961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.280410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:04.305406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.306041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.306632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:11:04.412879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.413709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.414302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.490202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:04.514937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.515587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.516177: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.554199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_29' with dtype double and shape [1046,30,1]\n",
      "\t [[{{node Placeholder/_29}}]]\n",
      "2023-07-13 02:11:04.554455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_34' with dtype double and shape [1046,20]\n",
      "\t [[{{node Placeholder/_34}}]]\n",
      "2023-07-13 02:11:04.664046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.664923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.665564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.741520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:04.768128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.768817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.769458: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.870570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.871464: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.872120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:04.950422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:04.977152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:04.977869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:04.978508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:11:05.082571: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:05.083421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:05.084072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:05.159672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:05.186185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:05.186885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:05.187539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:05.443916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:05.665106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:05.886681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:06.220835: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.221754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.222432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:06.296774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:06.323446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.324146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.324795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:06.427552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.428402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.429078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:06.509738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:06.536211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.536911: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.537538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:11:06.638587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.639440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.640075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:06.715437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:06.741901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:11:06.742593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:11:06.743240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:11:07.002828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:07.235720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:11:07.458211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 13ms/step - loss: 1439057.6250 - mean_squared_error: 1439057.6250\n",
      "Epoch 2/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1438916.5000 - mean_squared_error: 1438916.5000\n",
      "Epoch 3/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1438715.7500 - mean_squared_error: 1438715.7500\n",
      "Epoch 4/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1438419.7500 - mean_squared_error: 1438419.7500\n",
      "Epoch 5/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1438009.2500 - mean_squared_error: 1438009.2500\n",
      "Epoch 6/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1437452.2500 - mean_squared_error: 1437452.2500\n",
      "Epoch 7/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1436707.0000 - mean_squared_error: 1436707.0000\n",
      "Epoch 8/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1435782.5000 - mean_squared_error: 1435782.5000\n",
      "Epoch 9/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1434628.6250 - mean_squared_error: 1434628.6250\n",
      "Epoch 10/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1433439.8750 - mean_squared_error: 1433439.8750\n",
      "Epoch 11/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1431998.2500 - mean_squared_error: 1431998.1250\n",
      "Epoch 12/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1430492.1250 - mean_squared_error: 1430492.1250\n",
      "Epoch 13/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1429008.0000 - mean_squared_error: 1429008.0000\n",
      "Epoch 14/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1427420.5000 - mean_squared_error: 1427420.5000\n",
      "Epoch 15/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1425835.6250 - mean_squared_error: 1425835.6250\n",
      "Epoch 16/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1424255.5000 - mean_squared_error: 1424255.5000\n",
      "Epoch 17/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1422354.7500 - mean_squared_error: 1422354.7500\n",
      "Epoch 18/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1420901.0000 - mean_squared_error: 1420901.0000\n",
      "Epoch 19/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1419029.0000 - mean_squared_error: 1419029.0000\n",
      "Epoch 20/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1417465.7500 - mean_squared_error: 1417465.7500\n",
      "Epoch 21/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1415315.1250 - mean_squared_error: 1415315.1250\n",
      "Epoch 22/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1413651.1250 - mean_squared_error: 1413651.1250\n",
      "Epoch 23/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1411728.7500 - mean_squared_error: 1411728.7500\n",
      "Epoch 24/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1409617.1250 - mean_squared_error: 1409617.1250\n",
      "Epoch 25/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1407983.1250 - mean_squared_error: 1407983.1250\n",
      "Epoch 26/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1405771.8750 - mean_squared_error: 1405771.8750\n",
      "Epoch 27/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1403609.7500 - mean_squared_error: 1403609.7500\n",
      "Epoch 28/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1401441.2500 - mean_squared_error: 1401441.2500\n",
      "Epoch 29/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1399477.6250 - mean_squared_error: 1399477.6250\n",
      "Epoch 30/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1397601.1250 - mean_squared_error: 1397601.1250\n",
      "Epoch 31/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1395395.5000 - mean_squared_error: 1395395.5000\n",
      "Epoch 32/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1393550.8750 - mean_squared_error: 1393551.0000\n",
      "Epoch 33/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1391436.0000 - mean_squared_error: 1391436.0000\n",
      "Epoch 34/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1389542.2500 - mean_squared_error: 1389542.2500\n",
      "Epoch 35/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1387538.3750 - mean_squared_error: 1387538.2500\n",
      "Epoch 36/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1385658.3750 - mean_squared_error: 1385658.3750\n",
      "Epoch 37/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1384208.8750 - mean_squared_error: 1384208.8750\n",
      "Epoch 38/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1382061.2500 - mean_squared_error: 1382061.2500\n",
      "Epoch 39/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1380586.1250 - mean_squared_error: 1380586.1250\n",
      "Epoch 40/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1378470.8750 - mean_squared_error: 1378470.8750\n",
      "Epoch 41/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1376902.3750 - mean_squared_error: 1376902.5000\n",
      "Epoch 42/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1375214.3750 - mean_squared_error: 1375214.3750\n",
      "Epoch 43/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1373528.6250 - mean_squared_error: 1373528.6250\n",
      "Epoch 44/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1371569.2500 - mean_squared_error: 1371569.2500\n",
      "Epoch 45/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1369438.7500 - mean_squared_error: 1369438.7500\n",
      "Epoch 46/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1368792.3750 - mean_squared_error: 1368792.3750\n",
      "Epoch 47/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1367065.6250 - mean_squared_error: 1367065.6250\n",
      "Epoch 48/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1365181.3750 - mean_squared_error: 1365181.3750\n",
      "Epoch 49/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1363355.3750 - mean_squared_error: 1363355.3750\n",
      "Epoch 50/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1362330.0000 - mean_squared_error: 1362330.0000\n",
      "Epoch 51/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1359502.6250 - mean_squared_error: 1359502.6250\n",
      "Epoch 52/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1358279.1250 - mean_squared_error: 1358279.2500\n",
      "Epoch 53/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1357044.5000 - mean_squared_error: 1357044.5000\n",
      "Epoch 54/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1355306.8750 - mean_squared_error: 1355306.8750\n",
      "Epoch 55/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1354091.6250 - mean_squared_error: 1354091.6250\n",
      "Epoch 56/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1352618.3750 - mean_squared_error: 1352618.3750\n",
      "Epoch 57/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1351666.0000 - mean_squared_error: 1351666.0000\n",
      "Epoch 58/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1349744.6250 - mean_squared_error: 1349744.6250\n",
      "Epoch 59/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1347627.5000 - mean_squared_error: 1347627.5000\n",
      "Epoch 60/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1346291.8750 - mean_squared_error: 1346291.8750\n",
      "Epoch 61/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1345040.6250 - mean_squared_error: 1345040.6250\n",
      "Epoch 62/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1344220.0000 - mean_squared_error: 1344220.1250\n",
      "Epoch 63/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1342072.5000 - mean_squared_error: 1342072.5000\n",
      "Epoch 64/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1340453.7500 - mean_squared_error: 1340453.7500\n",
      "Epoch 65/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1339278.8750 - mean_squared_error: 1339278.8750\n",
      "Epoch 66/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1337321.2500 - mean_squared_error: 1337321.3750\n",
      "Epoch 67/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1336799.0000 - mean_squared_error: 1336799.0000\n",
      "Epoch 68/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1335063.0000 - mean_squared_error: 1335063.0000\n",
      "Epoch 69/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1333481.2500 - mean_squared_error: 1333481.2500\n",
      "Epoch 70/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1331321.5000 - mean_squared_error: 1331321.5000\n",
      "Epoch 71/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1329920.5000 - mean_squared_error: 1329920.5000\n",
      "Epoch 72/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1328059.7500 - mean_squared_error: 1328059.7500\n",
      "Epoch 73/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1327570.8750 - mean_squared_error: 1327570.8750\n",
      "Epoch 74/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1325896.0000 - mean_squared_error: 1325896.0000\n",
      "Epoch 75/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1324898.7500 - mean_squared_error: 1324898.7500\n",
      "Epoch 76/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1324177.5000 - mean_squared_error: 1324177.5000\n",
      "Epoch 77/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1322514.8750 - mean_squared_error: 1322514.8750\n",
      "Epoch 78/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1320936.2500 - mean_squared_error: 1320936.2500\n",
      "Epoch 79/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1319145.3750 - mean_squared_error: 1319145.3750\n",
      "Epoch 80/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1317353.2500 - mean_squared_error: 1317353.2500\n",
      "Epoch 81/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1316433.3750 - mean_squared_error: 1316433.3750\n",
      "Epoch 82/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1315336.6250 - mean_squared_error: 1315336.6250\n",
      "Epoch 83/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1313559.8750 - mean_squared_error: 1313559.8750\n",
      "Epoch 84/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1312457.0000 - mean_squared_error: 1312457.0000\n",
      "Epoch 85/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1311328.1250 - mean_squared_error: 1311328.1250\n",
      "Epoch 86/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1309604.8750 - mean_squared_error: 1309604.8750\n",
      "Epoch 87/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1308535.0000 - mean_squared_error: 1308535.1250\n",
      "Epoch 88/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1307404.2500 - mean_squared_error: 1307404.2500\n",
      "Epoch 89/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1306806.0000 - mean_squared_error: 1306806.0000\n",
      "Epoch 90/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1304318.0000 - mean_squared_error: 1304318.0000\n",
      "Epoch 91/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1303251.2500 - mean_squared_error: 1303251.2500\n",
      "Epoch 92/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1301155.7500 - mean_squared_error: 1301155.6250\n",
      "Epoch 93/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1300634.1250 - mean_squared_error: 1300634.1250\n",
      "Epoch 94/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1299528.3750 - mean_squared_error: 1299528.3750\n",
      "Epoch 95/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1298429.7500 - mean_squared_error: 1298429.7500\n",
      "Epoch 96/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1297175.2500 - mean_squared_error: 1297175.2500\n",
      "Epoch 97/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294864.2500 - mean_squared_error: 1294864.2500\n",
      "Epoch 98/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1294175.7500 - mean_squared_error: 1294175.7500\n",
      "Epoch 99/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1292893.2500 - mean_squared_error: 1292893.2500\n",
      "Epoch 100/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1291064.5000 - mean_squared_error: 1291064.5000\n",
      "Epoch 101/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1289968.6250 - mean_squared_error: 1289968.6250\n",
      "Epoch 102/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1289982.0000 - mean_squared_error: 1289982.0000\n",
      "Epoch 103/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1287772.6250 - mean_squared_error: 1287772.6250\n",
      "Epoch 104/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1286924.7500 - mean_squared_error: 1286924.7500\n",
      "Epoch 105/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1285311.1250 - mean_squared_error: 1285311.1250\n",
      "Epoch 106/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1283807.1250 - mean_squared_error: 1283807.1250\n",
      "Epoch 107/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1282510.3750 - mean_squared_error: 1282510.3750\n",
      "Epoch 108/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1280432.0000 - mean_squared_error: 1280432.0000\n",
      "Epoch 109/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1279589.1250 - mean_squared_error: 1279589.1250\n",
      "Epoch 110/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1278923.6250 - mean_squared_error: 1278923.6250\n",
      "Epoch 111/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1278507.6250 - mean_squared_error: 1278507.6250\n",
      "Epoch 112/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1277130.3750 - mean_squared_error: 1277130.3750\n",
      "Epoch 113/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1275638.1250 - mean_squared_error: 1275638.1250\n",
      "Epoch 114/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1275144.2500 - mean_squared_error: 1275144.2500\n",
      "Epoch 115/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1273364.7500 - mean_squared_error: 1273364.7500\n",
      "Epoch 116/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1272220.0000 - mean_squared_error: 1272220.0000\n",
      "Epoch 117/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1270090.1250 - mean_squared_error: 1270090.1250\n",
      "Epoch 118/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1269064.1250 - mean_squared_error: 1269064.1250\n",
      "Epoch 119/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1267804.2500 - mean_squared_error: 1267804.2500\n",
      "Epoch 120/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1267166.2500 - mean_squared_error: 1267166.2500\n",
      "Epoch 121/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1265783.2500 - mean_squared_error: 1265783.2500\n",
      "Epoch 122/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1264458.6250 - mean_squared_error: 1264458.6250\n",
      "Epoch 123/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1262933.1250 - mean_squared_error: 1262933.2500\n",
      "Epoch 124/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1260607.7500 - mean_squared_error: 1260607.7500\n",
      "Epoch 125/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1261315.1250 - mean_squared_error: 1261315.1250\n",
      "Epoch 126/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1260939.5000 - mean_squared_error: 1260939.5000\n",
      "Epoch 127/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1257579.6250 - mean_squared_error: 1257579.6250\n",
      "Epoch 128/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1257155.7500 - mean_squared_error: 1257155.7500\n",
      "Epoch 129/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1254846.6250 - mean_squared_error: 1254846.6250\n",
      "Epoch 130/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1256667.1250 - mean_squared_error: 1256667.1250\n",
      "Epoch 131/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1254025.6250 - mean_squared_error: 1254025.6250\n",
      "Epoch 132/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 1254070.8750 - mean_squared_error: 1254070.8750\n",
      "Epoch 133/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1251193.7500 - mean_squared_error: 1251193.7500\n",
      "Epoch 134/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1250048.7500 - mean_squared_error: 1250048.7500\n",
      "Epoch 135/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1249243.0000 - mean_squared_error: 1249243.0000\n",
      "Epoch 136/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1248215.7500 - mean_squared_error: 1248215.7500\n",
      "Epoch 137/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1246990.0000 - mean_squared_error: 1246990.0000\n",
      "Epoch 138/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1247106.2500 - mean_squared_error: 1247106.2500\n",
      "Epoch 139/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1241794.8750 - mean_squared_error: 1241794.8750\n",
      "Epoch 140/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1243361.1250 - mean_squared_error: 1243361.1250\n",
      "Epoch 141/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1242968.2500 - mean_squared_error: 1242968.2500\n",
      "Epoch 142/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1240133.2500 - mean_squared_error: 1240133.2500\n",
      "Epoch 143/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1241495.7500 - mean_squared_error: 1241495.8750\n",
      "Epoch 144/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1239110.6250 - mean_squared_error: 1239110.5000\n",
      "Epoch 145/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1238098.7500 - mean_squared_error: 1238098.7500\n",
      "Epoch 146/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1236991.3750 - mean_squared_error: 1236991.3750\n",
      "Epoch 147/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1234506.1250 - mean_squared_error: 1234506.1250\n",
      "Epoch 148/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1233388.0000 - mean_squared_error: 1233388.0000\n",
      "Epoch 149/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1232291.6250 - mean_squared_error: 1232291.6250\n",
      "Epoch 150/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1233465.7500 - mean_squared_error: 1233465.7500\n",
      "Epoch 151/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1230910.6250 - mean_squared_error: 1230910.6250\n",
      "Epoch 152/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1230514.0000 - mean_squared_error: 1230514.0000\n",
      "Epoch 153/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1230264.2500 - mean_squared_error: 1230264.1250\n",
      "Epoch 154/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1228511.3750 - mean_squared_error: 1228511.3750\n",
      "Epoch 155/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1227049.0000 - mean_squared_error: 1227049.0000\n",
      "Epoch 156/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1225040.7500 - mean_squared_error: 1225040.7500\n",
      "Epoch 157/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1224448.7500 - mean_squared_error: 1224448.7500\n",
      "Epoch 158/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1223083.2500 - mean_squared_error: 1223083.2500\n",
      "Epoch 159/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1220874.8750 - mean_squared_error: 1220874.7500\n",
      "Epoch 160/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1222191.7500 - mean_squared_error: 1222191.7500\n",
      "Epoch 161/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1218424.7500 - mean_squared_error: 1218424.7500\n",
      "Epoch 162/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1220270.2500 - mean_squared_error: 1220270.2500\n",
      "Epoch 163/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1217104.8750 - mean_squared_error: 1217104.8750\n",
      "Epoch 164/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1215829.1250 - mean_squared_error: 1215829.1250\n",
      "Epoch 165/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1216352.0000 - mean_squared_error: 1216352.0000\n",
      "Epoch 166/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1214782.1250 - mean_squared_error: 1214782.1250\n",
      "Epoch 167/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1212454.3750 - mean_squared_error: 1212454.3750\n",
      "Epoch 168/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1211754.5000 - mean_squared_error: 1211754.5000\n",
      "Epoch 169/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1213111.5000 - mean_squared_error: 1213111.5000\n",
      "Epoch 170/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1209234.1250 - mean_squared_error: 1209234.1250\n",
      "Epoch 171/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1209216.7500 - mean_squared_error: 1209216.7500\n",
      "Epoch 172/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1207912.7500 - mean_squared_error: 1207912.7500\n",
      "Epoch 173/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1206419.3750 - mean_squared_error: 1206419.3750\n",
      "Epoch 174/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1204507.3750 - mean_squared_error: 1204507.2500\n",
      "Epoch 175/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1204750.7500 - mean_squared_error: 1204750.7500\n",
      "Epoch 176/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1203436.6250 - mean_squared_error: 1203436.6250\n",
      "Epoch 177/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1203774.6250 - mean_squared_error: 1203774.6250\n",
      "Epoch 178/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1200396.8750 - mean_squared_error: 1200396.8750\n",
      "Epoch 179/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1200494.3750 - mean_squared_error: 1200494.3750\n",
      "Epoch 180/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1197784.5000 - mean_squared_error: 1197784.5000\n",
      "Epoch 181/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1197956.6250 - mean_squared_error: 1197956.6250\n",
      "Epoch 182/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1196680.8750 - mean_squared_error: 1196680.8750\n",
      "Epoch 183/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1197442.8750 - mean_squared_error: 1197442.7500\n",
      "Epoch 184/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1194307.8750 - mean_squared_error: 1194307.8750\n",
      "Epoch 185/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1192904.1250 - mean_squared_error: 1192904.1250\n",
      "Epoch 186/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1191864.0000 - mean_squared_error: 1191864.0000\n",
      "Epoch 187/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1191478.0000 - mean_squared_error: 1191478.0000\n",
      "Epoch 188/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1189255.1250 - mean_squared_error: 1189255.1250\n",
      "Epoch 189/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1189131.7500 - mean_squared_error: 1189131.7500\n",
      "Epoch 190/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1187764.3750 - mean_squared_error: 1187764.3750\n",
      "Epoch 191/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1184814.0000 - mean_squared_error: 1184814.0000\n",
      "Epoch 192/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1184163.7500 - mean_squared_error: 1184163.7500\n",
      "Epoch 193/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1184541.2500 - mean_squared_error: 1184541.2500\n",
      "Epoch 194/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1185050.0000 - mean_squared_error: 1185050.0000\n",
      "Epoch 195/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1181611.1250 - mean_squared_error: 1181611.1250\n",
      "Epoch 196/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1182557.2500 - mean_squared_error: 1182557.2500\n",
      "Epoch 197/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1179667.1250 - mean_squared_error: 1179667.1250\n",
      "Epoch 198/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1180083.3750 - mean_squared_error: 1180083.3750\n",
      "Epoch 199/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1176174.0000 - mean_squared_error: 1176174.0000\n",
      "Epoch 200/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1177924.0000 - mean_squared_error: 1177923.8750\n",
      "Epoch 201/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1178144.2500 - mean_squared_error: 1178144.2500\n",
      "Epoch 202/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1176705.7500 - mean_squared_error: 1176705.7500\n",
      "Epoch 203/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1176767.7500 - mean_squared_error: 1176767.7500\n",
      "Epoch 204/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1173376.7500 - mean_squared_error: 1173376.7500\n",
      "Epoch 205/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1172971.7500 - mean_squared_error: 1172971.7500\n",
      "Epoch 206/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1170237.5000 - mean_squared_error: 1170237.5000\n",
      "Epoch 207/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1170280.7500 - mean_squared_error: 1170280.7500\n",
      "Epoch 208/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1168278.5000 - mean_squared_error: 1168278.5000\n",
      "Epoch 209/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1166473.1250 - mean_squared_error: 1166473.1250\n",
      "Epoch 210/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1166886.7500 - mean_squared_error: 1166886.6250\n",
      "Epoch 211/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1167980.2500 - mean_squared_error: 1167980.2500\n",
      "Epoch 212/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1165423.1250 - mean_squared_error: 1165423.1250\n",
      "Epoch 213/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1165222.1250 - mean_squared_error: 1165222.1250\n",
      "Epoch 214/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1165834.7500 - mean_squared_error: 1165834.7500\n",
      "Epoch 215/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1160376.8750 - mean_squared_error: 1160376.8750\n",
      "Epoch 216/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1161689.5000 - mean_squared_error: 1161689.5000\n",
      "Epoch 217/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1160139.6250 - mean_squared_error: 1160139.6250\n",
      "Epoch 218/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1159864.2500 - mean_squared_error: 1159864.2500\n",
      "Epoch 219/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1157837.1250 - mean_squared_error: 1157837.1250\n",
      "Epoch 220/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1156383.3750 - mean_squared_error: 1156383.3750\n",
      "Epoch 221/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1157153.3750 - mean_squared_error: 1157153.3750\n",
      "Epoch 222/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1152258.6250 - mean_squared_error: 1152258.6250\n",
      "Epoch 223/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1155189.0000 - mean_squared_error: 1155189.0000\n",
      "Epoch 224/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1153536.6250 - mean_squared_error: 1153536.6250\n",
      "Epoch 225/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1152704.1250 - mean_squared_error: 1152704.1250\n",
      "Epoch 226/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1152312.8750 - mean_squared_error: 1152312.8750\n",
      "Epoch 227/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1148526.6250 - mean_squared_error: 1148526.6250\n",
      "Epoch 228/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1149709.5000 - mean_squared_error: 1149709.5000\n",
      "Epoch 229/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1147255.0000 - mean_squared_error: 1147255.0000\n",
      "Epoch 230/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1144466.7500 - mean_squared_error: 1144466.7500\n",
      "Epoch 231/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1147741.0000 - mean_squared_error: 1147741.0000\n",
      "Epoch 232/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1143543.5000 - mean_squared_error: 1143543.5000\n",
      "Epoch 233/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1144698.1250 - mean_squared_error: 1144698.1250\n",
      "Epoch 234/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1141462.7500 - mean_squared_error: 1141462.7500\n",
      "Epoch 235/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1141905.8750 - mean_squared_error: 1141905.8750\n",
      "Epoch 236/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1140880.1250 - mean_squared_error: 1140880.1250\n",
      "Epoch 237/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1140405.2500 - mean_squared_error: 1140405.2500\n",
      "Epoch 238/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1140858.8750 - mean_squared_error: 1140858.8750\n",
      "Epoch 239/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1137413.5000 - mean_squared_error: 1137413.5000\n",
      "Epoch 240/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1136213.0000 - mean_squared_error: 1136213.0000\n",
      "Epoch 241/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1136918.0000 - mean_squared_error: 1136918.0000\n",
      "Epoch 242/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1133859.5000 - mean_squared_error: 1133859.5000\n",
      "Epoch 243/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1134521.5000 - mean_squared_error: 1134521.5000\n",
      "Epoch 244/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1133493.2500 - mean_squared_error: 1133493.2500\n",
      "Epoch 245/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1131588.0000 - mean_squared_error: 1131588.0000\n",
      "Epoch 246/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1132026.8750 - mean_squared_error: 1132026.8750\n",
      "Epoch 247/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1130038.7500 - mean_squared_error: 1130038.7500\n",
      "Epoch 248/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1129312.0000 - mean_squared_error: 1129312.0000\n",
      "Epoch 249/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1129887.7500 - mean_squared_error: 1129887.7500\n",
      "Epoch 250/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1128769.1250 - mean_squared_error: 1128769.2500\n",
      "Epoch 251/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1124046.1250 - mean_squared_error: 1124046.1250\n",
      "Epoch 252/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1123597.8750 - mean_squared_error: 1123597.8750\n",
      "Epoch 253/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1123721.3750 - mean_squared_error: 1123721.3750\n",
      "Epoch 254/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1122170.1250 - mean_squared_error: 1122170.1250\n",
      "Epoch 255/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1120424.2500 - mean_squared_error: 1120424.2500\n",
      "Epoch 256/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1121157.1250 - mean_squared_error: 1121157.1250\n",
      "Epoch 257/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1118548.7500 - mean_squared_error: 1118548.7500\n",
      "Epoch 258/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1117697.1250 - mean_squared_error: 1117697.1250\n",
      "Epoch 259/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1117650.6250 - mean_squared_error: 1117650.6250\n",
      "Epoch 260/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1117616.1250 - mean_squared_error: 1117616.1250\n",
      "Epoch 261/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1115878.7500 - mean_squared_error: 1115878.8750\n",
      "Epoch 262/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1115657.5000 - mean_squared_error: 1115657.5000\n",
      "Epoch 263/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1113781.6250 - mean_squared_error: 1113781.6250\n",
      "Epoch 264/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1113186.5000 - mean_squared_error: 1113186.5000\n",
      "Epoch 265/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1110772.6250 - mean_squared_error: 1110772.6250\n",
      "Epoch 266/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1111198.0000 - mean_squared_error: 1111198.0000\n",
      "Epoch 267/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1109767.3750 - mean_squared_error: 1109767.3750\n",
      "Epoch 268/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1110116.3750 - mean_squared_error: 1110116.3750\n",
      "Epoch 269/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1105253.8750 - mean_squared_error: 1105253.8750\n",
      "Epoch 270/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1104555.3750 - mean_squared_error: 1104555.3750\n",
      "Epoch 271/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1106391.3750 - mean_squared_error: 1106391.3750\n",
      "Epoch 272/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1102605.8750 - mean_squared_error: 1102605.8750\n",
      "Epoch 273/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1104775.1250 - mean_squared_error: 1104775.1250\n",
      "Epoch 274/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1101728.2500 - mean_squared_error: 1101728.2500\n",
      "Epoch 275/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1102394.1250 - mean_squared_error: 1102394.1250\n",
      "Epoch 276/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1101265.6250 - mean_squared_error: 1101265.6250\n",
      "Epoch 277/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1099529.3750 - mean_squared_error: 1099529.3750\n",
      "Epoch 278/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1100459.1250 - mean_squared_error: 1100459.1250\n",
      "Epoch 279/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1099208.0000 - mean_squared_error: 1099208.0000\n",
      "Epoch 280/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1097640.2500 - mean_squared_error: 1097640.2500\n",
      "Epoch 281/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1095885.2500 - mean_squared_error: 1095885.2500\n",
      "Epoch 282/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1093709.3750 - mean_squared_error: 1093709.3750\n",
      "Epoch 283/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1095997.0000 - mean_squared_error: 1095997.0000\n",
      "Epoch 284/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1095071.3750 - mean_squared_error: 1095071.3750\n",
      "Epoch 285/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1093527.3750 - mean_squared_error: 1093527.3750\n",
      "Epoch 286/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1092262.3750 - mean_squared_error: 1092262.3750\n",
      "Epoch 287/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1091686.6250 - mean_squared_error: 1091686.6250\n",
      "Epoch 288/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1086899.7500 - mean_squared_error: 1086899.7500\n",
      "Epoch 289/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1087774.7500 - mean_squared_error: 1087774.7500\n",
      "Epoch 290/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1086539.3750 - mean_squared_error: 1086539.3750\n",
      "Epoch 291/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1087175.6250 - mean_squared_error: 1087175.5000\n",
      "Epoch 292/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1084879.0000 - mean_squared_error: 1084879.0000\n",
      "Epoch 293/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1085108.7500 - mean_squared_error: 1085108.7500\n",
      "Epoch 294/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1084887.1250 - mean_squared_error: 1084887.1250\n",
      "Epoch 295/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1082074.2500 - mean_squared_error: 1082074.2500\n",
      "Epoch 296/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1084912.0000 - mean_squared_error: 1084912.0000\n",
      "Epoch 297/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1081622.7500 - mean_squared_error: 1081622.7500\n",
      "Epoch 298/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1080790.8750 - mean_squared_error: 1080790.8750\n",
      "Epoch 299/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1079747.7500 - mean_squared_error: 1079747.7500\n",
      "Epoch 300/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1078619.7500 - mean_squared_error: 1078619.7500\n",
      "Epoch 301/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1077221.5000 - mean_squared_error: 1077221.5000\n",
      "Epoch 302/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1074269.5000 - mean_squared_error: 1074269.5000\n",
      "Epoch 303/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1074908.0000 - mean_squared_error: 1074908.0000\n",
      "Epoch 304/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1073258.6250 - mean_squared_error: 1073258.6250\n",
      "Epoch 305/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1074224.0000 - mean_squared_error: 1074224.0000\n",
      "Epoch 306/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1074270.0000 - mean_squared_error: 1074270.0000\n",
      "Epoch 307/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1072729.7500 - mean_squared_error: 1072729.7500\n",
      "Epoch 308/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1069290.0000 - mean_squared_error: 1069290.0000\n",
      "Epoch 309/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1069034.1250 - mean_squared_error: 1069034.1250\n",
      "Epoch 310/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1065500.5000 - mean_squared_error: 1065500.5000\n",
      "Epoch 311/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1066258.7500 - mean_squared_error: 1066258.7500\n",
      "Epoch 312/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1063249.0000 - mean_squared_error: 1063249.0000\n",
      "Epoch 313/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1067941.7500 - mean_squared_error: 1067941.7500\n",
      "Epoch 314/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1063551.8750 - mean_squared_error: 1063551.8750\n",
      "Epoch 315/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1065651.6250 - mean_squared_error: 1065651.6250\n",
      "Epoch 316/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1064410.5000 - mean_squared_error: 1064410.5000\n",
      "Epoch 317/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1061004.6250 - mean_squared_error: 1061004.6250\n",
      "Epoch 318/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1060902.7500 - mean_squared_error: 1060902.8750\n",
      "Epoch 319/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1060523.0000 - mean_squared_error: 1060523.0000\n",
      "Epoch 320/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1059662.5000 - mean_squared_error: 1059662.5000\n",
      "Epoch 321/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1059682.8750 - mean_squared_error: 1059682.8750\n",
      "Epoch 322/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1058758.6250 - mean_squared_error: 1058758.6250\n",
      "Epoch 323/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1059425.2500 - mean_squared_error: 1059425.2500\n",
      "Epoch 324/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1057376.1250 - mean_squared_error: 1057376.1250\n",
      "Epoch 325/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1054708.1250 - mean_squared_error: 1054708.1250\n",
      "Epoch 326/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1051718.0000 - mean_squared_error: 1051718.2500\n",
      "Epoch 327/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1050943.1250 - mean_squared_error: 1050943.1250\n",
      "Epoch 328/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1054007.0000 - mean_squared_error: 1054007.0000\n",
      "Epoch 329/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1049822.1250 - mean_squared_error: 1049822.1250\n",
      "Epoch 330/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1050952.7500 - mean_squared_error: 1050952.7500\n",
      "Epoch 331/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1050860.3750 - mean_squared_error: 1050860.3750\n",
      "Epoch 332/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1048478.2500 - mean_squared_error: 1048478.1250\n",
      "Epoch 333/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1046601.6875 - mean_squared_error: 1046601.6875\n",
      "Epoch 334/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1042318.0625 - mean_squared_error: 1042318.0625\n",
      "Epoch 335/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1045642.2500 - mean_squared_error: 1045642.2500\n",
      "Epoch 336/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1045207.8750 - mean_squared_error: 1045207.8750\n",
      "Epoch 337/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1043047.7500 - mean_squared_error: 1043047.7500\n",
      "Epoch 338/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1039821.4375 - mean_squared_error: 1039821.4375\n",
      "Epoch 339/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1042963.3125 - mean_squared_error: 1042963.3125\n",
      "Epoch 340/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1043916.7500 - mean_squared_error: 1043916.7500\n",
      "Epoch 341/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1041725.1875 - mean_squared_error: 1041725.1875\n",
      "Epoch 342/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1041471.0000 - mean_squared_error: 1041471.0000\n",
      "Epoch 343/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1039518.8125 - mean_squared_error: 1039518.8125\n",
      "Epoch 344/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1037754.1250 - mean_squared_error: 1037754.1250\n",
      "Epoch 345/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1036215.0625 - mean_squared_error: 1036215.0625\n",
      "Epoch 346/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1034464.8125 - mean_squared_error: 1034464.8125\n",
      "Epoch 347/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1033372.7500 - mean_squared_error: 1033372.7500\n",
      "Epoch 348/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1031322.6875 - mean_squared_error: 1031322.6875\n",
      "Epoch 349/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1034924.0625 - mean_squared_error: 1034924.0625\n",
      "Epoch 350/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1033668.3750 - mean_squared_error: 1033668.3750\n",
      "Epoch 351/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1030109.6250 - mean_squared_error: 1030109.6250\n",
      "Epoch 352/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1028429.5625 - mean_squared_error: 1028429.5625\n",
      "Epoch 353/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1029708.5000 - mean_squared_error: 1029708.5000\n",
      "Epoch 354/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1027670.8750 - mean_squared_error: 1027670.8750\n",
      "Epoch 355/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1029414.3125 - mean_squared_error: 1029414.3125\n",
      "Epoch 356/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1024847.1875 - mean_squared_error: 1024847.1875\n",
      "Epoch 357/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1025679.6250 - mean_squared_error: 1025679.6250\n",
      "Epoch 358/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1023168.6875 - mean_squared_error: 1023168.6875\n",
      "Epoch 359/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1021679.3750 - mean_squared_error: 1021679.3750\n",
      "Epoch 360/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1022226.3750 - mean_squared_error: 1022226.3750\n",
      "Epoch 361/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1024569.3750 - mean_squared_error: 1024569.3750\n",
      "Epoch 362/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1018381.5000 - mean_squared_error: 1018381.5000\n",
      "Epoch 363/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1019855.4375 - mean_squared_error: 1019855.4375\n",
      "Epoch 364/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1017347.0625 - mean_squared_error: 1017347.0625\n",
      "Epoch 365/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1019789.7500 - mean_squared_error: 1019789.7500\n",
      "Epoch 366/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1016989.6875 - mean_squared_error: 1016989.7500\n",
      "Epoch 367/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1017153.9375 - mean_squared_error: 1017153.9375\n",
      "Epoch 368/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1016170.6875 - mean_squared_error: 1016170.6875\n",
      "Epoch 369/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1015600.5625 - mean_squared_error: 1015600.5625\n",
      "Epoch 370/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1012510.6250 - mean_squared_error: 1012510.6250\n",
      "Epoch 371/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1011434.6250 - mean_squared_error: 1011434.6875\n",
      "Epoch 372/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1011760.5000 - mean_squared_error: 1011760.5625\n",
      "Epoch 373/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1012852.5000 - mean_squared_error: 1012852.5000\n",
      "Epoch 374/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1011957.0000 - mean_squared_error: 1011957.0000\n",
      "Epoch 375/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1008727.3125 - mean_squared_error: 1008727.3125\n",
      "Epoch 376/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1009580.6875 - mean_squared_error: 1009580.6875\n",
      "Epoch 377/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1005961.0625 - mean_squared_error: 1005961.0625\n",
      "Epoch 378/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1010633.1875 - mean_squared_error: 1010633.1875\n",
      "Epoch 379/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1005181.0625 - mean_squared_error: 1005181.0000\n",
      "Epoch 380/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1005784.1250 - mean_squared_error: 1005784.1250\n",
      "Epoch 381/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1002065.6250 - mean_squared_error: 1002065.6250\n",
      "Epoch 382/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1002530.3750 - mean_squared_error: 1002530.3750\n",
      "Epoch 383/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1002962.8750 - mean_squared_error: 1002962.8750\n",
      "Epoch 384/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1001086.7500 - mean_squared_error: 1001086.8750\n",
      "Epoch 385/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1000441.5000 - mean_squared_error: 1000441.5625\n",
      "Epoch 386/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 998782.2500 - mean_squared_error: 998782.2500\n",
      "Epoch 387/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 995676.5000 - mean_squared_error: 995676.5000\n",
      "Epoch 388/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 998180.6250 - mean_squared_error: 998180.6250\n",
      "Epoch 389/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1002783.9375 - mean_squared_error: 1002783.9375\n",
      "Epoch 390/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 995513.2500 - mean_squared_error: 995513.2500\n",
      "Epoch 391/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 995919.1250 - mean_squared_error: 995919.2500\n",
      "Epoch 392/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 998527.6250 - mean_squared_error: 998527.6250\n",
      "Epoch 393/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 995831.0625 - mean_squared_error: 995831.0625\n",
      "Epoch 394/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 990754.0000 - mean_squared_error: 990754.0000\n",
      "Epoch 395/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 991082.3750 - mean_squared_error: 991082.3750\n",
      "Epoch 396/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 990165.0625 - mean_squared_error: 990165.0625\n",
      "Epoch 397/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 990383.6875 - mean_squared_error: 990383.6875\n",
      "Epoch 398/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 988391.0000 - mean_squared_error: 988391.0000\n",
      "Epoch 399/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 987558.3125 - mean_squared_error: 987558.3125\n",
      "Epoch 400/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 986120.3125 - mean_squared_error: 986120.3125\n",
      "Epoch 401/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 985270.3750 - mean_squared_error: 985270.3125\n",
      "Epoch 402/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 985390.8750 - mean_squared_error: 985390.8750\n",
      "Epoch 403/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 986697.0000 - mean_squared_error: 986697.0000\n",
      "Epoch 404/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 984065.4375 - mean_squared_error: 984065.4375\n",
      "Epoch 405/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 986381.6875 - mean_squared_error: 986381.6875\n",
      "Epoch 406/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 983038.0625 - mean_squared_error: 983038.0625\n",
      "Epoch 407/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 980152.0625 - mean_squared_error: 980152.0625\n",
      "Epoch 408/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 982328.0000 - mean_squared_error: 982328.0000\n",
      "Epoch 409/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 979447.1875 - mean_squared_error: 979447.1875\n",
      "Epoch 410/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 981102.8750 - mean_squared_error: 981102.8750\n",
      "Epoch 411/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 974977.5625 - mean_squared_error: 974977.5625\n",
      "Epoch 412/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 975886.0625 - mean_squared_error: 975886.0625\n",
      "Epoch 413/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 977644.3750 - mean_squared_error: 977644.3750\n",
      "Epoch 414/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 972461.0000 - mean_squared_error: 972461.0000\n",
      "Epoch 415/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 976449.0000 - mean_squared_error: 976449.0000\n",
      "Epoch 416/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 974424.0625 - mean_squared_error: 974424.0625\n",
      "Epoch 417/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 970575.1250 - mean_squared_error: 970575.1250\n",
      "Epoch 418/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 971430.2500 - mean_squared_error: 971430.2500\n",
      "Epoch 419/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 971443.3750 - mean_squared_error: 971443.3750\n",
      "Epoch 420/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 966904.8125 - mean_squared_error: 966904.8125\n",
      "Epoch 421/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 970124.6250 - mean_squared_error: 970124.6250\n",
      "Epoch 422/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 968929.8750 - mean_squared_error: 968929.8750\n",
      "Epoch 423/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 969702.9375 - mean_squared_error: 969702.9375\n",
      "Epoch 424/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 964701.4375 - mean_squared_error: 964701.4375\n",
      "Epoch 425/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 967886.9375 - mean_squared_error: 967886.9375\n",
      "Epoch 426/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 965068.4375 - mean_squared_error: 965068.4375\n",
      "Epoch 427/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 961983.8750 - mean_squared_error: 961983.8750\n",
      "Epoch 428/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 964610.7500 - mean_squared_error: 964610.7500\n",
      "Epoch 429/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 958989.0625 - mean_squared_error: 958989.0625\n",
      "Epoch 430/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 959974.1875 - mean_squared_error: 959974.2500\n",
      "Epoch 431/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 961581.3750 - mean_squared_error: 961581.3750\n",
      "Epoch 432/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 959244.7500 - mean_squared_error: 959244.7500\n",
      "Epoch 433/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 959161.4375 - mean_squared_error: 959161.4375\n",
      "Epoch 434/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 958631.5625 - mean_squared_error: 958631.5625\n",
      "Epoch 435/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 953761.1250 - mean_squared_error: 953761.1250\n",
      "Epoch 436/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 957904.3125 - mean_squared_error: 957904.3125\n",
      "Epoch 437/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 951419.1250 - mean_squared_error: 951419.1250\n",
      "Epoch 438/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 955228.3750 - mean_squared_error: 955228.3750\n",
      "Epoch 439/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 956544.8750 - mean_squared_error: 956544.8750\n",
      "Epoch 440/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 956025.6250 - mean_squared_error: 956025.6250\n",
      "Epoch 441/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 954965.4375 - mean_squared_error: 954965.4375\n",
      "Epoch 442/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 950694.5000 - mean_squared_error: 950694.5000\n",
      "Epoch 443/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 950736.0625 - mean_squared_error: 950736.0625\n",
      "Epoch 444/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 951913.7500 - mean_squared_error: 951913.7500\n",
      "Epoch 445/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 949904.1250 - mean_squared_error: 949904.1250\n",
      "Epoch 446/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 947290.1875 - mean_squared_error: 947290.1875\n",
      "Epoch 447/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 948752.8125 - mean_squared_error: 948752.8125\n",
      "Epoch 448/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 944621.1250 - mean_squared_error: 944621.1250\n",
      "Epoch 449/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 945863.6875 - mean_squared_error: 945863.6875\n",
      "Epoch 450/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 944956.3750 - mean_squared_error: 944956.3750\n",
      "Epoch 451/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 945904.9375 - mean_squared_error: 945904.9375\n",
      "Epoch 452/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 944871.3750 - mean_squared_error: 944871.3750\n",
      "Epoch 453/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 944972.8125 - mean_squared_error: 944972.8750\n",
      "Epoch 454/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 940445.2500 - mean_squared_error: 940445.2500\n",
      "Epoch 455/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 941391.5625 - mean_squared_error: 941391.5625\n",
      "Epoch 456/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 937083.6250 - mean_squared_error: 937083.6250\n",
      "Epoch 457/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 939899.6250 - mean_squared_error: 939899.6250\n",
      "Epoch 458/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 940561.3125 - mean_squared_error: 940561.3125\n",
      "Epoch 459/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 937002.3125 - mean_squared_error: 937002.3125\n",
      "Epoch 460/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 935387.6875 - mean_squared_error: 935387.6875\n",
      "Epoch 461/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 933878.3750 - mean_squared_error: 933878.3750\n",
      "Epoch 462/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 936575.2500 - mean_squared_error: 936575.2500\n",
      "Epoch 463/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 930974.5625 - mean_squared_error: 930974.5625\n",
      "Epoch 464/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 933604.6875 - mean_squared_error: 933604.6875\n",
      "Epoch 465/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 931405.6875 - mean_squared_error: 931405.6875\n",
      "Epoch 466/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 931995.5625 - mean_squared_error: 931995.5625\n",
      "Epoch 467/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 928849.0625 - mean_squared_error: 928849.0625\n",
      "Epoch 468/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 927588.5000 - mean_squared_error: 927588.5625\n",
      "Epoch 469/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 930046.2500 - mean_squared_error: 930046.2500\n",
      "Epoch 470/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 927745.4375 - mean_squared_error: 927745.4375\n",
      "Epoch 471/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 925331.8750 - mean_squared_error: 925331.8125\n",
      "Epoch 472/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 933193.5000 - mean_squared_error: 933193.5000\n",
      "Epoch 473/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 928147.3750 - mean_squared_error: 928147.3750\n",
      "Epoch 474/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 920893.1875 - mean_squared_error: 920893.1875\n",
      "Epoch 475/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 922902.7500 - mean_squared_error: 922902.7500\n",
      "Epoch 476/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 920905.4375 - mean_squared_error: 920905.4375\n",
      "Epoch 477/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 922276.5625 - mean_squared_error: 922276.5625\n",
      "Epoch 478/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 918448.3750 - mean_squared_error: 918448.3125\n",
      "Epoch 479/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 921390.1250 - mean_squared_error: 921390.1250\n",
      "Epoch 480/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 919359.6875 - mean_squared_error: 919359.6875\n",
      "Epoch 481/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 917820.7500 - mean_squared_error: 917820.7500\n",
      "Epoch 482/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 916633.0000 - mean_squared_error: 916633.0000\n",
      "Epoch 483/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 916924.3125 - mean_squared_error: 916924.3125\n",
      "Epoch 484/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 916098.3750 - mean_squared_error: 916098.3750\n",
      "Epoch 485/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 918004.3750 - mean_squared_error: 918004.3750\n",
      "Epoch 486/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 915139.9375 - mean_squared_error: 915139.9375\n",
      "Epoch 487/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 914354.3125 - mean_squared_error: 914354.3125\n",
      "Epoch 488/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 913368.6875 - mean_squared_error: 913368.6875\n",
      "Epoch 489/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 907900.1875 - mean_squared_error: 907900.1875\n",
      "Epoch 490/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 910984.0625 - mean_squared_error: 910984.0625\n",
      "Epoch 491/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 914991.1875 - mean_squared_error: 914991.1875\n",
      "Epoch 492/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 911161.5625 - mean_squared_error: 911161.5625\n",
      "Epoch 493/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 909502.3750 - mean_squared_error: 909502.3750\n",
      "Epoch 494/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 907123.8125 - mean_squared_error: 907123.8125\n",
      "Epoch 495/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 908898.4375 - mean_squared_error: 908898.3750\n",
      "Epoch 496/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 907989.9375 - mean_squared_error: 907989.9375\n",
      "Epoch 497/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 908811.7500 - mean_squared_error: 908811.7500\n",
      "Epoch 498/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 909394.5625 - mean_squared_error: 909394.5625\n",
      "Epoch 499/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 907019.0000 - mean_squared_error: 907019.0000\n",
      "Epoch 500/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 905191.0000 - mean_squared_error: 905191.0000\n",
      "Epoch 501/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 901325.6875 - mean_squared_error: 901325.6875\n",
      "Epoch 502/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 900623.7500 - mean_squared_error: 900623.7500\n",
      "Epoch 503/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 900374.6875 - mean_squared_error: 900374.6875\n",
      "Epoch 504/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 903526.0625 - mean_squared_error: 903526.0625\n",
      "Epoch 505/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 899299.3125 - mean_squared_error: 899299.3125\n",
      "Epoch 506/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 899461.5000 - mean_squared_error: 899461.5000\n",
      "Epoch 507/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 899486.0000 - mean_squared_error: 899486.0000\n",
      "Epoch 508/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 901301.8750 - mean_squared_error: 901301.8750\n",
      "Epoch 509/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 902358.8750 - mean_squared_error: 902358.8750\n",
      "Epoch 510/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 898501.0625 - mean_squared_error: 898501.1250\n",
      "Epoch 511/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 892722.9375 - mean_squared_error: 892722.9375\n",
      "Epoch 512/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 890148.1250 - mean_squared_error: 890148.1250\n",
      "Epoch 513/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 891430.5625 - mean_squared_error: 891430.5625\n",
      "Epoch 514/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 893744.7500 - mean_squared_error: 893744.7500\n",
      "Epoch 515/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 888109.2500 - mean_squared_error: 888109.2500\n",
      "Epoch 516/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 887211.5000 - mean_squared_error: 887211.5000\n",
      "Epoch 517/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 894568.1250 - mean_squared_error: 894568.1250\n",
      "Epoch 518/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 891324.3125 - mean_squared_error: 891324.3125\n",
      "Epoch 519/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 887187.1875 - mean_squared_error: 887187.1875\n",
      "Epoch 520/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 885244.3750 - mean_squared_error: 885244.4375\n",
      "Epoch 521/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 888976.0000 - mean_squared_error: 888976.0000\n",
      "Epoch 522/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 889297.9375 - mean_squared_error: 889297.9375\n",
      "Epoch 523/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 885499.6250 - mean_squared_error: 885499.6250\n",
      "Epoch 524/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 887213.5000 - mean_squared_error: 887213.5000\n",
      "Epoch 525/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 885195.3125 - mean_squared_error: 885195.3125\n",
      "Epoch 526/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 883752.2500 - mean_squared_error: 883752.2500\n",
      "Epoch 527/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 884751.9375 - mean_squared_error: 884751.9375\n",
      "Epoch 528/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 879893.1875 - mean_squared_error: 879893.1875\n",
      "Epoch 529/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 879427.4375 - mean_squared_error: 879427.4375\n",
      "Epoch 530/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 881485.0625 - mean_squared_error: 881485.0625\n",
      "Epoch 531/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 875677.5000 - mean_squared_error: 875677.4375\n",
      "Epoch 532/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 876843.2500 - mean_squared_error: 876843.3125\n",
      "Epoch 533/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 881349.6875 - mean_squared_error: 881349.6875\n",
      "Epoch 534/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 882663.2500 - mean_squared_error: 882663.2500\n",
      "Epoch 535/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 876037.5625 - mean_squared_error: 876037.5625\n",
      "Epoch 536/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 877857.3750 - mean_squared_error: 877857.3750\n",
      "Epoch 537/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 876871.8125 - mean_squared_error: 876871.8125\n",
      "Epoch 538/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 875642.6250 - mean_squared_error: 875642.6250\n",
      "Epoch 539/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 877522.6875 - mean_squared_error: 877522.6875\n",
      "Epoch 540/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 875909.2500 - mean_squared_error: 875909.2500\n",
      "Epoch 541/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 871501.2500 - mean_squared_error: 871501.2500\n",
      "Epoch 542/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 870257.5000 - mean_squared_error: 870257.5000\n",
      "Epoch 543/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 867551.1875 - mean_squared_error: 867551.1875\n",
      "Epoch 544/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 868399.1250 - mean_squared_error: 868399.1875\n",
      "Epoch 545/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 867650.8750 - mean_squared_error: 867650.8750\n",
      "Epoch 546/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 863317.8750 - mean_squared_error: 863317.8125\n",
      "Epoch 547/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 871478.6875 - mean_squared_error: 871478.6875\n",
      "Epoch 548/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 866297.5625 - mean_squared_error: 866297.5625\n",
      "Epoch 549/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 865883.6250 - mean_squared_error: 865883.6250\n",
      "Epoch 550/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 860987.6875 - mean_squared_error: 860987.6250\n",
      "Epoch 551/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 863553.9375 - mean_squared_error: 863553.8125\n",
      "Epoch 552/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 864271.9375 - mean_squared_error: 864271.9375\n",
      "Epoch 553/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 864790.6875 - mean_squared_error: 864790.6875\n",
      "Epoch 554/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 855224.6875 - mean_squared_error: 855224.6875\n",
      "Epoch 555/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 865506.2500 - mean_squared_error: 865506.3125\n",
      "Epoch 556/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 861692.8750 - mean_squared_error: 861692.8750\n",
      "Epoch 557/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 857420.1250 - mean_squared_error: 857420.1250\n",
      "Epoch 558/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 860888.4375 - mean_squared_error: 860888.4375\n",
      "Epoch 559/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 855838.8125 - mean_squared_error: 855838.8125\n",
      "Epoch 560/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 859031.7500 - mean_squared_error: 859031.7500\n",
      "Epoch 561/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 857079.3125 - mean_squared_error: 857079.3125\n",
      "Epoch 562/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 856885.0625 - mean_squared_error: 856885.0625\n",
      "Epoch 563/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 858240.7500 - mean_squared_error: 858240.7500\n",
      "Epoch 564/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 854267.1250 - mean_squared_error: 854267.1250\n",
      "Epoch 565/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 852723.9375 - mean_squared_error: 852723.9375\n",
      "Epoch 566/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 853409.9375 - mean_squared_error: 853409.9375\n",
      "Epoch 567/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 849724.1875 - mean_squared_error: 849724.1875\n",
      "Epoch 568/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 850957.0625 - mean_squared_error: 850957.0625\n",
      "Epoch 569/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 852435.6875 - mean_squared_error: 852435.7500\n",
      "Epoch 570/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 846569.8750 - mean_squared_error: 846569.8750\n",
      "Epoch 571/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 848948.5625 - mean_squared_error: 848948.5625\n",
      "Epoch 572/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 849462.1875 - mean_squared_error: 849462.1875\n",
      "Epoch 573/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 849145.7500 - mean_squared_error: 849145.7500\n",
      "Epoch 574/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 847329.8125 - mean_squared_error: 847329.8750\n",
      "Epoch 575/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 844844.8750 - mean_squared_error: 844844.8750\n",
      "Epoch 576/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 847927.9375 - mean_squared_error: 847927.9375\n",
      "Epoch 577/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 842321.5625 - mean_squared_error: 842321.5625\n",
      "Epoch 578/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 837804.2500 - mean_squared_error: 837804.2500\n",
      "Epoch 579/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 840806.4375 - mean_squared_error: 840806.4375\n",
      "Epoch 580/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 841941.4375 - mean_squared_error: 841941.3750\n",
      "Epoch 581/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 841708.0625 - mean_squared_error: 841708.0625\n",
      "Epoch 582/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 839830.1250 - mean_squared_error: 839830.1250\n",
      "Epoch 583/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 841059.8125 - mean_squared_error: 841059.8125\n",
      "Epoch 584/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 839080.9375 - mean_squared_error: 839080.9375\n",
      "Epoch 585/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 841743.5000 - mean_squared_error: 841743.5000\n",
      "Epoch 586/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 838715.3125 - mean_squared_error: 838715.3125\n",
      "Epoch 587/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 834490.0000 - mean_squared_error: 834490.0000\n",
      "Epoch 588/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 834517.3125 - mean_squared_error: 834517.3125\n",
      "Epoch 589/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 833353.0000 - mean_squared_error: 833353.0000\n",
      "Epoch 590/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 838585.2500 - mean_squared_error: 838585.2500\n",
      "Epoch 591/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 834323.7500 - mean_squared_error: 834323.7500\n",
      "Epoch 592/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 833045.0625 - mean_squared_error: 833045.0625\n",
      "Epoch 593/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 830422.5000 - mean_squared_error: 830422.5000\n",
      "Epoch 594/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 832092.3750 - mean_squared_error: 832092.3750\n",
      "Epoch 595/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 829863.0625 - mean_squared_error: 829863.0625\n",
      "Epoch 596/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 835601.5000 - mean_squared_error: 835601.5000\n",
      "Epoch 597/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 829343.6250 - mean_squared_error: 829343.5625\n",
      "Epoch 598/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 826965.6875 - mean_squared_error: 826965.6875\n",
      "Epoch 599/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 830088.7500 - mean_squared_error: 830088.7500\n",
      "Epoch 600/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 829308.3750 - mean_squared_error: 829308.3750\n",
      "Epoch 601/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 828712.2500 - mean_squared_error: 828712.2500\n",
      "Epoch 602/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 828504.3750 - mean_squared_error: 828504.2500\n",
      "Epoch 603/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 825555.1250 - mean_squared_error: 825555.1250\n",
      "Epoch 604/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 829120.0000 - mean_squared_error: 829119.9375\n",
      "Epoch 605/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 823527.2500 - mean_squared_error: 823527.2500\n",
      "Epoch 606/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 821333.1250 - mean_squared_error: 821333.1250\n",
      "Epoch 607/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 824122.6250 - mean_squared_error: 824122.6250\n",
      "Epoch 608/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 823451.4375 - mean_squared_error: 823451.4375\n",
      "Epoch 609/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 820370.9375 - mean_squared_error: 820370.9375\n",
      "Epoch 610/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 820751.1875 - mean_squared_error: 820751.1875\n",
      "Epoch 611/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815855.1875 - mean_squared_error: 815855.1875\n",
      "Epoch 612/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 823461.0625 - mean_squared_error: 823461.0625\n",
      "Epoch 613/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 814674.1250 - mean_squared_error: 814674.1250\n",
      "Epoch 614/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 817749.8125 - mean_squared_error: 817749.8125\n",
      "Epoch 615/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 820597.8125 - mean_squared_error: 820597.8125\n",
      "Epoch 616/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 811422.5625 - mean_squared_error: 811422.6250\n",
      "Epoch 617/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 814802.8750 - mean_squared_error: 814802.7500\n",
      "Epoch 618/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815583.5625 - mean_squared_error: 815583.5625\n",
      "Epoch 619/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 814309.5000 - mean_squared_error: 814309.5625\n",
      "Epoch 620/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815805.9375 - mean_squared_error: 815806.0000\n",
      "Epoch 621/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815456.4375 - mean_squared_error: 815456.4375\n",
      "Epoch 622/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 808860.8750 - mean_squared_error: 808860.8750\n",
      "Epoch 623/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 805562.6250 - mean_squared_error: 805562.6250\n",
      "Epoch 624/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 806983.5000 - mean_squared_error: 806983.5000\n",
      "Epoch 625/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 812317.6250 - mean_squared_error: 812317.6875\n",
      "Epoch 626/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 808313.3750 - mean_squared_error: 808313.3750\n",
      "Epoch 627/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 811098.4375 - mean_squared_error: 811098.4375\n",
      "Epoch 628/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 804396.0000 - mean_squared_error: 804396.0625\n",
      "Epoch 629/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 807753.3750 - mean_squared_error: 807753.3750\n",
      "Epoch 630/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 801790.5625 - mean_squared_error: 801790.5625\n",
      "Epoch 631/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 824623.4375 - mean_squared_error: 824623.4375\n",
      "Epoch 632/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 798485.9375 - mean_squared_error: 798485.9375\n",
      "Epoch 633/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 804438.1250 - mean_squared_error: 804438.1250\n",
      "Epoch 634/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 801780.0000 - mean_squared_error: 801780.0000\n",
      "Epoch 635/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 803421.8750 - mean_squared_error: 803421.8750\n",
      "Epoch 636/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 802158.0000 - mean_squared_error: 802158.0000\n",
      "Epoch 637/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 803377.7500 - mean_squared_error: 803377.8125\n",
      "Epoch 638/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 800590.8750 - mean_squared_error: 800590.8750\n",
      "Epoch 639/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 802822.6250 - mean_squared_error: 802822.6250\n",
      "Epoch 640/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 799108.5000 - mean_squared_error: 799108.5000\n",
      "Epoch 641/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 798315.1875 - mean_squared_error: 798315.1875\n",
      "Epoch 642/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 797395.0000 - mean_squared_error: 797395.0000\n",
      "Epoch 643/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 796189.5625 - mean_squared_error: 796189.5625\n",
      "Epoch 644/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 797698.9375 - mean_squared_error: 797698.9375\n",
      "Epoch 645/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 796113.3750 - mean_squared_error: 796113.3750\n",
      "Epoch 646/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 796082.8125 - mean_squared_error: 796082.8750\n",
      "Epoch 647/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 799751.3125 - mean_squared_error: 799751.3125\n",
      "Epoch 648/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 791910.1250 - mean_squared_error: 791910.1250\n",
      "Epoch 649/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 793327.2500 - mean_squared_error: 793327.2500\n",
      "Epoch 650/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 791937.6875 - mean_squared_error: 791937.6875\n",
      "Epoch 651/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 792092.0000 - mean_squared_error: 792092.0000\n",
      "Epoch 652/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 797393.0000 - mean_squared_error: 797393.0000\n",
      "Epoch 653/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 793645.7500 - mean_squared_error: 793645.8125\n",
      "Epoch 654/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 789031.6250 - mean_squared_error: 789031.6250\n",
      "Epoch 655/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 793181.6250 - mean_squared_error: 793181.6250\n",
      "Epoch 656/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 788198.6875 - mean_squared_error: 788198.6250\n",
      "Epoch 657/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 789586.9375 - mean_squared_error: 789586.9375\n",
      "Epoch 658/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 788519.9375 - mean_squared_error: 788519.9375\n",
      "Epoch 659/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 787173.3125 - mean_squared_error: 787173.3125\n",
      "Epoch 660/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 789027.6250 - mean_squared_error: 789027.5625\n",
      "Epoch 661/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 786475.3750 - mean_squared_error: 786475.3750\n",
      "Epoch 662/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 787016.5625 - mean_squared_error: 787016.5625\n",
      "Epoch 663/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 782452.6250 - mean_squared_error: 782452.6250\n",
      "Epoch 664/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 781838.7500 - mean_squared_error: 781838.8125\n",
      "Epoch 665/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 779375.9375 - mean_squared_error: 779375.9375\n",
      "Epoch 666/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 783137.0000 - mean_squared_error: 783137.0000\n",
      "Epoch 667/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 781317.3750 - mean_squared_error: 781317.3750\n",
      "Epoch 668/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 782201.2500 - mean_squared_error: 782201.2500\n",
      "Epoch 669/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 783848.5625 - mean_squared_error: 783848.5625\n",
      "Epoch 670/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 776955.9375 - mean_squared_error: 776955.9375\n",
      "Epoch 671/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 776027.4375 - mean_squared_error: 776027.4375\n",
      "Epoch 672/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 777374.2500 - mean_squared_error: 777374.2500\n",
      "Epoch 673/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 778222.2500 - mean_squared_error: 778222.2500\n",
      "Epoch 674/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 771897.8750 - mean_squared_error: 771897.8750\n",
      "Epoch 675/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 777255.4375 - mean_squared_error: 777255.4375\n",
      "Epoch 676/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 776579.1875 - mean_squared_error: 776579.1875\n",
      "Epoch 677/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 770132.5625 - mean_squared_error: 770132.5625\n",
      "Epoch 678/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 769481.1875 - mean_squared_error: 769481.1875\n",
      "Epoch 679/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 772901.4375 - mean_squared_error: 772901.4375\n",
      "Epoch 680/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 771143.5000 - mean_squared_error: 771143.5000\n",
      "Epoch 681/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 773223.3125 - mean_squared_error: 773223.3125\n",
      "Epoch 682/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 770636.1875 - mean_squared_error: 770636.1875\n",
      "Epoch 683/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 767799.3750 - mean_squared_error: 767799.4375\n",
      "Epoch 684/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 766948.5625 - mean_squared_error: 766948.5625\n",
      "Epoch 685/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 768059.0625 - mean_squared_error: 768059.0625\n",
      "Epoch 686/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 769324.5625 - mean_squared_error: 769324.5625\n",
      "Epoch 687/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 763622.1875 - mean_squared_error: 763622.1875\n",
      "Epoch 688/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 765434.3750 - mean_squared_error: 765434.3750\n",
      "Epoch 689/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 767973.4375 - mean_squared_error: 767973.4375\n",
      "Epoch 690/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 764577.0625 - mean_squared_error: 764577.0000\n",
      "Epoch 691/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 766804.1250 - mean_squared_error: 766804.1250\n",
      "Epoch 692/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 768443.2500 - mean_squared_error: 768443.2500\n",
      "Epoch 693/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 760664.6250 - mean_squared_error: 760664.6250\n",
      "Epoch 694/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 757463.0625 - mean_squared_error: 757463.0625\n",
      "Epoch 695/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 762671.0625 - mean_squared_error: 762671.0625\n",
      "Epoch 696/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 767370.1250 - mean_squared_error: 767370.1250\n",
      "Epoch 697/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 760230.5625 - mean_squared_error: 760230.5625\n",
      "Epoch 698/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 763340.9375 - mean_squared_error: 763340.9375\n",
      "Epoch 699/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 758942.1250 - mean_squared_error: 758942.1250\n",
      "Epoch 700/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 760733.1250 - mean_squared_error: 760733.1250\n",
      "Epoch 701/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 759533.0625 - mean_squared_error: 759533.0625\n",
      "Epoch 702/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 753995.5625 - mean_squared_error: 753995.5625\n",
      "Epoch 703/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 754128.5625 - mean_squared_error: 754128.5625\n",
      "Epoch 704/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 757691.2500 - mean_squared_error: 757691.2500\n",
      "Epoch 705/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 755325.7500 - mean_squared_error: 755325.7500\n",
      "Epoch 706/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 753909.1250 - mean_squared_error: 753909.1250\n",
      "Epoch 707/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 756424.7500 - mean_squared_error: 756424.7500\n",
      "Epoch 708/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 750125.6250 - mean_squared_error: 750125.6250\n",
      "Epoch 709/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 754197.3125 - mean_squared_error: 754197.3125\n",
      "Epoch 710/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 755792.3125 - mean_squared_error: 755792.3125\n",
      "Epoch 711/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 747317.5000 - mean_squared_error: 747317.5000\n",
      "Epoch 712/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 748191.4375 - mean_squared_error: 748191.4375\n",
      "Epoch 713/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 751758.8125 - mean_squared_error: 751758.8125\n",
      "Epoch 714/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 751854.0000 - mean_squared_error: 751854.0000\n",
      "Epoch 715/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 748135.9375 - mean_squared_error: 748135.9375\n",
      "Epoch 716/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 749715.8750 - mean_squared_error: 749715.8750\n",
      "Epoch 717/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 748988.2500 - mean_squared_error: 748988.2500\n",
      "Epoch 718/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 748075.6875 - mean_squared_error: 748075.6250\n",
      "Epoch 719/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 747240.2500 - mean_squared_error: 747240.2500\n",
      "Epoch 720/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 745633.5625 - mean_squared_error: 745633.5625\n",
      "Epoch 721/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 750385.3125 - mean_squared_error: 750385.3125\n",
      "Epoch 722/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 744895.8750 - mean_squared_error: 744895.8750\n",
      "Epoch 723/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 743364.0000 - mean_squared_error: 743364.0000\n",
      "Epoch 724/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 743618.6875 - mean_squared_error: 743618.6875\n",
      "Epoch 725/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 741072.6250 - mean_squared_error: 741072.6250\n",
      "Epoch 726/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 740916.6875 - mean_squared_error: 740916.6875\n",
      "Epoch 727/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 737405.3125 - mean_squared_error: 737405.3125\n",
      "Epoch 728/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 738402.9375 - mean_squared_error: 738402.9375\n",
      "Epoch 729/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 739161.5625 - mean_squared_error: 739161.5625\n",
      "Epoch 730/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 740607.9375 - mean_squared_error: 740607.9375\n",
      "Epoch 731/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 742226.1875 - mean_squared_error: 742226.1250\n",
      "Epoch 732/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 732967.4375 - mean_squared_error: 732967.4375\n",
      "Epoch 733/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 734736.7500 - mean_squared_error: 734736.7500\n",
      "Epoch 734/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 731938.1250 - mean_squared_error: 731938.1250\n",
      "Epoch 735/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 735831.3750 - mean_squared_error: 735831.3750\n",
      "Epoch 736/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 733393.3125 - mean_squared_error: 733393.3125\n",
      "Epoch 737/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 735421.1875 - mean_squared_error: 735421.1875\n",
      "Epoch 738/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 733191.8125 - mean_squared_error: 733191.8125\n",
      "Epoch 739/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 729619.1250 - mean_squared_error: 729619.1875\n",
      "Epoch 740/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 732298.8125 - mean_squared_error: 732298.8125\n",
      "Epoch 741/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 730414.0625 - mean_squared_error: 730414.0625\n",
      "Epoch 742/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 730620.6875 - mean_squared_error: 730620.6875\n",
      "Epoch 743/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 729518.3125 - mean_squared_error: 729518.3125\n",
      "Epoch 744/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 730329.5000 - mean_squared_error: 730329.5000\n",
      "Epoch 745/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 728361.4375 - mean_squared_error: 728361.4375\n",
      "Epoch 746/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 731317.0625 - mean_squared_error: 731317.0625\n",
      "Epoch 747/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 728481.1875 - mean_squared_error: 728481.1875\n",
      "Epoch 748/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 724855.8125 - mean_squared_error: 724855.8125\n",
      "Epoch 749/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 727345.9375 - mean_squared_error: 727345.9375\n",
      "Epoch 750/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 726154.7500 - mean_squared_error: 726154.8125\n",
      "Epoch 751/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 726042.9375 - mean_squared_error: 726042.9375\n",
      "Epoch 752/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 722075.0625 - mean_squared_error: 722075.0625\n",
      "Epoch 753/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 722525.8125 - mean_squared_error: 722525.8125\n",
      "Epoch 754/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 728234.4375 - mean_squared_error: 728234.4375\n",
      "Epoch 755/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 718938.0000 - mean_squared_error: 718938.0000\n",
      "Epoch 756/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 723925.8750 - mean_squared_error: 723925.8750\n",
      "Epoch 757/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 725285.8125 - mean_squared_error: 725285.8125\n",
      "Epoch 758/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 724619.2500 - mean_squared_error: 724619.2500\n",
      "Epoch 759/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 722120.9375 - mean_squared_error: 722120.9375\n",
      "Epoch 760/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 719984.0000 - mean_squared_error: 719984.0000\n",
      "Epoch 761/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 720233.7500 - mean_squared_error: 720233.7500\n",
      "Epoch 762/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 721320.2500 - mean_squared_error: 721320.2500\n",
      "Epoch 763/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 717888.6875 - mean_squared_error: 717888.6875\n",
      "Epoch 764/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 717565.5625 - mean_squared_error: 717565.5625\n",
      "Epoch 765/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 719687.3750 - mean_squared_error: 719687.3750\n",
      "Epoch 766/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 716130.0000 - mean_squared_error: 716130.0000\n",
      "Epoch 767/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 717603.0000 - mean_squared_error: 717603.0000\n",
      "Epoch 768/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 715750.3125 - mean_squared_error: 715750.3125\n",
      "Epoch 769/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 710333.0000 - mean_squared_error: 710333.0000\n",
      "Epoch 770/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 710092.6250 - mean_squared_error: 710092.6250\n",
      "Epoch 771/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 713629.2500 - mean_squared_error: 713629.2500\n",
      "Epoch 772/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 709950.8750 - mean_squared_error: 709950.8750\n",
      "Epoch 773/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 712804.8750 - mean_squared_error: 712804.8750\n",
      "Epoch 774/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 713732.6250 - mean_squared_error: 713732.6250\n",
      "Epoch 775/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 714400.8750 - mean_squared_error: 714400.8750\n",
      "Epoch 776/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 707206.4375 - mean_squared_error: 707206.4375\n",
      "Epoch 777/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 709979.6250 - mean_squared_error: 709979.6250\n",
      "Epoch 778/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 714793.8125 - mean_squared_error: 714793.8125\n",
      "Epoch 779/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 709347.7500 - mean_squared_error: 709347.6875\n",
      "Epoch 780/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 710611.2500 - mean_squared_error: 710611.2500\n",
      "Epoch 781/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 705662.3750 - mean_squared_error: 705662.3750\n",
      "Epoch 782/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 707756.4375 - mean_squared_error: 707756.4375\n",
      "Epoch 783/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 710546.3125 - mean_squared_error: 710546.3125\n",
      "Epoch 784/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 706112.6250 - mean_squared_error: 706112.6250\n",
      "Epoch 785/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 701491.7500 - mean_squared_error: 701491.7500\n",
      "Epoch 786/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 704325.1250 - mean_squared_error: 704325.1250\n",
      "Epoch 787/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 703718.6875 - mean_squared_error: 703718.6250\n",
      "Epoch 788/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 702767.3750 - mean_squared_error: 702767.3750\n",
      "Epoch 789/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 699239.0000 - mean_squared_error: 699239.0000\n",
      "Epoch 790/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 699451.1875 - mean_squared_error: 699451.1875\n",
      "Epoch 791/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 710288.3750 - mean_squared_error: 710288.3750\n",
      "Epoch 792/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 704353.9375 - mean_squared_error: 704353.9375\n",
      "Epoch 793/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 698279.2500 - mean_squared_error: 698279.2500\n",
      "Epoch 794/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 700702.1250 - mean_squared_error: 700702.1250\n",
      "Epoch 795/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 699587.6875 - mean_squared_error: 699587.6875\n",
      "Epoch 796/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 695069.5000 - mean_squared_error: 695069.5000\n",
      "Epoch 797/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 690640.9375 - mean_squared_error: 690640.9375\n",
      "Epoch 798/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 695558.6875 - mean_squared_error: 695558.6875\n",
      "Epoch 799/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 696293.0625 - mean_squared_error: 696293.0625\n",
      "Epoch 800/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 693048.6875 - mean_squared_error: 693048.6875\n",
      "Epoch 801/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 694846.6250 - mean_squared_error: 694846.6250\n",
      "Epoch 802/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 699308.3750 - mean_squared_error: 699308.3750\n",
      "Epoch 803/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 694871.5000 - mean_squared_error: 694871.5000\n",
      "Epoch 804/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 693624.7500 - mean_squared_error: 693624.7500\n",
      "Epoch 805/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 693931.2500 - mean_squared_error: 693931.3125\n",
      "Epoch 806/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 688432.8125 - mean_squared_error: 688432.8125\n",
      "Epoch 807/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 690312.0000 - mean_squared_error: 690312.0000\n",
      "Epoch 808/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 691304.3125 - mean_squared_error: 691304.3125\n",
      "Epoch 809/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 687636.3750 - mean_squared_error: 687636.3750\n",
      "Epoch 810/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 693059.0625 - mean_squared_error: 693059.0625\n",
      "Epoch 811/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 691745.6250 - mean_squared_error: 691745.6250\n",
      "Epoch 812/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 683071.6250 - mean_squared_error: 683071.6250\n",
      "Epoch 813/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 687625.5625 - mean_squared_error: 687625.5625\n",
      "Epoch 814/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 688614.8125 - mean_squared_error: 688614.8125\n",
      "Epoch 815/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 685026.6875 - mean_squared_error: 685026.6875\n",
      "Epoch 816/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 686515.0625 - mean_squared_error: 686515.0625\n",
      "Epoch 817/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 686751.0625 - mean_squared_error: 686751.0625\n",
      "Epoch 818/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 682984.0625 - mean_squared_error: 682984.0625\n",
      "Epoch 819/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 679965.3750 - mean_squared_error: 679965.3750\n",
      "Epoch 820/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 685461.6250 - mean_squared_error: 685461.6250\n",
      "Epoch 821/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 684210.6875 - mean_squared_error: 684210.6875\n",
      "Epoch 822/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679620.5625 - mean_squared_error: 679620.5625\n",
      "Epoch 823/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 682093.1250 - mean_squared_error: 682093.1875\n",
      "Epoch 824/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679786.8125 - mean_squared_error: 679786.7500\n",
      "Epoch 825/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 683009.6250 - mean_squared_error: 683009.6250\n",
      "Epoch 826/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 681142.3750 - mean_squared_error: 681142.3750\n",
      "Epoch 827/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 682128.2500 - mean_squared_error: 682128.2500\n",
      "Epoch 828/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 679666.8125 - mean_squared_error: 679666.8750\n",
      "Epoch 829/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 678431.7500 - mean_squared_error: 678431.7500\n",
      "Epoch 830/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 676368.3750 - mean_squared_error: 676368.3750\n",
      "Epoch 831/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 680585.1250 - mean_squared_error: 680585.1250\n",
      "Epoch 832/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 678009.3125 - mean_squared_error: 678009.3125\n",
      "Epoch 833/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679934.0625 - mean_squared_error: 679934.0625\n",
      "Epoch 834/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 674245.9375 - mean_squared_error: 674245.9375\n",
      "Epoch 835/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 678202.7500 - mean_squared_error: 678202.7500\n",
      "Epoch 836/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 673614.1250 - mean_squared_error: 673614.1250\n",
      "Epoch 837/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 680805.9375 - mean_squared_error: 680805.9375\n",
      "Epoch 838/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 668282.0000 - mean_squared_error: 668282.0625\n",
      "Epoch 839/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 667474.1875 - mean_squared_error: 667474.1875\n",
      "Epoch 840/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 672238.7500 - mean_squared_error: 672238.7500\n",
      "Epoch 841/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 674145.3125 - mean_squared_error: 674145.2500\n",
      "Epoch 842/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 676813.8750 - mean_squared_error: 676813.8750\n",
      "Epoch 843/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 669739.0625 - mean_squared_error: 669739.0625\n",
      "Epoch 844/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 671636.6250 - mean_squared_error: 671636.6250\n",
      "Epoch 845/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 671362.6250 - mean_squared_error: 671362.6250\n",
      "Epoch 846/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 667642.1250 - mean_squared_error: 667642.1250\n",
      "Epoch 847/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 668445.3750 - mean_squared_error: 668445.3750\n",
      "Epoch 848/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 672241.1875 - mean_squared_error: 672241.1875\n",
      "Epoch 849/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 660750.5000 - mean_squared_error: 660750.5000\n",
      "Epoch 850/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 666990.1875 - mean_squared_error: 666990.1875\n",
      "Epoch 851/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 665936.0000 - mean_squared_error: 665936.0000\n",
      "Epoch 852/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 664642.0000 - mean_squared_error: 664642.0000\n",
      "Epoch 853/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 661229.0000 - mean_squared_error: 661229.0000\n",
      "Epoch 854/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 665438.2500 - mean_squared_error: 665438.2500\n",
      "Epoch 855/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 667783.0000 - mean_squared_error: 667782.9375\n",
      "Epoch 856/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 659849.0625 - mean_squared_error: 659849.0625\n",
      "Epoch 857/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 666489.7500 - mean_squared_error: 666489.7500\n",
      "Epoch 858/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 663115.0000 - mean_squared_error: 663115.0000\n",
      "Epoch 859/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 667292.0000 - mean_squared_error: 667292.0000\n",
      "Epoch 860/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660933.6875 - mean_squared_error: 660933.6875\n",
      "Epoch 861/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 661450.3750 - mean_squared_error: 661450.3750\n",
      "Epoch 862/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 662040.7500 - mean_squared_error: 662040.8125\n",
      "Epoch 863/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 660146.4375 - mean_squared_error: 660146.4375\n",
      "Epoch 864/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660713.2500 - mean_squared_error: 660713.2500\n",
      "Epoch 865/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 664664.0625 - mean_squared_error: 664664.0625\n",
      "Epoch 866/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 649859.8125 - mean_squared_error: 649859.8125\n",
      "Epoch 867/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 657060.4375 - mean_squared_error: 657060.3750\n",
      "Epoch 868/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 655366.3750 - mean_squared_error: 655366.3750\n",
      "Epoch 869/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 653747.7500 - mean_squared_error: 653747.7500\n",
      "Epoch 870/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 662636.6875 - mean_squared_error: 662636.6875\n",
      "Epoch 871/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 655547.3125 - mean_squared_error: 655547.3125\n",
      "Epoch 872/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 648827.4375 - mean_squared_error: 648827.4375\n",
      "Epoch 873/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 648857.5625 - mean_squared_error: 648857.5625\n",
      "Epoch 874/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 646169.5625 - mean_squared_error: 646169.5625\n",
      "Epoch 875/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 651471.6250 - mean_squared_error: 651471.6250\n",
      "Epoch 876/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 652459.5625 - mean_squared_error: 652459.5625\n",
      "Epoch 877/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 647983.4375 - mean_squared_error: 647983.4375\n",
      "Epoch 878/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 652881.8125 - mean_squared_error: 652881.8125\n",
      "Epoch 879/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 653535.3125 - mean_squared_error: 653535.3125\n",
      "Epoch 880/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 651340.5000 - mean_squared_error: 651340.5000\n",
      "Epoch 881/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 650556.3125 - mean_squared_error: 650556.3125\n",
      "Epoch 882/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 646075.1250 - mean_squared_error: 646075.1250\n",
      "Epoch 883/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 649242.6875 - mean_squared_error: 649242.6875\n",
      "Epoch 884/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 644634.0625 - mean_squared_error: 644634.0625\n",
      "Epoch 885/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 649426.9375 - mean_squared_error: 649426.9375\n",
      "Epoch 886/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 643011.4375 - mean_squared_error: 643011.4375\n",
      "Epoch 887/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 656686.9375 - mean_squared_error: 656686.9375\n",
      "Epoch 888/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 639253.5625 - mean_squared_error: 639253.5625\n",
      "Epoch 889/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 642839.1875 - mean_squared_error: 642839.1875\n",
      "Epoch 890/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 642562.3125 - mean_squared_error: 642562.3125\n",
      "Epoch 891/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 642762.3125 - mean_squared_error: 642762.3125\n",
      "Epoch 892/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 646026.1875 - mean_squared_error: 646026.1875\n",
      "Epoch 893/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 641313.1875 - mean_squared_error: 641313.1875\n",
      "Epoch 894/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 642971.5625 - mean_squared_error: 642971.5625\n",
      "Epoch 895/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 639040.6250 - mean_squared_error: 639040.6250\n",
      "Epoch 896/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635961.1250 - mean_squared_error: 635961.1250\n",
      "Epoch 897/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 641730.8125 - mean_squared_error: 641730.8125\n",
      "Epoch 898/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638342.8750 - mean_squared_error: 638342.8750\n",
      "Epoch 899/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 637793.8125 - mean_squared_error: 637793.8125\n",
      "Epoch 900/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638704.2500 - mean_squared_error: 638704.3125\n",
      "Epoch 901/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638968.1250 - mean_squared_error: 638968.1250\n",
      "Epoch 902/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 641156.7500 - mean_squared_error: 641156.7500\n",
      "Epoch 903/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 640735.4375 - mean_squared_error: 640735.4375\n",
      "Epoch 904/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635734.9375 - mean_squared_error: 635734.9375\n",
      "Epoch 905/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 636678.7500 - mean_squared_error: 636678.7500\n",
      "Epoch 906/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635590.7500 - mean_squared_error: 635590.7500\n",
      "Epoch 907/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 633887.5625 - mean_squared_error: 633887.5625\n",
      "Epoch 908/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 641261.3125 - mean_squared_error: 641261.3125\n",
      "Epoch 909/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 631975.0625 - mean_squared_error: 631975.0625\n",
      "Epoch 910/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 633891.8125 - mean_squared_error: 633891.8125\n",
      "Epoch 911/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 633712.2500 - mean_squared_error: 633712.2500\n",
      "Epoch 912/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 632102.8750 - mean_squared_error: 632102.8750\n",
      "Epoch 913/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 633463.8125 - mean_squared_error: 633463.8125\n",
      "Epoch 914/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 625964.8750 - mean_squared_error: 625964.8750\n",
      "Epoch 915/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 632228.5625 - mean_squared_error: 632228.5625\n",
      "Epoch 916/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 630513.6875 - mean_squared_error: 630513.6875\n",
      "Epoch 917/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 627789.4375 - mean_squared_error: 627789.4375\n",
      "Epoch 918/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 633306.0625 - mean_squared_error: 633306.0625\n",
      "Epoch 919/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 629818.3750 - mean_squared_error: 629818.3750\n",
      "Epoch 920/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 632785.0000 - mean_squared_error: 632785.0000\n",
      "Epoch 921/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 629537.3750 - mean_squared_error: 629537.3750\n",
      "Epoch 922/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 627435.2500 - mean_squared_error: 627435.2500\n",
      "Epoch 923/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 624213.6875 - mean_squared_error: 624213.6875\n",
      "Epoch 924/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 632199.5625 - mean_squared_error: 632199.5625\n",
      "Epoch 925/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 627678.8125 - mean_squared_error: 627678.8125\n",
      "Epoch 926/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 624659.2500 - mean_squared_error: 624659.2500\n",
      "Epoch 927/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 628803.1875 - mean_squared_error: 628803.1875\n",
      "Epoch 928/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 625325.2500 - mean_squared_error: 625325.2500\n",
      "Epoch 929/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 627289.2500 - mean_squared_error: 627289.2500\n",
      "Epoch 930/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 624726.4375 - mean_squared_error: 624726.4375\n",
      "Epoch 931/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 616710.3125 - mean_squared_error: 616710.3125\n",
      "Epoch 932/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 619659.2500 - mean_squared_error: 619659.2500\n",
      "Epoch 933/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 621370.1250 - mean_squared_error: 621370.1250\n",
      "Epoch 934/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 623038.5625 - mean_squared_error: 623038.5625\n",
      "Epoch 935/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 627308.3125 - mean_squared_error: 627308.3125\n",
      "Epoch 936/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 619036.4375 - mean_squared_error: 619036.4375\n",
      "Epoch 937/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 615874.8750 - mean_squared_error: 615874.8750\n",
      "Epoch 938/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 616337.3750 - mean_squared_error: 616337.3750\n",
      "Epoch 939/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 621763.9375 - mean_squared_error: 621763.9375\n",
      "Epoch 940/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 620126.0000 - mean_squared_error: 620126.0000\n",
      "Epoch 941/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 617606.8125 - mean_squared_error: 617606.8125\n",
      "Epoch 942/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 621361.3125 - mean_squared_error: 621361.3125\n",
      "Epoch 943/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 619686.5000 - mean_squared_error: 619686.5000\n",
      "Epoch 944/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 614119.8125 - mean_squared_error: 614119.8125\n",
      "Epoch 945/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 615056.8750 - mean_squared_error: 615056.8750\n",
      "Epoch 946/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 617291.3125 - mean_squared_error: 617291.3125\n",
      "Epoch 947/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 613739.2500 - mean_squared_error: 613739.2500\n",
      "Epoch 948/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 616177.9375 - mean_squared_error: 616177.9375\n",
      "Epoch 949/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 617256.5000 - mean_squared_error: 617256.5000\n",
      "Epoch 950/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 616414.9375 - mean_squared_error: 616414.9375\n",
      "Epoch 951/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 616017.6250 - mean_squared_error: 616017.6250\n",
      "Epoch 952/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 614988.9375 - mean_squared_error: 614988.9375\n",
      "Epoch 953/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 612147.4375 - mean_squared_error: 612147.4375\n",
      "Epoch 954/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 610672.0000 - mean_squared_error: 610672.0000\n",
      "Epoch 955/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 604922.8750 - mean_squared_error: 604922.8750\n",
      "Epoch 956/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 610041.3125 - mean_squared_error: 610041.3125\n",
      "Epoch 957/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 610879.1875 - mean_squared_error: 610879.1875\n",
      "Epoch 958/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 612983.5625 - mean_squared_error: 612983.5625\n",
      "Epoch 959/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 609929.0625 - mean_squared_error: 609929.0625\n",
      "Epoch 960/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 607951.6875 - mean_squared_error: 607951.6875\n",
      "Epoch 961/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 604993.3125 - mean_squared_error: 604993.3125\n",
      "Epoch 962/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 603165.7500 - mean_squared_error: 603165.7500\n",
      "Epoch 963/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 608752.0000 - mean_squared_error: 608752.0000\n",
      "Epoch 964/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 605276.4375 - mean_squared_error: 605276.4375\n",
      "Epoch 965/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 603157.5000 - mean_squared_error: 603157.5000\n",
      "Epoch 966/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 605265.6875 - mean_squared_error: 605265.6875\n",
      "Epoch 967/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 605383.3750 - mean_squared_error: 605383.3750\n",
      "Epoch 968/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 606762.1250 - mean_squared_error: 606762.1250\n",
      "Epoch 969/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 603247.3750 - mean_squared_error: 603247.3750\n",
      "Epoch 970/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 602386.9375 - mean_squared_error: 602386.9375\n",
      "Epoch 971/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 598937.3125 - mean_squared_error: 598937.3125\n",
      "Epoch 972/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 601129.0000 - mean_squared_error: 601129.0000\n",
      "Epoch 973/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 602983.2500 - mean_squared_error: 602983.2500\n",
      "Epoch 974/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 602256.5000 - mean_squared_error: 602256.5000\n",
      "Epoch 975/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 593493.8125 - mean_squared_error: 593493.8125\n",
      "Epoch 976/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 595467.7500 - mean_squared_error: 595467.7500\n",
      "Epoch 977/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 596787.3750 - mean_squared_error: 596787.3125\n",
      "Epoch 978/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 595402.9375 - mean_squared_error: 595402.9375\n",
      "Epoch 979/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 595703.6875 - mean_squared_error: 595703.6875\n",
      "Epoch 980/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 595784.5000 - mean_squared_error: 595784.5000\n",
      "Epoch 981/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 592435.4375 - mean_squared_error: 592435.4375\n",
      "Epoch 982/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 598399.1250 - mean_squared_error: 598399.1250\n",
      "Epoch 983/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 596594.9375 - mean_squared_error: 596594.9375\n",
      "Epoch 984/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 594834.2500 - mean_squared_error: 594834.2500\n",
      "Epoch 985/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 597145.4375 - mean_squared_error: 597145.4375\n",
      "Epoch 986/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 591320.3750 - mean_squared_error: 591320.3750\n",
      "Epoch 987/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 593854.6875 - mean_squared_error: 593854.6875\n",
      "Epoch 988/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 593102.8750 - mean_squared_error: 593102.8750\n",
      "Epoch 989/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 594344.0000 - mean_squared_error: 594344.0000\n",
      "Epoch 990/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 588060.0000 - mean_squared_error: 588060.0000\n",
      "Epoch 991/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 593362.1250 - mean_squared_error: 593362.1250\n",
      "Epoch 992/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 591305.5000 - mean_squared_error: 591305.5000\n",
      "Epoch 993/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 586700.0000 - mean_squared_error: 586700.0000\n",
      "Epoch 994/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 589748.8750 - mean_squared_error: 589748.8750\n",
      "Epoch 995/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 587924.3125 - mean_squared_error: 587924.3125\n",
      "Epoch 996/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 589416.0625 - mean_squared_error: 589416.0625\n",
      "Epoch 997/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 587566.1250 - mean_squared_error: 587566.1250\n",
      "Epoch 998/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 584430.3750 - mean_squared_error: 584430.3750\n",
      "Epoch 999/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582144.7500 - mean_squared_error: 582144.7500\n",
      "Epoch 1000/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 584981.2500 - mean_squared_error: 584981.3125\n",
      "Epoch 1001/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 584958.0625 - mean_squared_error: 584958.0625\n",
      "Epoch 1002/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 588141.8125 - mean_squared_error: 588141.8125\n",
      "Epoch 1003/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 588135.3750 - mean_squared_error: 588135.3750\n",
      "Epoch 1004/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 582007.4375 - mean_squared_error: 582007.4375\n",
      "Epoch 1005/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 582127.2500 - mean_squared_error: 582127.2500\n",
      "Epoch 1006/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 584523.3125 - mean_squared_error: 584523.3125\n",
      "Epoch 1007/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582415.8125 - mean_squared_error: 582415.8125\n",
      "Epoch 1008/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 581979.0000 - mean_squared_error: 581979.0000\n",
      "Epoch 1009/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 586201.3125 - mean_squared_error: 586201.3125\n",
      "Epoch 1010/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 579346.5625 - mean_squared_error: 579346.5625\n",
      "Epoch 1011/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582536.1250 - mean_squared_error: 582536.1250\n",
      "Epoch 1012/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 577533.2500 - mean_squared_error: 577533.2500\n",
      "Epoch 1013/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 581713.0000 - mean_squared_error: 581713.0000\n",
      "Epoch 1014/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 577859.8125 - mean_squared_error: 577859.8125\n",
      "Epoch 1015/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 579122.8125 - mean_squared_error: 579122.8125\n",
      "Epoch 1016/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 576488.8750 - mean_squared_error: 576488.8750\n",
      "Epoch 1017/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 580450.6250 - mean_squared_error: 580450.5625\n",
      "Epoch 1018/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 575681.4375 - mean_squared_error: 575681.4375\n",
      "Epoch 1019/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 580929.7500 - mean_squared_error: 580929.7500\n",
      "Epoch 1020/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 575974.9375 - mean_squared_error: 575974.9375\n",
      "Epoch 1021/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 566131.5625 - mean_squared_error: 566131.5625\n",
      "Epoch 1022/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 579360.2500 - mean_squared_error: 579360.2500\n",
      "Epoch 1023/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 570225.5625 - mean_squared_error: 570225.5625\n",
      "Epoch 1024/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 577312.0000 - mean_squared_error: 577312.0000\n",
      "Epoch 1025/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 572404.7500 - mean_squared_error: 572404.7500\n",
      "Epoch 1026/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 574845.6250 - mean_squared_error: 574845.6250\n",
      "Epoch 1027/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 573513.0000 - mean_squared_error: 573513.0000\n",
      "Epoch 1028/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 567018.9375 - mean_squared_error: 567018.9375\n",
      "Epoch 1029/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 573789.5625 - mean_squared_error: 573789.5625\n",
      "Epoch 1030/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 575815.3750 - mean_squared_error: 575815.3750\n",
      "Epoch 1031/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 573895.2500 - mean_squared_error: 573895.2500\n",
      "Epoch 1032/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 570666.5625 - mean_squared_error: 570666.5625\n",
      "Epoch 1033/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 574128.5000 - mean_squared_error: 574128.5000\n",
      "Epoch 1034/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 566734.0625 - mean_squared_error: 566734.0625\n",
      "Epoch 1035/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 571536.5625 - mean_squared_error: 571536.5625\n",
      "Epoch 1036/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 570116.6250 - mean_squared_error: 570116.6250\n",
      "Epoch 1037/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 573234.3125 - mean_squared_error: 573234.3125\n",
      "Epoch 1038/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 568084.5000 - mean_squared_error: 568084.5000\n",
      "Epoch 1039/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 565876.5000 - mean_squared_error: 565876.5000\n",
      "Epoch 1040/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 572453.1250 - mean_squared_error: 572453.1250\n",
      "Epoch 1041/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 566677.6875 - mean_squared_error: 566677.7500\n",
      "Epoch 1042/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 567477.6250 - mean_squared_error: 567477.6250\n",
      "Epoch 1043/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 567117.0625 - mean_squared_error: 567117.0625\n",
      "Epoch 1044/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 568464.2500 - mean_squared_error: 568464.2500\n",
      "Epoch 1045/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 566072.1875 - mean_squared_error: 566072.1875\n",
      "Epoch 1046/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 564373.6875 - mean_squared_error: 564373.6875\n",
      "Epoch 1047/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 564195.1250 - mean_squared_error: 564195.1250\n",
      "Epoch 1048/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 563932.2500 - mean_squared_error: 563932.3125\n",
      "Epoch 1049/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 560171.3750 - mean_squared_error: 560171.3750\n",
      "Epoch 1050/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 567952.3125 - mean_squared_error: 567952.3125\n",
      "Epoch 1051/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 566819.6250 - mean_squared_error: 566819.6250\n",
      "Epoch 1052/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 560620.0625 - mean_squared_error: 560620.0000\n",
      "Epoch 1053/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 559007.8125 - mean_squared_error: 559007.8125\n",
      "Epoch 1054/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 561944.4375 - mean_squared_error: 561944.4375\n",
      "Epoch 1055/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 563001.5625 - mean_squared_error: 563001.5625\n",
      "Epoch 1056/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 568649.3750 - mean_squared_error: 568649.3750\n",
      "Epoch 1057/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 562214.3125 - mean_squared_error: 562214.3125\n",
      "Epoch 1058/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 564752.2500 - mean_squared_error: 564752.2500\n",
      "Epoch 1059/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 559491.1875 - mean_squared_error: 559491.1875\n",
      "Epoch 1060/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 559528.1875 - mean_squared_error: 559528.1875\n",
      "Epoch 1061/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 555722.0625 - mean_squared_error: 555722.0625\n",
      "Epoch 1062/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 556557.0625 - mean_squared_error: 556557.0625\n",
      "Epoch 1063/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 555455.1875 - mean_squared_error: 555455.1875\n",
      "Epoch 1064/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 557340.5000 - mean_squared_error: 557340.5000\n",
      "Epoch 1065/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 558156.3750 - mean_squared_error: 558156.3750\n",
      "Epoch 1066/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 560941.1250 - mean_squared_error: 560941.1250\n",
      "Epoch 1067/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 559473.8125 - mean_squared_error: 559473.8125\n",
      "Epoch 1068/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 556202.8750 - mean_squared_error: 556202.8750\n",
      "Epoch 1069/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 552067.4375 - mean_squared_error: 552067.4375\n",
      "Epoch 1070/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 559904.4375 - mean_squared_error: 559904.4375\n",
      "Epoch 1071/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 554933.7500 - mean_squared_error: 554933.7500\n",
      "Epoch 1072/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 556891.3750 - mean_squared_error: 556891.3750\n",
      "Epoch 1073/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 551776.1250 - mean_squared_error: 551776.1250\n",
      "Epoch 1074/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 551887.3125 - mean_squared_error: 551887.3125\n",
      "Epoch 1075/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 554389.7500 - mean_squared_error: 554389.7500\n",
      "Epoch 1076/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 553975.8125 - mean_squared_error: 553975.8125\n",
      "Epoch 1077/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 549544.6250 - mean_squared_error: 549544.6250\n",
      "Epoch 1078/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 550567.5000 - mean_squared_error: 550567.5000\n",
      "Epoch 1079/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 551480.0625 - mean_squared_error: 551480.0625\n",
      "Epoch 1080/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 553068.6250 - mean_squared_error: 553068.6250\n",
      "Epoch 1081/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 547938.8125 - mean_squared_error: 547938.8125\n",
      "Epoch 1082/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 549830.3125 - mean_squared_error: 549830.3125\n",
      "Epoch 1083/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 543171.9375 - mean_squared_error: 543171.9375\n",
      "Epoch 1084/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 549732.5000 - mean_squared_error: 549732.5000\n",
      "Epoch 1085/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 547840.9375 - mean_squared_error: 547840.9375\n",
      "Epoch 1086/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 549199.8125 - mean_squared_error: 549199.8125\n",
      "Epoch 1087/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 551040.0000 - mean_squared_error: 551040.0000\n",
      "Epoch 1088/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 549144.9375 - mean_squared_error: 549145.0000\n",
      "Epoch 1089/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 542890.5000 - mean_squared_error: 542890.5000\n",
      "Epoch 1090/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 549612.3125 - mean_squared_error: 549612.3125\n",
      "Epoch 1091/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 551202.3125 - mean_squared_error: 551202.3125\n",
      "Epoch 1092/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 548199.0000 - mean_squared_error: 548199.0000\n",
      "Epoch 1093/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 538995.9375 - mean_squared_error: 538995.9375\n",
      "Epoch 1094/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 546367.8750 - mean_squared_error: 546367.8750\n",
      "Epoch 1095/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 542466.6250 - mean_squared_error: 542466.6250\n",
      "Epoch 1096/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 548941.9375 - mean_squared_error: 548941.9375\n",
      "Epoch 1097/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 541177.6875 - mean_squared_error: 541177.6875\n",
      "Epoch 1098/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 543550.8125 - mean_squared_error: 543550.8125\n",
      "Epoch 1099/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 547441.0625 - mean_squared_error: 547441.0625\n",
      "Epoch 1100/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 545222.8125 - mean_squared_error: 545222.8125\n",
      "Epoch 1101/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 541451.1875 - mean_squared_error: 541451.1875\n",
      "Epoch 1102/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 540078.8750 - mean_squared_error: 540078.8750\n",
      "Epoch 1103/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 540400.3125 - mean_squared_error: 540400.3125\n",
      "Epoch 1104/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 539560.3125 - mean_squared_error: 539560.3125\n",
      "Epoch 1105/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 543601.9375 - mean_squared_error: 543602.0000\n",
      "Epoch 1106/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 539354.0000 - mean_squared_error: 539354.0000\n",
      "Epoch 1107/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 541361.1250 - mean_squared_error: 541361.1250\n",
      "Epoch 1108/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 533480.3750 - mean_squared_error: 533480.3750\n",
      "Epoch 1109/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 529105.9375 - mean_squared_error: 529105.9375\n",
      "Epoch 1110/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 538427.6250 - mean_squared_error: 538427.6250\n",
      "Epoch 1111/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 537282.8125 - mean_squared_error: 537282.8125\n",
      "Epoch 1112/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 537223.2500 - mean_squared_error: 537223.2500\n",
      "Epoch 1113/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 532433.0625 - mean_squared_error: 532433.0625\n",
      "Epoch 1114/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 538962.9375 - mean_squared_error: 538962.9375\n",
      "Epoch 1115/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 534255.8125 - mean_squared_error: 534255.8125\n",
      "Epoch 1116/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 531169.1875 - mean_squared_error: 531169.1875\n",
      "Epoch 1117/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 531491.8750 - mean_squared_error: 531491.8750\n",
      "Epoch 1118/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 536291.6875 - mean_squared_error: 536291.6875\n",
      "Epoch 1119/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 533776.3750 - mean_squared_error: 533776.3750\n",
      "Epoch 1120/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 532358.0625 - mean_squared_error: 532358.0625\n",
      "Epoch 1121/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 537081.6250 - mean_squared_error: 537081.6250\n",
      "Epoch 1122/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 530026.1250 - mean_squared_error: 530026.1250\n",
      "Epoch 1123/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 531758.8750 - mean_squared_error: 531758.8750\n",
      "Epoch 1124/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 533379.2500 - mean_squared_error: 533379.2500\n",
      "Epoch 1125/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 525762.6875 - mean_squared_error: 525762.6875\n",
      "Epoch 1126/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 529662.3125 - mean_squared_error: 529662.3125\n",
      "Epoch 1127/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 526327.5000 - mean_squared_error: 526327.5000\n",
      "Epoch 1128/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 531562.8750 - mean_squared_error: 531562.8750\n",
      "Epoch 1129/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 530989.9375 - mean_squared_error: 530989.9375\n",
      "Epoch 1130/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 533145.6250 - mean_squared_error: 533145.5625\n",
      "Epoch 1131/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 531650.1250 - mean_squared_error: 531650.1250\n",
      "Epoch 1132/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 523847.9062 - mean_squared_error: 523847.9062\n",
      "Epoch 1133/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 527103.4375 - mean_squared_error: 527103.4375\n",
      "Epoch 1134/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 526358.9375 - mean_squared_error: 526358.9375\n",
      "Epoch 1135/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 530053.0000 - mean_squared_error: 530053.0000\n",
      "Epoch 1136/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 526665.3750 - mean_squared_error: 526665.3750\n",
      "Epoch 1137/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 524764.0000 - mean_squared_error: 524764.0000\n",
      "Epoch 1138/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 524564.8125 - mean_squared_error: 524564.8125\n",
      "Epoch 1139/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 527002.5000 - mean_squared_error: 527002.5000\n",
      "Epoch 1140/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 527195.6250 - mean_squared_error: 527195.6250\n",
      "Epoch 1141/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 519169.9062 - mean_squared_error: 519169.9062\n",
      "Epoch 1142/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 527220.6875 - mean_squared_error: 527220.6875\n",
      "Epoch 1143/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 526357.6875 - mean_squared_error: 526357.6875\n",
      "Epoch 1144/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 520533.6562 - mean_squared_error: 520533.6562\n",
      "Epoch 1145/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 522753.2188 - mean_squared_error: 522753.2188\n",
      "Epoch 1146/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 525019.8750 - mean_squared_error: 525019.8750\n",
      "Epoch 1147/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 521832.3750 - mean_squared_error: 521832.3750\n",
      "Epoch 1148/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 526451.5625 - mean_squared_error: 526451.5625\n",
      "Epoch 1149/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 524194.2500 - mean_squared_error: 524194.2500\n",
      "Epoch 1150/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 514453.1562 - mean_squared_error: 514453.1562\n",
      "Epoch 1151/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 523996.6875 - mean_squared_error: 523996.6875\n",
      "Epoch 1152/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 517080.2188 - mean_squared_error: 517080.2188\n",
      "Epoch 1153/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 515263.9375 - mean_squared_error: 515263.9375\n",
      "Epoch 1154/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 521893.9375 - mean_squared_error: 521893.9375\n",
      "Epoch 1155/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 518884.2188 - mean_squared_error: 518884.2188\n",
      "Epoch 1156/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 515953.1250 - mean_squared_error: 515953.1250\n",
      "Epoch 1157/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 522169.9375 - mean_squared_error: 522169.9375\n",
      "Epoch 1158/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 517257.6562 - mean_squared_error: 517257.6562\n",
      "Epoch 1159/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 521235.4688 - mean_squared_error: 521235.4688\n",
      "Epoch 1160/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 518280.1875 - mean_squared_error: 518280.1875\n",
      "Epoch 1161/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 519803.7188 - mean_squared_error: 519803.7188\n",
      "Epoch 1162/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 514359.7500 - mean_squared_error: 514359.7500\n",
      "Epoch 1163/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 530003.9375 - mean_squared_error: 530003.9375\n",
      "Epoch 1164/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 514693.5000 - mean_squared_error: 514693.5000\n",
      "Epoch 1165/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 516525.7188 - mean_squared_error: 516525.7188\n",
      "Epoch 1166/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 513444.5938 - mean_squared_error: 513444.5938\n",
      "Epoch 1167/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511936.3438 - mean_squared_error: 511936.3438\n",
      "Epoch 1168/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 509577.8438 - mean_squared_error: 509577.8438\n",
      "Epoch 1169/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 517302.0938 - mean_squared_error: 517302.0938\n",
      "Epoch 1170/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 517491.4062 - mean_squared_error: 517491.4062\n",
      "Epoch 1171/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511555.8125 - mean_squared_error: 511555.8125\n",
      "Epoch 1172/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 508659.1250 - mean_squared_error: 508659.1250\n",
      "Epoch 1173/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 509637.7500 - mean_squared_error: 509637.7500\n",
      "Epoch 1174/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 512635.6250 - mean_squared_error: 512635.6250\n",
      "Epoch 1175/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 512705.4688 - mean_squared_error: 512705.4688\n",
      "Epoch 1176/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 514024.4375 - mean_squared_error: 514024.4375\n",
      "Epoch 1177/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 508361.6875 - mean_squared_error: 508361.6875\n",
      "Epoch 1178/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 510453.2188 - mean_squared_error: 510453.2188\n",
      "Epoch 1179/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 504502.1875 - mean_squared_error: 504502.2188\n",
      "Epoch 1180/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 500400.4688 - mean_squared_error: 500400.4688\n",
      "Epoch 1181/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 510700.9062 - mean_squared_error: 510700.9062\n",
      "Epoch 1182/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 506573.2188 - mean_squared_error: 506573.2188\n",
      "Epoch 1183/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 506291.8125 - mean_squared_error: 506291.8125\n",
      "Epoch 1184/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 506705.9062 - mean_squared_error: 506705.9062\n",
      "Epoch 1185/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 506599.9062 - mean_squared_error: 506599.9062\n",
      "Epoch 1186/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 509496.6562 - mean_squared_error: 509496.6562\n",
      "Epoch 1187/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 504773.5625 - mean_squared_error: 504773.5625\n",
      "Epoch 1188/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 504912.7500 - mean_squared_error: 504912.7500\n",
      "Epoch 1189/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 507980.2500 - mean_squared_error: 507980.2500\n",
      "Epoch 1190/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511441.8750 - mean_squared_error: 511441.8750\n",
      "Epoch 1191/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 503126.3750 - mean_squared_error: 503126.3750\n",
      "Epoch 1192/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 506125.5000 - mean_squared_error: 506125.5000\n",
      "Epoch 1193/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 504991.3125 - mean_squared_error: 504991.3125\n",
      "Epoch 1194/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499848.1875 - mean_squared_error: 499848.1875\n",
      "Epoch 1195/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 496541.1250 - mean_squared_error: 496541.1250\n",
      "Epoch 1196/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502412.7812 - mean_squared_error: 502412.7812\n",
      "Epoch 1197/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 501659.0312 - mean_squared_error: 501659.0312\n",
      "Epoch 1198/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 503201.3750 - mean_squared_error: 503201.3125\n",
      "Epoch 1199/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 498757.5000 - mean_squared_error: 498757.5000\n",
      "Epoch 1200/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 502089.3750 - mean_squared_error: 502089.3750\n",
      "Epoch 1201/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500423.4688 - mean_squared_error: 500423.4688\n",
      "Epoch 1202/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500552.8125 - mean_squared_error: 500552.8125\n",
      "Epoch 1203/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502711.2812 - mean_squared_error: 502711.3125\n",
      "Epoch 1204/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502200.3125 - mean_squared_error: 502200.3125\n",
      "Epoch 1205/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502283.4375 - mean_squared_error: 502283.4375\n",
      "Epoch 1206/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 494324.4375 - mean_squared_error: 494324.4375\n",
      "Epoch 1207/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 498582.6250 - mean_squared_error: 498582.6250\n",
      "Epoch 1208/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 498447.8438 - mean_squared_error: 498447.8438\n",
      "Epoch 1209/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 493862.3125 - mean_squared_error: 493862.3125\n",
      "Epoch 1210/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500474.2188 - mean_squared_error: 500474.2188\n",
      "Epoch 1211/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 494701.0312 - mean_squared_error: 494701.0312\n",
      "Epoch 1212/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 497061.5312 - mean_squared_error: 497061.5312\n",
      "Epoch 1213/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 496798.5938 - mean_squared_error: 496798.5938\n",
      "Epoch 1214/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 499117.7812 - mean_squared_error: 499117.7500\n",
      "Epoch 1215/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 494221.3438 - mean_squared_error: 494221.3438\n",
      "Epoch 1216/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 504350.6562 - mean_squared_error: 504350.6562\n",
      "Epoch 1217/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 498542.3750 - mean_squared_error: 498542.3750\n",
      "Epoch 1218/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492297.4062 - mean_squared_error: 492297.4062\n",
      "Epoch 1219/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 497436.2812 - mean_squared_error: 497436.2812\n",
      "Epoch 1220/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 494931.5625 - mean_squared_error: 494931.5625\n",
      "Epoch 1221/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 503553.1250 - mean_squared_error: 503553.1250\n",
      "Epoch 1222/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 491279.5312 - mean_squared_error: 491279.4688\n",
      "Epoch 1223/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 493023.7188 - mean_squared_error: 493023.7188\n",
      "Epoch 1224/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 499127.1562 - mean_squared_error: 499127.1562\n",
      "Epoch 1225/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 489186.6875 - mean_squared_error: 489186.6875\n",
      "Epoch 1226/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 495137.7188 - mean_squared_error: 495137.7188\n",
      "Epoch 1227/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 491913.7188 - mean_squared_error: 491913.7188\n",
      "Epoch 1228/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 496553.4375 - mean_squared_error: 496553.4688\n",
      "Epoch 1229/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 487934.1562 - mean_squared_error: 487934.1562\n",
      "Epoch 1230/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 493356.3125 - mean_squared_error: 493356.3125\n",
      "Epoch 1231/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492104.3750 - mean_squared_error: 492104.3438\n",
      "Epoch 1232/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 488953.0000 - mean_squared_error: 488953.0000\n",
      "Epoch 1233/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 490158.2500 - mean_squared_error: 490158.2500\n",
      "Epoch 1234/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 493228.6875 - mean_squared_error: 493228.6875\n",
      "Epoch 1235/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 488630.8125 - mean_squared_error: 488630.8125\n",
      "Epoch 1236/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 487014.0938 - mean_squared_error: 487014.0938\n",
      "Epoch 1237/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492176.4375 - mean_squared_error: 492176.4375\n",
      "Epoch 1238/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 488836.0312 - mean_squared_error: 488836.0312\n",
      "Epoch 1239/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 491362.5625 - mean_squared_error: 491362.5625\n",
      "Epoch 1240/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 482564.5938 - mean_squared_error: 482564.5938\n",
      "Epoch 1241/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 488933.5938 - mean_squared_error: 488933.5938\n",
      "Epoch 1242/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 493111.2812 - mean_squared_error: 493111.2812\n",
      "Epoch 1243/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 488139.7500 - mean_squared_error: 488139.7500\n",
      "Epoch 1244/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 486148.7812 - mean_squared_error: 486148.7812\n",
      "Epoch 1245/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 480179.4062 - mean_squared_error: 480179.3438\n",
      "Epoch 1246/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 485772.8750 - mean_squared_error: 485772.8750\n",
      "Epoch 1247/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 487790.0312 - mean_squared_error: 487790.0312\n",
      "Epoch 1248/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 487039.7500 - mean_squared_error: 487039.7500\n",
      "Epoch 1249/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 481409.6562 - mean_squared_error: 481409.6562\n",
      "Epoch 1250/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 482758.5312 - mean_squared_error: 482758.5625\n",
      "Epoch 1251/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479928.0312 - mean_squared_error: 479928.0312\n",
      "Epoch 1252/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 489879.5938 - mean_squared_error: 489879.5938\n",
      "Epoch 1253/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 486286.2812 - mean_squared_error: 486286.2812\n",
      "Epoch 1254/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 485132.8125 - mean_squared_error: 485132.8125\n",
      "Epoch 1255/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 481471.6250 - mean_squared_error: 481471.6250\n",
      "Epoch 1256/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479734.6562 - mean_squared_error: 479734.6562\n",
      "Epoch 1257/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 479849.2500 - mean_squared_error: 479849.2500\n",
      "Epoch 1258/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 480464.5000 - mean_squared_error: 480464.5000\n",
      "Epoch 1259/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475573.4062 - mean_squared_error: 475573.4062\n",
      "Epoch 1260/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 480207.6875 - mean_squared_error: 480207.6875\n",
      "Epoch 1261/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 482805.2188 - mean_squared_error: 482805.1562\n",
      "Epoch 1262/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 481268.3438 - mean_squared_error: 481268.3438\n",
      "Epoch 1263/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 470104.5312 - mean_squared_error: 470104.5312\n",
      "Epoch 1264/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 478651.7188 - mean_squared_error: 478651.7188\n",
      "Epoch 1265/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 476012.8125 - mean_squared_error: 476012.8125\n",
      "Epoch 1266/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 484050.4375 - mean_squared_error: 484050.4375\n",
      "Epoch 1267/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 480539.6562 - mean_squared_error: 480539.6562\n",
      "Epoch 1268/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 480726.1250 - mean_squared_error: 480726.1250\n",
      "Epoch 1269/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 476335.5000 - mean_squared_error: 476335.5000\n",
      "Epoch 1270/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479954.0938 - mean_squared_error: 479954.0938\n",
      "Epoch 1271/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475166.1562 - mean_squared_error: 475166.1562\n",
      "Epoch 1272/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 476042.3750 - mean_squared_error: 476042.4062\n",
      "Epoch 1273/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 474559.6250 - mean_squared_error: 474559.6250\n",
      "Epoch 1274/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 474782.1875 - mean_squared_error: 474782.1875\n",
      "Epoch 1275/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 468503.1250 - mean_squared_error: 468503.1250\n",
      "Epoch 1276/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479133.0938 - mean_squared_error: 479133.1250\n",
      "Epoch 1277/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 476110.9688 - mean_squared_error: 476110.9688\n",
      "Epoch 1278/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 467736.5625 - mean_squared_error: 467736.5625\n",
      "Epoch 1279/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 477388.5312 - mean_squared_error: 477388.5312\n",
      "Epoch 1280/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475486.2812 - mean_squared_error: 475486.2812\n",
      "Epoch 1281/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470755.6250 - mean_squared_error: 470755.6250\n",
      "Epoch 1282/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 467663.6562 - mean_squared_error: 467663.6562\n",
      "Epoch 1283/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 474961.2500 - mean_squared_error: 474961.2500\n",
      "Epoch 1284/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 470696.5938 - mean_squared_error: 470696.5938\n",
      "Epoch 1285/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 472010.1875 - mean_squared_error: 472010.1875\n",
      "Epoch 1286/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 475696.7188 - mean_squared_error: 475696.7188\n",
      "Epoch 1287/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 468664.4688 - mean_squared_error: 468664.4688\n",
      "Epoch 1288/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 469648.0312 - mean_squared_error: 469648.0312\n",
      "Epoch 1289/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466438.8438 - mean_squared_error: 466438.8438\n",
      "Epoch 1290/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466672.3438 - mean_squared_error: 466672.3438\n",
      "Epoch 1291/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 472665.4062 - mean_squared_error: 472665.4062\n",
      "Epoch 1292/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 478102.6250 - mean_squared_error: 478102.6250\n",
      "Epoch 1293/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 474357.6562 - mean_squared_error: 474357.6562\n",
      "Epoch 1294/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 465307.8125 - mean_squared_error: 465307.8125\n",
      "Epoch 1295/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 478406.7812 - mean_squared_error: 478406.7500\n",
      "Epoch 1296/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 467832.1875 - mean_squared_error: 467832.1875\n",
      "Epoch 1297/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 473678.1250 - mean_squared_error: 473678.1250\n",
      "Epoch 1298/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 470804.7500 - mean_squared_error: 470804.7500\n",
      "Epoch 1299/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470767.2500 - mean_squared_error: 470767.2500\n",
      "Epoch 1300/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 469600.5000 - mean_squared_error: 469600.5000\n",
      "Epoch 1301/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 468355.5000 - mean_squared_error: 468355.5000\n",
      "Epoch 1302/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 471538.0000 - mean_squared_error: 471538.0000\n",
      "Epoch 1303/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466670.5625 - mean_squared_error: 466670.5625\n",
      "Epoch 1304/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 468538.5312 - mean_squared_error: 468538.5312\n",
      "Epoch 1305/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 463278.9375 - mean_squared_error: 463278.9375\n",
      "Epoch 1306/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 463138.7188 - mean_squared_error: 463138.7188\n",
      "Epoch 1307/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 464308.4062 - mean_squared_error: 464308.4062\n",
      "Epoch 1308/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 461987.0938 - mean_squared_error: 461987.0938\n",
      "Epoch 1309/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 461949.5625 - mean_squared_error: 461949.5625\n",
      "Epoch 1310/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 461743.3438 - mean_squared_error: 461743.3438\n",
      "Epoch 1311/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 458812.2812 - mean_squared_error: 458812.2812\n",
      "Epoch 1312/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466690.9688 - mean_squared_error: 466690.9688\n",
      "Epoch 1313/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 457394.3125 - mean_squared_error: 457394.3125\n",
      "Epoch 1314/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 459214.8125 - mean_squared_error: 459214.8125\n",
      "Epoch 1315/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 462631.5938 - mean_squared_error: 462631.5938\n",
      "Epoch 1316/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 458556.6875 - mean_squared_error: 458556.6875\n",
      "Epoch 1317/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 462781.6250 - mean_squared_error: 462781.6250\n",
      "Epoch 1318/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 462630.6562 - mean_squared_error: 462630.6562\n",
      "Epoch 1319/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 465171.3125 - mean_squared_error: 465171.3125\n",
      "Epoch 1320/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 454613.0312 - mean_squared_error: 454613.0312\n",
      "Epoch 1321/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 460605.5312 - mean_squared_error: 460605.5312\n",
      "Epoch 1322/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 457673.3750 - mean_squared_error: 457673.3750\n",
      "Epoch 1323/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 455322.3125 - mean_squared_error: 455322.3125\n",
      "Epoch 1324/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 462354.4375 - mean_squared_error: 462354.4375\n",
      "Epoch 1325/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 457670.7500 - mean_squared_error: 457670.7500\n",
      "Epoch 1326/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 462652.8125 - mean_squared_error: 462652.8125\n",
      "Epoch 1327/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 454181.8438 - mean_squared_error: 454181.8438\n",
      "Epoch 1328/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 454980.9062 - mean_squared_error: 454980.9062\n",
      "Epoch 1329/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 447657.5312 - mean_squared_error: 447657.5312\n",
      "Epoch 1330/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452374.8750 - mean_squared_error: 452374.8750\n",
      "Epoch 1331/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 455600.3438 - mean_squared_error: 455600.3438\n",
      "Epoch 1332/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452519.5312 - mean_squared_error: 452519.5312\n",
      "Epoch 1333/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 444961.9062 - mean_squared_error: 444961.9062\n",
      "Epoch 1334/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 449472.7812 - mean_squared_error: 449472.7812\n",
      "Epoch 1335/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447128.4062 - mean_squared_error: 447128.4062\n",
      "Epoch 1336/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 451472.9688 - mean_squared_error: 451472.9688\n",
      "Epoch 1337/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 441067.4375 - mean_squared_error: 441067.4375\n",
      "Epoch 1338/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 431728.5000 - mean_squared_error: 431728.5000\n",
      "Epoch 1339/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 467582.8438 - mean_squared_error: 467582.8438\n",
      "Epoch 1340/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 441409.5312 - mean_squared_error: 441409.5312\n",
      "Epoch 1341/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452734.8438 - mean_squared_error: 452734.8438\n",
      "Epoch 1342/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 449837.8125 - mean_squared_error: 449837.8125\n",
      "Epoch 1343/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 449483.1875 - mean_squared_error: 449483.1875\n",
      "Epoch 1344/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 454542.8438 - mean_squared_error: 454542.8438\n",
      "Epoch 1345/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 458613.0625 - mean_squared_error: 458613.0625\n",
      "Epoch 1346/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447454.0938 - mean_squared_error: 447454.0938\n",
      "Epoch 1347/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 448843.6875 - mean_squared_error: 448843.6875\n",
      "Epoch 1348/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 451185.2812 - mean_squared_error: 451185.2812\n",
      "Epoch 1349/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 453304.0938 - mean_squared_error: 453304.0938\n",
      "Epoch 1350/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 454570.7812 - mean_squared_error: 454570.7812\n",
      "Epoch 1351/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 452462.3750 - mean_squared_error: 452462.3750\n",
      "Epoch 1352/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 447177.7188 - mean_squared_error: 447177.7188\n",
      "Epoch 1353/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 449468.4375 - mean_squared_error: 449468.4375\n",
      "Epoch 1354/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 445487.7188 - mean_squared_error: 445487.7812\n",
      "Epoch 1355/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447029.8438 - mean_squared_error: 447029.8438\n",
      "Epoch 1356/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447766.1562 - mean_squared_error: 447766.1875\n",
      "Epoch 1357/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447725.2812 - mean_squared_error: 447725.2812\n",
      "Epoch 1358/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 450685.4688 - mean_squared_error: 450685.4688\n",
      "Epoch 1359/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 439871.9375 - mean_squared_error: 439871.9375\n",
      "Epoch 1360/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 445912.9688 - mean_squared_error: 445912.9688\n",
      "Epoch 1361/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 438075.2188 - mean_squared_error: 438075.2188\n",
      "Epoch 1362/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 450228.5000 - mean_squared_error: 450228.5000\n",
      "Epoch 1363/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 451992.9062 - mean_squared_error: 451992.9062\n",
      "Epoch 1364/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 448001.8125 - mean_squared_error: 448001.8125\n",
      "Epoch 1365/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 445663.6250 - mean_squared_error: 445663.6250\n",
      "Epoch 1366/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 449383.7188 - mean_squared_error: 449383.7188\n",
      "Epoch 1367/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 438929.1250 - mean_squared_error: 438929.1250\n",
      "Epoch 1368/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 439610.9688 - mean_squared_error: 439610.9688\n",
      "Epoch 1369/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 445932.3750 - mean_squared_error: 445932.3750\n",
      "Epoch 1370/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 446120.3125 - mean_squared_error: 446120.3125\n",
      "Epoch 1371/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 442002.7812 - mean_squared_error: 442002.7812\n",
      "Epoch 1372/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 442548.3438 - mean_squared_error: 442548.3438\n",
      "Epoch 1373/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 440527.1250 - mean_squared_error: 440527.1250\n",
      "Epoch 1374/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 440486.1250 - mean_squared_error: 440486.1250\n",
      "Epoch 1375/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 450716.9375 - mean_squared_error: 450716.9375\n",
      "Epoch 1376/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 443609.7188 - mean_squared_error: 443609.7188\n",
      "Epoch 1377/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 444703.0312 - mean_squared_error: 444703.0312\n",
      "Epoch 1378/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 438728.8438 - mean_squared_error: 438728.8438\n",
      "Epoch 1379/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 445789.5625 - mean_squared_error: 445789.5625\n",
      "Epoch 1380/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 445915.4062 - mean_squared_error: 445915.4062\n",
      "Epoch 1381/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 438194.1250 - mean_squared_error: 438194.1250\n",
      "Epoch 1382/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 433374.1875 - mean_squared_error: 433374.1875\n",
      "Epoch 1383/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 435662.5938 - mean_squared_error: 435662.5938\n",
      "Epoch 1384/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435994.4688 - mean_squared_error: 435994.4688\n",
      "Epoch 1385/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 441913.3438 - mean_squared_error: 441913.3438\n",
      "Epoch 1386/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435644.6875 - mean_squared_error: 435644.6875\n",
      "Epoch 1387/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 439071.5625 - mean_squared_error: 439071.5000\n",
      "Epoch 1388/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 440038.1562 - mean_squared_error: 440038.1562\n",
      "Epoch 1389/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 442023.1875 - mean_squared_error: 442023.1875\n",
      "Epoch 1390/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 439134.6250 - mean_squared_error: 439134.6250\n",
      "Epoch 1391/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 434386.8125 - mean_squared_error: 434386.8125\n",
      "Epoch 1392/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 439007.7500 - mean_squared_error: 439007.7500\n",
      "Epoch 1393/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 441913.1562 - mean_squared_error: 441913.1562\n",
      "Epoch 1394/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 441828.5625 - mean_squared_error: 441828.5625\n",
      "Epoch 1395/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 435147.1875 - mean_squared_error: 435147.1875\n",
      "Epoch 1396/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434469.7812 - mean_squared_error: 434469.7812\n",
      "Epoch 1397/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437420.2812 - mean_squared_error: 437420.2812\n",
      "Epoch 1398/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435724.9375 - mean_squared_error: 435724.9375\n",
      "Epoch 1399/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 440305.8750 - mean_squared_error: 440305.8750\n",
      "Epoch 1400/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435000.5000 - mean_squared_error: 435000.5000\n",
      "Epoch 1401/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 430597.2188 - mean_squared_error: 430597.2188\n",
      "Epoch 1402/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 429990.5312 - mean_squared_error: 429990.5312\n",
      "Epoch 1403/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 436801.6875 - mean_squared_error: 436801.6875\n",
      "Epoch 1404/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435776.3750 - mean_squared_error: 435776.3750\n",
      "Epoch 1405/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434603.1250 - mean_squared_error: 434603.1250\n",
      "Epoch 1406/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 431883.3438 - mean_squared_error: 431883.3438\n",
      "Epoch 1407/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 438059.6562 - mean_squared_error: 438059.6562\n",
      "Epoch 1408/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 434007.6562 - mean_squared_error: 434007.6562\n",
      "Epoch 1409/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 430912.1875 - mean_squared_error: 430912.1875\n",
      "Epoch 1410/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 429702.0938 - mean_squared_error: 429702.0938\n",
      "Epoch 1411/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 432964.2188 - mean_squared_error: 432964.2188\n",
      "Epoch 1412/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 430982.0000 - mean_squared_error: 430982.0000\n",
      "Epoch 1413/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 434471.6562 - mean_squared_error: 434471.6562\n",
      "Epoch 1414/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 428037.0938 - mean_squared_error: 428037.0938\n",
      "Epoch 1415/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 435080.4375 - mean_squared_error: 435080.4375\n",
      "Epoch 1416/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 438405.0938 - mean_squared_error: 438405.0938\n",
      "Epoch 1417/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 429993.4688 - mean_squared_error: 429993.4688\n",
      "Epoch 1418/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 426714.5000 - mean_squared_error: 426714.5000\n",
      "Epoch 1419/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434646.8438 - mean_squared_error: 434646.8750\n",
      "Epoch 1420/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 433762.6562 - mean_squared_error: 433762.6562\n",
      "Epoch 1421/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435864.4062 - mean_squared_error: 435864.4062\n",
      "Epoch 1422/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 427985.3438 - mean_squared_error: 427985.3125\n",
      "Epoch 1423/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 428704.9688 - mean_squared_error: 428704.9688\n",
      "Epoch 1424/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 429144.5000 - mean_squared_error: 429144.5000\n",
      "Epoch 1425/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427414.9062 - mean_squared_error: 427414.9062\n",
      "Epoch 1426/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 423569.9375 - mean_squared_error: 423569.9375\n",
      "Epoch 1427/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 426963.4688 - mean_squared_error: 426963.4688\n",
      "Epoch 1428/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 432195.6250 - mean_squared_error: 432195.6250\n",
      "Epoch 1429/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 426426.1875 - mean_squared_error: 426426.1875\n",
      "Epoch 1430/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 431384.7500 - mean_squared_error: 431384.7500\n",
      "Epoch 1431/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427624.7500 - mean_squared_error: 427624.7500\n",
      "Epoch 1432/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425491.2188 - mean_squared_error: 425491.2188\n",
      "Epoch 1433/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 423337.5312 - mean_squared_error: 423337.5312\n",
      "Epoch 1434/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425854.6875 - mean_squared_error: 425854.6875\n",
      "Epoch 1435/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 428870.9688 - mean_squared_error: 428870.9688\n",
      "Epoch 1436/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 417079.5938 - mean_squared_error: 417079.5938\n",
      "Epoch 1437/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 426848.7500 - mean_squared_error: 426848.7500\n",
      "Epoch 1438/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 421507.8750 - mean_squared_error: 421507.8750\n",
      "Epoch 1439/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 423041.9375 - mean_squared_error: 423041.9375\n",
      "Epoch 1440/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425042.2188 - mean_squared_error: 425042.2500\n",
      "Epoch 1441/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 421939.4688 - mean_squared_error: 421939.4688\n",
      "Epoch 1442/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 422476.1562 - mean_squared_error: 422476.1562\n",
      "Epoch 1443/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 428146.0625 - mean_squared_error: 428146.0625\n",
      "Epoch 1444/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 425797.0312 - mean_squared_error: 425797.0312\n",
      "Epoch 1445/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419871.9062 - mean_squared_error: 419871.9062\n",
      "Epoch 1446/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427283.0938 - mean_squared_error: 427283.0938\n",
      "Epoch 1447/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 422782.2188 - mean_squared_error: 422782.2188\n",
      "Epoch 1448/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 428636.2188 - mean_squared_error: 428636.2188\n",
      "Epoch 1449/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425542.7188 - mean_squared_error: 425542.7188\n",
      "Epoch 1450/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 422116.6562 - mean_squared_error: 422116.6562\n",
      "Epoch 1451/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 420592.1250 - mean_squared_error: 420592.1250\n",
      "Epoch 1452/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 420669.5625 - mean_squared_error: 420669.5938\n",
      "Epoch 1453/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 430741.2812 - mean_squared_error: 430741.2812\n",
      "Epoch 1454/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 417692.1875 - mean_squared_error: 417692.1875\n",
      "Epoch 1455/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 423026.7812 - mean_squared_error: 423026.7500\n",
      "Epoch 1456/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 422003.5312 - mean_squared_error: 422003.5312\n",
      "Epoch 1457/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415797.9688 - mean_squared_error: 415797.9688\n",
      "Epoch 1458/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 421544.9375 - mean_squared_error: 421544.9375\n",
      "Epoch 1459/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 422435.4375 - mean_squared_error: 422435.4375\n",
      "Epoch 1460/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 412997.0938 - mean_squared_error: 412997.0938\n",
      "Epoch 1461/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419430.7188 - mean_squared_error: 419430.7188\n",
      "Epoch 1462/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 415238.7812 - mean_squared_error: 415238.7812\n",
      "Epoch 1463/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 414774.8125 - mean_squared_error: 414774.7812\n",
      "Epoch 1464/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 416525.3125 - mean_squared_error: 416525.3125\n",
      "Epoch 1465/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 418699.7188 - mean_squared_error: 418699.7188\n",
      "Epoch 1466/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414487.2500 - mean_squared_error: 414487.2500\n",
      "Epoch 1467/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 422883.8125 - mean_squared_error: 422883.8125\n",
      "Epoch 1468/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 423024.1250 - mean_squared_error: 423024.1250\n",
      "Epoch 1469/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 411172.0312 - mean_squared_error: 411172.0312\n",
      "Epoch 1470/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 416542.0938 - mean_squared_error: 416542.0938\n",
      "Epoch 1471/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 418364.4688 - mean_squared_error: 418364.4688\n",
      "Epoch 1472/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414781.5938 - mean_squared_error: 414781.5938\n",
      "Epoch 1473/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 413222.9688 - mean_squared_error: 413222.9688\n",
      "Epoch 1474/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414774.5625 - mean_squared_error: 414774.5625\n",
      "Epoch 1475/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 412885.0312 - mean_squared_error: 412885.0312\n",
      "Epoch 1476/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 410693.5000 - mean_squared_error: 410693.5000\n",
      "Epoch 1477/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 417045.1562 - mean_squared_error: 417045.1562\n",
      "Epoch 1478/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 418627.8438 - mean_squared_error: 418627.8438\n",
      "Epoch 1479/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 413836.4062 - mean_squared_error: 413836.4062\n",
      "Epoch 1480/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 415443.0625 - mean_squared_error: 415443.0625\n",
      "Epoch 1481/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414610.2500 - mean_squared_error: 414610.2500\n",
      "Epoch 1482/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 416462.0625 - mean_squared_error: 416462.0625\n",
      "Epoch 1483/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 415828.8438 - mean_squared_error: 415828.8438\n",
      "Epoch 1484/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 417890.4375 - mean_squared_error: 417890.4375\n",
      "Epoch 1485/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415162.6250 - mean_squared_error: 415162.6250\n",
      "Epoch 1486/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419879.0312 - mean_squared_error: 419879.0312\n",
      "Epoch 1487/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 416939.4375 - mean_squared_error: 416939.4375\n",
      "Epoch 1488/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 416913.8438 - mean_squared_error: 416913.8438\n",
      "Epoch 1489/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415067.7812 - mean_squared_error: 415067.7812\n",
      "Epoch 1490/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411423.3750 - mean_squared_error: 411423.3750\n",
      "Epoch 1491/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 415848.9375 - mean_squared_error: 415848.9375\n",
      "Epoch 1492/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 410152.1875 - mean_squared_error: 410152.1875\n",
      "Epoch 1493/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413583.1562 - mean_squared_error: 413583.1562\n",
      "Epoch 1494/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 410915.5625 - mean_squared_error: 410915.5625\n",
      "Epoch 1495/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414546.5000 - mean_squared_error: 414546.5000\n",
      "Epoch 1496/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 410964.5625 - mean_squared_error: 410964.5625\n",
      "Epoch 1497/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 410030.3750 - mean_squared_error: 410030.3750\n",
      "Epoch 1498/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 405760.9688 - mean_squared_error: 405760.9688\n",
      "Epoch 1499/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 408062.0938 - mean_squared_error: 408062.0938\n",
      "Epoch 1500/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 414376.8750 - mean_squared_error: 414376.8750\n",
      "Epoch 1501/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415758.3750 - mean_squared_error: 415758.3750\n",
      "Epoch 1502/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 416472.0000 - mean_squared_error: 416472.0000\n",
      "Epoch 1503/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411709.8438 - mean_squared_error: 411709.8438\n",
      "Epoch 1504/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 413735.4688 - mean_squared_error: 413735.4688\n",
      "Epoch 1505/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 405728.9688 - mean_squared_error: 405728.9688\n",
      "Epoch 1506/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413128.8750 - mean_squared_error: 413128.8750\n",
      "Epoch 1507/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 410313.9375 - mean_squared_error: 410313.9375\n",
      "Epoch 1508/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 410745.3750 - mean_squared_error: 410745.3750\n",
      "Epoch 1509/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 407111.5000 - mean_squared_error: 407111.5000\n",
      "Epoch 1510/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408769.5000 - mean_squared_error: 408769.5000\n",
      "Epoch 1511/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 402881.5312 - mean_squared_error: 402881.5312\n",
      "Epoch 1512/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413087.6250 - mean_squared_error: 413087.6250\n",
      "Epoch 1513/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 403818.5625 - mean_squared_error: 403818.5625\n",
      "Epoch 1514/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 409700.0938 - mean_squared_error: 409700.0938\n",
      "Epoch 1515/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 404182.3438 - mean_squared_error: 404182.3438\n",
      "Epoch 1516/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411913.5938 - mean_squared_error: 411913.5625\n",
      "Epoch 1517/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404365.5625 - mean_squared_error: 404365.5625\n",
      "Epoch 1518/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 407125.4688 - mean_squared_error: 407125.4688\n",
      "Epoch 1519/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 402695.8750 - mean_squared_error: 402695.8750\n",
      "Epoch 1520/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 407089.4688 - mean_squared_error: 407089.4688\n",
      "Epoch 1521/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 404109.5938 - mean_squared_error: 404109.5938\n",
      "Epoch 1522/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401742.4375 - mean_squared_error: 401742.4375\n",
      "Epoch 1523/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404489.5625 - mean_squared_error: 404489.5625\n",
      "Epoch 1524/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 397712.7500 - mean_squared_error: 397712.7500\n",
      "Epoch 1525/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 409673.5000 - mean_squared_error: 409673.5000\n",
      "Epoch 1526/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 400819.3750 - mean_squared_error: 400819.3750\n",
      "Epoch 1527/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 395847.3438 - mean_squared_error: 395847.3438\n",
      "Epoch 1528/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 396541.5000 - mean_squared_error: 396541.5000\n",
      "Epoch 1529/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401749.3750 - mean_squared_error: 401749.3750\n",
      "Epoch 1530/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404839.7812 - mean_squared_error: 404839.7812\n",
      "Epoch 1531/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 405280.9375 - mean_squared_error: 405280.9375\n",
      "Epoch 1532/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 402370.2500 - mean_squared_error: 402370.2500\n",
      "Epoch 1533/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 397522.1875 - mean_squared_error: 397522.1562\n",
      "Epoch 1534/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 394898.0625 - mean_squared_error: 394898.0625\n",
      "Epoch 1535/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 398552.1562 - mean_squared_error: 398552.1562\n",
      "Epoch 1536/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 394373.4375 - mean_squared_error: 394373.4375\n",
      "Epoch 1537/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 387530.4375 - mean_squared_error: 387530.4062\n",
      "Epoch 1538/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 395991.1562 - mean_squared_error: 395991.1562\n",
      "Epoch 1539/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 408062.5312 - mean_squared_error: 408062.5312\n",
      "Epoch 1540/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 399414.1562 - mean_squared_error: 399414.1562\n",
      "Epoch 1541/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 402826.8750 - mean_squared_error: 402826.8438\n",
      "Epoch 1542/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 399956.9375 - mean_squared_error: 399956.9062\n",
      "Epoch 1543/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408681.4375 - mean_squared_error: 408681.4375\n",
      "Epoch 1544/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394910.6562 - mean_squared_error: 394910.6250\n",
      "Epoch 1545/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 396127.0625 - mean_squared_error: 396127.0625\n",
      "Epoch 1546/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 400665.9375 - mean_squared_error: 400665.9375\n",
      "Epoch 1547/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 397887.4688 - mean_squared_error: 397887.4688\n",
      "Epoch 1548/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396203.5000 - mean_squared_error: 396203.5000\n",
      "Epoch 1549/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394653.0938 - mean_squared_error: 394653.0938\n",
      "Epoch 1550/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396109.5938 - mean_squared_error: 396109.5938\n",
      "Epoch 1551/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404221.8125 - mean_squared_error: 404221.8125\n",
      "Epoch 1552/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 395357.4375 - mean_squared_error: 395357.4375\n",
      "Epoch 1553/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 395839.8750 - mean_squared_error: 395839.8750\n",
      "Epoch 1554/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 403050.6250 - mean_squared_error: 403050.6250\n",
      "Epoch 1555/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 393615.2812 - mean_squared_error: 393615.2812\n",
      "Epoch 1556/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 405586.1250 - mean_squared_error: 405586.1250\n",
      "Epoch 1557/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 397957.8125 - mean_squared_error: 397957.8125\n",
      "Epoch 1558/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 397049.0312 - mean_squared_error: 397049.0312\n",
      "Epoch 1559/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393641.3125 - mean_squared_error: 393641.3125\n",
      "Epoch 1560/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393199.0938 - mean_squared_error: 393199.0938\n",
      "Epoch 1561/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393486.0000 - mean_squared_error: 393486.0000\n",
      "Epoch 1562/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 390065.5938 - mean_squared_error: 390065.6250\n",
      "Epoch 1563/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 395749.6562 - mean_squared_error: 395749.6562\n",
      "Epoch 1564/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 401724.5000 - mean_squared_error: 401724.5000\n",
      "Epoch 1565/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396754.2500 - mean_squared_error: 396754.2500\n",
      "Epoch 1566/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 398573.0312 - mean_squared_error: 398573.0312\n",
      "Epoch 1567/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390576.1250 - mean_squared_error: 390576.1250\n",
      "Epoch 1568/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 393238.5000 - mean_squared_error: 393238.5000\n",
      "Epoch 1569/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 393906.0625 - mean_squared_error: 393906.0625\n",
      "Epoch 1570/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396183.6250 - mean_squared_error: 396183.6250\n",
      "Epoch 1571/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 393005.3438 - mean_squared_error: 393005.3438\n",
      "Epoch 1572/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 397038.1562 - mean_squared_error: 397038.1562\n",
      "Epoch 1573/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394481.0000 - mean_squared_error: 394481.0000\n",
      "Epoch 1574/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 392501.0000 - mean_squared_error: 392501.0000\n",
      "Epoch 1575/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 389015.9688 - mean_squared_error: 389015.9688\n",
      "Epoch 1576/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396265.3438 - mean_squared_error: 396265.3438\n",
      "Epoch 1577/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 397472.9375 - mean_squared_error: 397472.9375\n",
      "Epoch 1578/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393471.4688 - mean_squared_error: 393471.4688\n",
      "Epoch 1579/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 396287.8750 - mean_squared_error: 396287.8750\n",
      "Epoch 1580/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 391788.5000 - mean_squared_error: 391788.5000\n",
      "Epoch 1581/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 387831.5312 - mean_squared_error: 387831.5312\n",
      "Epoch 1582/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 389783.1875 - mean_squared_error: 389783.1875\n",
      "Epoch 1583/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379430.3125 - mean_squared_error: 379430.3125\n",
      "Epoch 1584/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 391721.0938 - mean_squared_error: 391721.0938\n",
      "Epoch 1585/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 390398.0000 - mean_squared_error: 390398.0000\n",
      "Epoch 1586/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390108.0625 - mean_squared_error: 390108.0625\n",
      "Epoch 1587/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 379444.4688 - mean_squared_error: 379444.4688\n",
      "Epoch 1588/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390978.7188 - mean_squared_error: 390978.7188\n",
      "Epoch 1589/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 389867.2812 - mean_squared_error: 389867.2812\n",
      "Epoch 1590/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394256.5000 - mean_squared_error: 394256.5312\n",
      "Epoch 1591/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 389587.6250 - mean_squared_error: 389587.6562\n",
      "Epoch 1592/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 383922.6562 - mean_squared_error: 383922.6562\n",
      "Epoch 1593/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 394776.5312 - mean_squared_error: 394776.5938\n",
      "Epoch 1594/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390758.5312 - mean_squared_error: 390758.5312\n",
      "Epoch 1595/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 388146.2812 - mean_squared_error: 388146.2812\n",
      "Epoch 1596/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 383300.4062 - mean_squared_error: 383300.4062\n",
      "Epoch 1597/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 392165.3438 - mean_squared_error: 392165.3438\n",
      "Epoch 1598/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396160.6250 - mean_squared_error: 396160.6250\n",
      "Epoch 1599/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 381303.1250 - mean_squared_error: 381303.1562\n",
      "Epoch 1600/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 389357.0312 - mean_squared_error: 389357.0312\n",
      "Epoch 1601/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386869.3438 - mean_squared_error: 386869.3750\n",
      "Epoch 1602/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386895.2500 - mean_squared_error: 386895.2500\n",
      "Epoch 1603/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382649.7812 - mean_squared_error: 382649.7812\n",
      "Epoch 1604/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382595.3125 - mean_squared_error: 382595.3125\n",
      "Epoch 1605/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386156.9062 - mean_squared_error: 386156.9062\n",
      "Epoch 1606/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 383158.3125 - mean_squared_error: 383158.3438\n",
      "Epoch 1607/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 385363.7812 - mean_squared_error: 385363.7812\n",
      "Epoch 1608/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380940.5938 - mean_squared_error: 380940.5938\n",
      "Epoch 1609/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382168.3750 - mean_squared_error: 382168.3750\n",
      "Epoch 1610/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378361.5938 - mean_squared_error: 378361.6250\n",
      "Epoch 1611/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382750.0625 - mean_squared_error: 382750.0625\n",
      "Epoch 1612/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 384786.2812 - mean_squared_error: 384786.2812\n",
      "Epoch 1613/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 376644.2812 - mean_squared_error: 376644.2812\n",
      "Epoch 1614/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 378693.0000 - mean_squared_error: 378693.0000\n",
      "Epoch 1615/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382486.4688 - mean_squared_error: 382486.4688\n",
      "Epoch 1616/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 385634.3438 - mean_squared_error: 385634.3438\n",
      "Epoch 1617/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 385326.6875 - mean_squared_error: 385326.6875\n",
      "Epoch 1618/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386614.7500 - mean_squared_error: 386614.7500\n",
      "Epoch 1619/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380983.8438 - mean_squared_error: 380983.8438\n",
      "Epoch 1620/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383691.1875 - mean_squared_error: 383691.1875\n",
      "Epoch 1621/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380840.1875 - mean_squared_error: 380840.2188\n",
      "Epoch 1622/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380707.2500 - mean_squared_error: 380707.2500\n",
      "Epoch 1623/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 386848.4375 - mean_squared_error: 386848.4375\n",
      "Epoch 1624/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383580.8438 - mean_squared_error: 383580.8438\n",
      "Epoch 1625/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 391375.3438 - mean_squared_error: 391375.3438\n",
      "Epoch 1626/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 383139.6875 - mean_squared_error: 383139.6875\n",
      "Epoch 1627/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 381071.5312 - mean_squared_error: 381071.5312\n",
      "Epoch 1628/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382148.3438 - mean_squared_error: 382148.3438\n",
      "Epoch 1629/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377790.0938 - mean_squared_error: 377790.0938\n",
      "Epoch 1630/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382124.4688 - mean_squared_error: 382124.4688\n",
      "Epoch 1631/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380154.8125 - mean_squared_error: 380154.8125\n",
      "Epoch 1632/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378369.4062 - mean_squared_error: 378369.3750\n",
      "Epoch 1633/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380649.0000 - mean_squared_error: 380649.0000\n",
      "Epoch 1634/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373418.3750 - mean_squared_error: 373418.3750\n",
      "Epoch 1635/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378732.6562 - mean_squared_error: 378732.6562\n",
      "Epoch 1636/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371389.7500 - mean_squared_error: 371389.7500\n",
      "Epoch 1637/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374197.2188 - mean_squared_error: 374197.2188\n",
      "Epoch 1638/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374801.7500 - mean_squared_error: 374801.7500\n",
      "Epoch 1639/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379285.3438 - mean_squared_error: 379285.3438\n",
      "Epoch 1640/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383040.1250 - mean_squared_error: 383040.1250\n",
      "Epoch 1641/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 381594.0938 - mean_squared_error: 381594.1250\n",
      "Epoch 1642/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380396.3750 - mean_squared_error: 380396.3750\n",
      "Epoch 1643/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373746.0000 - mean_squared_error: 373746.0000\n",
      "Epoch 1644/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 382434.1875 - mean_squared_error: 382434.1875\n",
      "Epoch 1645/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377978.9062 - mean_squared_error: 377978.8750\n",
      "Epoch 1646/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377988.5938 - mean_squared_error: 377988.5938\n",
      "Epoch 1647/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374826.2188 - mean_squared_error: 374826.2188\n",
      "Epoch 1648/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371494.7500 - mean_squared_error: 371494.7500\n",
      "Epoch 1649/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377344.2500 - mean_squared_error: 377344.2500\n",
      "Epoch 1650/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378996.3438 - mean_squared_error: 378996.3438\n",
      "Epoch 1651/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378229.5625 - mean_squared_error: 378229.5625\n",
      "Epoch 1652/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373795.5625 - mean_squared_error: 373795.5625\n",
      "Epoch 1653/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373075.8125 - mean_squared_error: 373075.8125\n",
      "Epoch 1654/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374444.8125 - mean_squared_error: 374444.8125\n",
      "Epoch 1655/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369239.0000 - mean_squared_error: 369239.0000\n",
      "Epoch 1656/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 378988.6250 - mean_squared_error: 378988.6250\n",
      "Epoch 1657/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374840.3125 - mean_squared_error: 374840.3125\n",
      "Epoch 1658/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377380.6562 - mean_squared_error: 377380.6562\n",
      "Epoch 1659/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371383.2812 - mean_squared_error: 371383.2812\n",
      "Epoch 1660/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373583.3438 - mean_squared_error: 373583.3125\n",
      "Epoch 1661/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374783.3750 - mean_squared_error: 374783.3438\n",
      "Epoch 1662/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372589.9062 - mean_squared_error: 372589.9062\n",
      "Epoch 1663/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374799.7812 - mean_squared_error: 374799.7812\n",
      "Epoch 1664/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380525.2188 - mean_squared_error: 380525.2188\n",
      "Epoch 1665/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372245.7188 - mean_squared_error: 372245.7188\n",
      "Epoch 1666/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367958.2188 - mean_squared_error: 367958.2188\n",
      "Epoch 1667/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362247.0625 - mean_squared_error: 362247.0625\n",
      "Epoch 1668/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380259.9375 - mean_squared_error: 380259.9375\n",
      "Epoch 1669/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371601.8125 - mean_squared_error: 371601.8125\n",
      "Epoch 1670/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 372656.9688 - mean_squared_error: 372656.9688\n",
      "Epoch 1671/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 366010.5938 - mean_squared_error: 366010.5938\n",
      "Epoch 1672/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373175.1250 - mean_squared_error: 373175.1250\n",
      "Epoch 1673/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 372366.2812 - mean_squared_error: 372366.2812\n",
      "Epoch 1674/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366525.3125 - mean_squared_error: 366525.3125\n",
      "Epoch 1675/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368903.3750 - mean_squared_error: 368903.3750\n",
      "Epoch 1676/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371640.0938 - mean_squared_error: 371640.0938\n",
      "Epoch 1677/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372763.5312 - mean_squared_error: 372763.5312\n",
      "Epoch 1678/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373890.8750 - mean_squared_error: 373890.8750\n",
      "Epoch 1679/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366960.2812 - mean_squared_error: 366960.2812\n",
      "Epoch 1680/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 375638.6250 - mean_squared_error: 375638.6250\n",
      "Epoch 1681/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369730.9375 - mean_squared_error: 369730.9375\n",
      "Epoch 1682/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371904.5625 - mean_squared_error: 371904.5625\n",
      "Epoch 1683/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374567.6562 - mean_squared_error: 374567.6562\n",
      "Epoch 1684/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 372300.3438 - mean_squared_error: 372300.3438\n",
      "Epoch 1685/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367198.1875 - mean_squared_error: 367198.1562\n",
      "Epoch 1686/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364990.2812 - mean_squared_error: 364990.2812\n",
      "Epoch 1687/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375148.2812 - mean_squared_error: 375148.2812\n",
      "Epoch 1688/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366552.7500 - mean_squared_error: 366552.7500\n",
      "Epoch 1689/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368528.1250 - mean_squared_error: 368528.1250\n",
      "Epoch 1690/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 375522.9688 - mean_squared_error: 375522.9688\n",
      "Epoch 1691/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369256.4688 - mean_squared_error: 369256.4688\n",
      "Epoch 1692/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373128.0625 - mean_squared_error: 373128.0625\n",
      "Epoch 1693/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374411.4688 - mean_squared_error: 374411.4688\n",
      "Epoch 1694/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365209.2500 - mean_squared_error: 365209.2500\n",
      "Epoch 1695/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366764.0938 - mean_squared_error: 366764.0938\n",
      "Epoch 1696/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365056.4688 - mean_squared_error: 365056.4688\n",
      "Epoch 1697/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 368196.2812 - mean_squared_error: 368196.2812\n",
      "Epoch 1698/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367764.3125 - mean_squared_error: 367764.3125\n",
      "Epoch 1699/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365332.2500 - mean_squared_error: 365332.2500\n",
      "Epoch 1700/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367983.5938 - mean_squared_error: 367983.5938\n",
      "Epoch 1701/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368460.3438 - mean_squared_error: 368460.3438\n",
      "Epoch 1702/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373873.5312 - mean_squared_error: 373873.5625\n",
      "Epoch 1703/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367783.8125 - mean_squared_error: 367783.8125\n",
      "Epoch 1704/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 367976.7188 - mean_squared_error: 367976.7188\n",
      "Epoch 1705/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367703.3438 - mean_squared_error: 367703.3438\n",
      "Epoch 1706/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359850.0938 - mean_squared_error: 359850.0938\n",
      "Epoch 1707/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365573.1875 - mean_squared_error: 365573.1875\n",
      "Epoch 1708/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 369353.1875 - mean_squared_error: 369353.1875\n",
      "Epoch 1709/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371335.2812 - mean_squared_error: 371335.2812\n",
      "Epoch 1710/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 369735.3125 - mean_squared_error: 369735.3125\n",
      "Epoch 1711/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368751.8438 - mean_squared_error: 368751.8438\n",
      "Epoch 1712/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 362788.2188 - mean_squared_error: 362788.2188\n",
      "Epoch 1713/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363845.7188 - mean_squared_error: 363845.7500\n",
      "Epoch 1714/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371429.8125 - mean_squared_error: 371429.8125\n",
      "Epoch 1715/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362865.6875 - mean_squared_error: 362865.6875\n",
      "Epoch 1716/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364148.0938 - mean_squared_error: 364148.0938\n",
      "Epoch 1717/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365839.7500 - mean_squared_error: 365839.7500\n",
      "Epoch 1718/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370919.2188 - mean_squared_error: 370919.2188\n",
      "Epoch 1719/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363478.6562 - mean_squared_error: 363478.6562\n",
      "Epoch 1720/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364307.0312 - mean_squared_error: 364307.0312\n",
      "Epoch 1721/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366626.1562 - mean_squared_error: 366626.1562\n",
      "Epoch 1722/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365623.7188 - mean_squared_error: 365623.7188\n",
      "Epoch 1723/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362488.0938 - mean_squared_error: 362488.1250\n",
      "Epoch 1724/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353290.3125 - mean_squared_error: 353290.3125\n",
      "Epoch 1725/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367041.0312 - mean_squared_error: 367041.0312\n",
      "Epoch 1726/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366376.1875 - mean_squared_error: 366376.1875\n",
      "Epoch 1727/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 361798.8125 - mean_squared_error: 361798.8125\n",
      "Epoch 1728/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368705.0938 - mean_squared_error: 368705.0938\n",
      "Epoch 1729/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361449.7500 - mean_squared_error: 361449.7500\n",
      "Epoch 1730/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 363353.9688 - mean_squared_error: 363353.9688\n",
      "Epoch 1731/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366534.3750 - mean_squared_error: 366534.3750\n",
      "Epoch 1732/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365584.8438 - mean_squared_error: 365584.8438\n",
      "Epoch 1733/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360141.5625 - mean_squared_error: 360141.5625\n",
      "Epoch 1734/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365009.9688 - mean_squared_error: 365009.9688\n",
      "Epoch 1735/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363968.6875 - mean_squared_error: 363968.6875\n",
      "Epoch 1736/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365408.6875 - mean_squared_error: 365408.6562\n",
      "Epoch 1737/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367542.8438 - mean_squared_error: 367542.8125\n",
      "Epoch 1738/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 364449.5938 - mean_squared_error: 364449.5938\n",
      "Epoch 1739/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370649.2188 - mean_squared_error: 370649.2188\n",
      "Epoch 1740/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359071.7812 - mean_squared_error: 359071.7812\n",
      "Epoch 1741/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 361360.8750 - mean_squared_error: 361360.8750\n",
      "Epoch 1742/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358471.8750 - mean_squared_error: 358471.8750\n",
      "Epoch 1743/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352534.0938 - mean_squared_error: 352534.0938\n",
      "Epoch 1744/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360005.3750 - mean_squared_error: 360005.3750\n",
      "Epoch 1745/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359604.4375 - mean_squared_error: 359604.4375\n",
      "Epoch 1746/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 361665.4062 - mean_squared_error: 361665.4375\n",
      "Epoch 1747/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362010.9062 - mean_squared_error: 362010.9062\n",
      "Epoch 1748/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366332.0000 - mean_squared_error: 366332.0000\n",
      "Epoch 1749/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364331.5625 - mean_squared_error: 364331.5625\n",
      "Epoch 1750/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357827.1250 - mean_squared_error: 357827.1250\n",
      "Epoch 1751/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355015.7188 - mean_squared_error: 355015.7188\n",
      "Epoch 1752/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359662.6875 - mean_squared_error: 359662.6875\n",
      "Epoch 1753/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 360008.7812 - mean_squared_error: 360008.7812\n",
      "Epoch 1754/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366931.1562 - mean_squared_error: 366931.1562\n",
      "Epoch 1755/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360053.0000 - mean_squared_error: 360053.0000\n",
      "Epoch 1756/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357747.5312 - mean_squared_error: 357747.5312\n",
      "Epoch 1757/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 356776.5000 - mean_squared_error: 356776.5000\n",
      "Epoch 1758/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359475.8750 - mean_squared_error: 359475.8750\n",
      "Epoch 1759/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355778.2188 - mean_squared_error: 355778.2188\n",
      "Epoch 1760/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359844.4688 - mean_squared_error: 359844.4688\n",
      "Epoch 1761/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356557.4375 - mean_squared_error: 356557.4375\n",
      "Epoch 1762/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354189.3438 - mean_squared_error: 354189.3438\n",
      "Epoch 1763/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355064.0312 - mean_squared_error: 355064.0312\n",
      "Epoch 1764/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359707.0938 - mean_squared_error: 359707.0938\n",
      "Epoch 1765/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356768.4375 - mean_squared_error: 356768.4375\n",
      "Epoch 1766/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356588.0625 - mean_squared_error: 356588.0625\n",
      "Epoch 1767/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357209.2188 - mean_squared_error: 357209.2188\n",
      "Epoch 1768/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358522.9062 - mean_squared_error: 358522.9062\n",
      "Epoch 1769/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 349002.3438 - mean_squared_error: 349002.3438\n",
      "Epoch 1770/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359062.8438 - mean_squared_error: 359062.8438\n",
      "Epoch 1771/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355750.5312 - mean_squared_error: 355750.5312\n",
      "Epoch 1772/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359653.1250 - mean_squared_error: 359653.1250\n",
      "Epoch 1773/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360684.7188 - mean_squared_error: 360684.7188\n",
      "Epoch 1774/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356949.8125 - mean_squared_error: 356949.8125\n",
      "Epoch 1775/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 361441.5000 - mean_squared_error: 361441.5000\n",
      "Epoch 1776/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357683.8438 - mean_squared_error: 357683.8750\n",
      "Epoch 1777/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353626.9062 - mean_squared_error: 353626.9062\n",
      "Epoch 1778/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351015.5938 - mean_squared_error: 351015.5938\n",
      "Epoch 1779/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356799.1250 - mean_squared_error: 356799.1250\n",
      "Epoch 1780/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354039.8438 - mean_squared_error: 354039.8438\n",
      "Epoch 1781/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353504.7812 - mean_squared_error: 353504.7812\n",
      "Epoch 1782/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354451.6250 - mean_squared_error: 354451.6250\n",
      "Epoch 1783/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352762.5000 - mean_squared_error: 352762.5000\n",
      "Epoch 1784/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356436.9062 - mean_squared_error: 356436.9062\n",
      "Epoch 1785/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356317.4375 - mean_squared_error: 356317.4375\n",
      "Epoch 1786/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357856.5625 - mean_squared_error: 357856.5625\n",
      "Epoch 1787/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355663.9062 - mean_squared_error: 355663.9062\n",
      "Epoch 1788/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353956.8125 - mean_squared_error: 353956.7812\n",
      "Epoch 1789/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356345.7500 - mean_squared_error: 356345.7812\n",
      "Epoch 1790/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352174.8125 - mean_squared_error: 352174.8438\n",
      "Epoch 1791/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356825.4688 - mean_squared_error: 356825.4688\n",
      "Epoch 1792/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360988.1562 - mean_squared_error: 360988.1562\n",
      "Epoch 1793/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352456.8125 - mean_squared_error: 352456.8125\n",
      "Epoch 1794/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361376.9375 - mean_squared_error: 361376.9375\n",
      "Epoch 1795/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350312.7812 - mean_squared_error: 350312.7812\n",
      "Epoch 1796/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355405.3438 - mean_squared_error: 355405.3750\n",
      "Epoch 1797/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356418.0312 - mean_squared_error: 356418.0312\n",
      "Epoch 1798/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352749.7188 - mean_squared_error: 352749.7188\n",
      "Epoch 1799/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349302.8125 - mean_squared_error: 349302.8125\n",
      "Epoch 1800/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346911.3125 - mean_squared_error: 346911.3125\n",
      "Epoch 1801/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352836.1250 - mean_squared_error: 352836.1250\n",
      "Epoch 1802/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354727.5625 - mean_squared_error: 354727.5625\n",
      "Epoch 1803/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347446.7500 - mean_squared_error: 347446.7500\n",
      "Epoch 1804/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354169.9375 - mean_squared_error: 354169.9375\n",
      "Epoch 1805/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351209.3438 - mean_squared_error: 351209.3750\n",
      "Epoch 1806/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355315.9062 - mean_squared_error: 355315.9062\n",
      "Epoch 1807/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355336.1875 - mean_squared_error: 355336.1875\n",
      "Epoch 1808/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353233.2500 - mean_squared_error: 353233.2500\n",
      "Epoch 1809/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345849.9375 - mean_squared_error: 345849.9375\n",
      "Epoch 1810/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352886.3438 - mean_squared_error: 352886.3438\n",
      "Epoch 1811/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349510.0000 - mean_squared_error: 349510.0000\n",
      "Epoch 1812/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343008.0000 - mean_squared_error: 343008.0000\n",
      "Epoch 1813/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356548.3125 - mean_squared_error: 356548.3125\n",
      "Epoch 1814/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345446.3750 - mean_squared_error: 345446.4062\n",
      "Epoch 1815/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344813.6562 - mean_squared_error: 344813.6562\n",
      "Epoch 1816/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355120.5312 - mean_squared_error: 355120.5312\n",
      "Epoch 1817/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343655.4688 - mean_squared_error: 343655.4688\n",
      "Epoch 1818/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353296.5312 - mean_squared_error: 353296.5312\n",
      "Epoch 1819/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345637.4688 - mean_squared_error: 345637.4688\n",
      "Epoch 1820/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351326.4062 - mean_squared_error: 351326.4062\n",
      "Epoch 1821/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353099.6250 - mean_squared_error: 353099.6250\n",
      "Epoch 1822/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348662.0938 - mean_squared_error: 348662.1250\n",
      "Epoch 1823/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348801.3125 - mean_squared_error: 348801.3125\n",
      "Epoch 1824/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350854.0312 - mean_squared_error: 350854.0312\n",
      "Epoch 1825/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351446.8125 - mean_squared_error: 351446.8125\n",
      "Epoch 1826/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351390.9688 - mean_squared_error: 351390.9688\n",
      "Epoch 1827/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352615.2188 - mean_squared_error: 352615.2188\n",
      "Epoch 1828/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351213.8125 - mean_squared_error: 351213.8125\n",
      "Epoch 1829/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353753.0312 - mean_squared_error: 353753.0312\n",
      "Epoch 1830/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352120.2188 - mean_squared_error: 352120.2188\n",
      "Epoch 1831/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350284.3750 - mean_squared_error: 350284.3750\n",
      "Epoch 1832/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348574.1250 - mean_squared_error: 348574.1562\n",
      "Epoch 1833/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340262.9062 - mean_squared_error: 340262.9062\n",
      "Epoch 1834/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348811.6875 - mean_squared_error: 348811.6875\n",
      "Epoch 1835/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350285.0312 - mean_squared_error: 350285.0312\n",
      "Epoch 1836/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344878.3438 - mean_squared_error: 344878.3125\n",
      "Epoch 1837/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344029.5312 - mean_squared_error: 344029.5312\n",
      "Epoch 1838/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343547.0000 - mean_squared_error: 343547.0000\n",
      "Epoch 1839/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343242.0312 - mean_squared_error: 343242.0312\n",
      "Epoch 1840/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348382.6562 - mean_squared_error: 348382.6562\n",
      "Epoch 1841/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338214.0938 - mean_squared_error: 338214.0938\n",
      "Epoch 1842/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350938.5938 - mean_squared_error: 350938.5938\n",
      "Epoch 1843/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347792.0000 - mean_squared_error: 347792.0000\n",
      "Epoch 1844/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 350447.7188 - mean_squared_error: 350447.7188\n",
      "Epoch 1845/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349496.8750 - mean_squared_error: 349496.8750\n",
      "Epoch 1846/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351771.2188 - mean_squared_error: 351771.2188\n",
      "Epoch 1847/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350634.9062 - mean_squared_error: 350634.9062\n",
      "Epoch 1848/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346042.6250 - mean_squared_error: 346042.6250\n",
      "Epoch 1849/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339118.4375 - mean_squared_error: 339118.4375\n",
      "Epoch 1850/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340772.5938 - mean_squared_error: 340772.5938\n",
      "Epoch 1851/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344214.7812 - mean_squared_error: 344214.7812\n",
      "Epoch 1852/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340883.4688 - mean_squared_error: 340883.4688\n",
      "Epoch 1853/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348648.5938 - mean_squared_error: 348648.5938\n",
      "Epoch 1854/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342709.9062 - mean_squared_error: 342709.9062\n",
      "Epoch 1855/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341352.3438 - mean_squared_error: 341352.3438\n",
      "Epoch 1856/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341565.8438 - mean_squared_error: 341565.8438\n",
      "Epoch 1857/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348267.7812 - mean_squared_error: 348267.8125\n",
      "Epoch 1858/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347872.7812 - mean_squared_error: 347872.7812\n",
      "Epoch 1859/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345558.2812 - mean_squared_error: 345558.2500\n",
      "Epoch 1860/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350020.0938 - mean_squared_error: 350020.0938\n",
      "Epoch 1861/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345973.4688 - mean_squared_error: 345973.4688\n",
      "Epoch 1862/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346173.5000 - mean_squared_error: 346173.5000\n",
      "Epoch 1863/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340161.3438 - mean_squared_error: 340161.3438\n",
      "Epoch 1864/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342477.9375 - mean_squared_error: 342477.9375\n",
      "Epoch 1865/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344334.7500 - mean_squared_error: 344334.7500\n",
      "Epoch 1866/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349241.6562 - mean_squared_error: 349241.6250\n",
      "Epoch 1867/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341201.5625 - mean_squared_error: 341201.5625\n",
      "Epoch 1868/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341835.9688 - mean_squared_error: 341835.9688\n",
      "Epoch 1869/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332245.0938 - mean_squared_error: 332245.0938\n",
      "Epoch 1870/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347609.6875 - mean_squared_error: 347609.6875\n",
      "Epoch 1871/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341994.3438 - mean_squared_error: 341994.3438\n",
      "Epoch 1872/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337443.8438 - mean_squared_error: 337443.8438\n",
      "Epoch 1873/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346320.9062 - mean_squared_error: 346320.9062\n",
      "Epoch 1874/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343280.6250 - mean_squared_error: 343280.6250\n",
      "Epoch 1875/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345934.5000 - mean_squared_error: 345934.5312\n",
      "Epoch 1876/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346283.0312 - mean_squared_error: 346283.0312\n",
      "Epoch 1877/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343786.6562 - mean_squared_error: 343786.6562\n",
      "Epoch 1878/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343008.9062 - mean_squared_error: 343008.9062\n",
      "Epoch 1879/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336781.2812 - mean_squared_error: 336781.2812\n",
      "Epoch 1880/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337234.6562 - mean_squared_error: 337234.6562\n",
      "Epoch 1881/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338745.4062 - mean_squared_error: 338745.4062\n",
      "Epoch 1882/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339148.7812 - mean_squared_error: 339148.7812\n",
      "Epoch 1883/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340348.8438 - mean_squared_error: 340348.8438\n",
      "Epoch 1884/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339676.0000 - mean_squared_error: 339676.0000\n",
      "Epoch 1885/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340615.8438 - mean_squared_error: 340615.8438\n",
      "Epoch 1886/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343892.5312 - mean_squared_error: 343892.5312\n",
      "Epoch 1887/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339551.7188 - mean_squared_error: 339551.7188\n",
      "Epoch 1888/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341161.9375 - mean_squared_error: 341161.9375\n",
      "Epoch 1889/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349941.9062 - mean_squared_error: 349941.9062\n",
      "Epoch 1890/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343806.7500 - mean_squared_error: 343806.7500\n",
      "Epoch 1891/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348016.7188 - mean_squared_error: 348016.7188\n",
      "Epoch 1892/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342226.3750 - mean_squared_error: 342226.3438\n",
      "Epoch 1893/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343603.8438 - mean_squared_error: 343603.8438\n",
      "Epoch 1894/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337083.8750 - mean_squared_error: 337083.8750\n",
      "Epoch 1895/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338320.2500 - mean_squared_error: 338320.2500\n",
      "Epoch 1896/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345590.5625 - mean_squared_error: 345590.5625\n",
      "Epoch 1897/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341148.6875 - mean_squared_error: 341148.6875\n",
      "Epoch 1898/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337153.5938 - mean_squared_error: 337153.5938\n",
      "Epoch 1899/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345332.8438 - mean_squared_error: 345332.8438\n",
      "Epoch 1900/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336072.0000 - mean_squared_error: 336072.0000\n",
      "Epoch 1901/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335907.6250 - mean_squared_error: 335907.6250\n",
      "Epoch 1902/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340604.8750 - mean_squared_error: 340604.8750\n",
      "Epoch 1903/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340408.4688 - mean_squared_error: 340408.5312\n",
      "Epoch 1904/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337334.4375 - mean_squared_error: 337334.4375\n",
      "Epoch 1905/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336343.4062 - mean_squared_error: 336343.4062\n",
      "Epoch 1906/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339398.8125 - mean_squared_error: 339398.8125\n",
      "Epoch 1907/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332608.1562 - mean_squared_error: 332608.1562\n",
      "Epoch 1908/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 328353.4688 - mean_squared_error: 328353.4688\n",
      "Epoch 1909/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338262.1562 - mean_squared_error: 338262.1562\n",
      "Epoch 1910/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 335351.1562 - mean_squared_error: 335351.1250\n",
      "Epoch 1911/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336104.9062 - mean_squared_error: 336104.9062\n",
      "Epoch 1912/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338432.7812 - mean_squared_error: 338432.7812\n",
      "Epoch 1913/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333476.8438 - mean_squared_error: 333476.8438\n",
      "Epoch 1914/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 331152.5625 - mean_squared_error: 331152.5625\n",
      "Epoch 1915/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338155.7500 - mean_squared_error: 338155.7500\n",
      "Epoch 1916/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333701.6562 - mean_squared_error: 333701.6562\n",
      "Epoch 1917/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337913.0000 - mean_squared_error: 337912.9688\n",
      "Epoch 1918/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 331562.2188 - mean_squared_error: 331562.2188\n",
      "Epoch 1919/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336612.6562 - mean_squared_error: 336612.6562\n",
      "Epoch 1920/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 340117.0938 - mean_squared_error: 340117.0938\n",
      "Epoch 1921/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340636.4688 - mean_squared_error: 340636.4375\n",
      "Epoch 1922/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335832.1562 - mean_squared_error: 335832.1562\n",
      "Epoch 1923/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333613.7188 - mean_squared_error: 333613.7188\n",
      "Epoch 1924/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338570.6250 - mean_squared_error: 338570.6250\n",
      "Epoch 1925/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342378.0938 - mean_squared_error: 342378.0938\n",
      "Epoch 1926/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339462.1250 - mean_squared_error: 339462.1250\n",
      "Epoch 1927/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345228.8750 - mean_squared_error: 345228.8750\n",
      "Epoch 1928/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333378.7812 - mean_squared_error: 333378.7812\n",
      "Epoch 1929/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 330977.7188 - mean_squared_error: 330977.7188\n",
      "Epoch 1930/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 324468.3125 - mean_squared_error: 324468.2812\n",
      "Epoch 1931/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334242.4375 - mean_squared_error: 334242.4375\n",
      "Epoch 1932/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332085.9375 - mean_squared_error: 332085.9375\n",
      "Epoch 1933/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334264.9688 - mean_squared_error: 334264.9688\n",
      "Epoch 1934/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338247.1250 - mean_squared_error: 338247.1250\n",
      "Epoch 1935/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334522.6250 - mean_squared_error: 334522.6250\n",
      "Epoch 1936/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339438.8125 - mean_squared_error: 339438.8125\n",
      "Epoch 1937/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331217.8125 - mean_squared_error: 331217.8125\n",
      "Epoch 1938/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340558.1250 - mean_squared_error: 340558.1250\n",
      "Epoch 1939/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332122.7500 - mean_squared_error: 332122.7500\n",
      "Epoch 1940/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337400.0312 - mean_squared_error: 337400.0312\n",
      "Epoch 1941/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333971.3750 - mean_squared_error: 333971.3750\n",
      "Epoch 1942/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335727.0312 - mean_squared_error: 335727.0312\n",
      "Epoch 1943/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341978.2500 - mean_squared_error: 341978.2500\n",
      "Epoch 1944/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337592.8750 - mean_squared_error: 337592.8750\n",
      "Epoch 1945/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 329741.8438 - mean_squared_error: 329741.8438\n",
      "Epoch 1946/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331433.2188 - mean_squared_error: 331433.2188\n",
      "Epoch 1947/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340260.0000 - mean_squared_error: 340260.0000\n",
      "Epoch 1948/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338050.5312 - mean_squared_error: 338050.5312\n",
      "Epoch 1949/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 331608.2188 - mean_squared_error: 331608.2188\n",
      "Epoch 1950/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328115.8125 - mean_squared_error: 328115.8125\n",
      "Epoch 1951/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339498.1562 - mean_squared_error: 339498.1562\n",
      "Epoch 1952/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335945.0312 - mean_squared_error: 335945.0312\n",
      "Epoch 1953/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334155.3438 - mean_squared_error: 334155.3438\n",
      "Epoch 1954/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335527.6250 - mean_squared_error: 335527.6250\n",
      "Epoch 1955/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328594.2188 - mean_squared_error: 328594.2188\n",
      "Epoch 1956/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334633.2188 - mean_squared_error: 334633.2188\n",
      "Epoch 1957/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 330851.5938 - mean_squared_error: 330851.5938\n",
      "Epoch 1958/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335690.1562 - mean_squared_error: 335690.1875\n",
      "Epoch 1959/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336778.9688 - mean_squared_error: 336778.9375\n",
      "Epoch 1960/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332179.9375 - mean_squared_error: 332179.9375\n",
      "Epoch 1961/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334449.9375 - mean_squared_error: 334449.9375\n",
      "Epoch 1962/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332841.9688 - mean_squared_error: 332841.9688\n",
      "Epoch 1963/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 331073.9688 - mean_squared_error: 331073.9688\n",
      "Epoch 1964/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337743.0625 - mean_squared_error: 337743.0625\n",
      "Epoch 1965/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333021.7500 - mean_squared_error: 333021.7500\n",
      "Epoch 1966/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333211.6562 - mean_squared_error: 333211.6562\n",
      "Epoch 1967/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337117.5625 - mean_squared_error: 337117.5625\n",
      "Epoch 1968/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 330143.4688 - mean_squared_error: 330143.4688\n",
      "Epoch 1969/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379749.4375 - mean_squared_error: 379749.4375\n",
      "Epoch 1970/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 329281.3750 - mean_squared_error: 329281.3750\n",
      "Epoch 1971/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 308988.3438 - mean_squared_error: 308988.3438\n",
      "Epoch 1972/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 989130.8125 - mean_squared_error: 989130.8125\n",
      "Epoch 1973/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 858674.4375 - mean_squared_error: 858674.4375\n",
      "Epoch 1974/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 795968.6250 - mean_squared_error: 795968.6250\n",
      "Epoch 1975/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 736515.7500 - mean_squared_error: 736515.7500\n",
      "Epoch 1976/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 631457.3750 - mean_squared_error: 631457.3750\n",
      "Epoch 1977/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 415403.3750 - mean_squared_error: 415403.3750\n",
      "Epoch 1978/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 377595.7188 - mean_squared_error: 377595.6875\n",
      "Epoch 1979/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 382881.1250 - mean_squared_error: 382881.1250\n",
      "Epoch 1980/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383177.8125 - mean_squared_error: 383177.8438\n",
      "Epoch 1981/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375830.2812 - mean_squared_error: 375830.2812\n",
      "Epoch 1982/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 387760.5312 - mean_squared_error: 387760.5312\n",
      "Epoch 1983/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 385792.9062 - mean_squared_error: 385792.9062\n",
      "Epoch 1984/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 378917.3125 - mean_squared_error: 378917.3125\n",
      "Epoch 1985/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 381900.1875 - mean_squared_error: 381900.1875\n",
      "Epoch 1986/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373306.4062 - mean_squared_error: 373306.4062\n",
      "Epoch 1987/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378104.9062 - mean_squared_error: 378104.9375\n",
      "Epoch 1988/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386429.8438 - mean_squared_error: 386429.8438\n",
      "Epoch 1989/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383671.7500 - mean_squared_error: 383671.7500\n",
      "Epoch 1990/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 376472.7500 - mean_squared_error: 376472.7500\n",
      "Epoch 1991/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 375541.2188 - mean_squared_error: 375541.2188\n",
      "Epoch 1992/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373581.4375 - mean_squared_error: 373581.4375\n",
      "Epoch 1993/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 377725.9375 - mean_squared_error: 377725.9375\n",
      "Epoch 1994/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375985.6250 - mean_squared_error: 375985.6250\n",
      "Epoch 1995/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373900.0625 - mean_squared_error: 373900.0625\n",
      "Epoch 1996/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375570.7812 - mean_squared_error: 375570.7812\n",
      "Epoch 1997/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 376509.7500 - mean_squared_error: 376509.7500\n",
      "Epoch 1998/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 376626.9688 - mean_squared_error: 376626.9688\n",
      "Epoch 1999/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 377774.3125 - mean_squared_error: 377774.3125\n",
      "Epoch 2000/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369922.7500 - mean_squared_error: 369922.7500\n",
      "Epoch 2001/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377699.7500 - mean_squared_error: 377699.7500\n",
      "Epoch 2002/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372608.0312 - mean_squared_error: 372608.0625\n",
      "Epoch 2003/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 375536.1250 - mean_squared_error: 375536.1250\n",
      "Epoch 2004/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 376968.9688 - mean_squared_error: 376969.0000\n",
      "Epoch 2005/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364618.7812 - mean_squared_error: 364618.7812\n",
      "Epoch 2006/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374645.5625 - mean_squared_error: 374645.5625\n",
      "Epoch 2007/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 372925.5000 - mean_squared_error: 372925.5000\n",
      "Epoch 2008/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366979.1250 - mean_squared_error: 366979.1250\n",
      "Epoch 2009/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367617.2188 - mean_squared_error: 367617.2188\n",
      "Epoch 2010/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366533.8438 - mean_squared_error: 366533.8438\n",
      "Epoch 2011/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 376674.1875 - mean_squared_error: 376674.1875\n",
      "Epoch 2012/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370848.4375 - mean_squared_error: 370848.4375\n",
      "Epoch 2013/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366415.2812 - mean_squared_error: 366415.2812\n",
      "Epoch 2014/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373128.6875 - mean_squared_error: 373128.6875\n",
      "Epoch 2015/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 374699.3438 - mean_squared_error: 374699.3125\n",
      "Epoch 2016/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375502.6562 - mean_squared_error: 375502.6562\n",
      "Epoch 2017/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371851.2500 - mean_squared_error: 371851.2500\n",
      "Epoch 2018/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366830.2188 - mean_squared_error: 366830.2188\n",
      "Epoch 2019/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 372724.3125 - mean_squared_error: 372724.3125\n",
      "Epoch 2020/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371809.7812 - mean_squared_error: 371809.8125\n",
      "Epoch 2021/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360756.3125 - mean_squared_error: 360756.3125\n",
      "Epoch 2022/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368550.4375 - mean_squared_error: 368550.4375\n",
      "Epoch 2023/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373409.4375 - mean_squared_error: 373409.4375\n",
      "Epoch 2024/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364973.3438 - mean_squared_error: 364973.3438\n",
      "Epoch 2025/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 370867.1875 - mean_squared_error: 370867.1875\n",
      "Epoch 2026/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362994.3750 - mean_squared_error: 362994.4062\n",
      "Epoch 2027/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366174.6875 - mean_squared_error: 366174.6875\n",
      "Epoch 2028/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 370414.5000 - mean_squared_error: 370414.5000\n",
      "Epoch 2029/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374822.4062 - mean_squared_error: 374822.4062\n",
      "Epoch 2030/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 369198.2188 - mean_squared_error: 369198.2188\n",
      "Epoch 2031/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372138.0625 - mean_squared_error: 372138.0625\n",
      "Epoch 2032/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366214.4375 - mean_squared_error: 366214.4375\n",
      "Epoch 2033/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 369292.6562 - mean_squared_error: 369292.6875\n",
      "Epoch 2034/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 373260.6875 - mean_squared_error: 373260.6875\n",
      "Epoch 2035/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371894.6562 - mean_squared_error: 371894.6562\n",
      "Epoch 2036/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 366355.0000 - mean_squared_error: 366355.0000\n",
      "Epoch 2037/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365419.9062 - mean_squared_error: 365419.9062\n",
      "Epoch 2038/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367995.5938 - mean_squared_error: 367995.5938\n",
      "Epoch 2039/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368040.9062 - mean_squared_error: 368040.9062\n",
      "Epoch 2040/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370371.8750 - mean_squared_error: 370371.8750\n",
      "Epoch 2041/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 370568.8125 - mean_squared_error: 370568.8125\n",
      "Epoch 2042/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363465.3125 - mean_squared_error: 363465.3125\n",
      "Epoch 2043/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364118.6562 - mean_squared_error: 364118.6562\n",
      "Epoch 2044/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362490.4375 - mean_squared_error: 362490.4375\n",
      "Epoch 2045/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 371390.6250 - mean_squared_error: 371390.5938\n",
      "Epoch 2046/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365373.2188 - mean_squared_error: 365373.2188\n",
      "Epoch 2047/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363477.6250 - mean_squared_error: 363477.6250\n",
      "Epoch 2048/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370980.2812 - mean_squared_error: 370980.2812\n",
      "Epoch 2049/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360575.5625 - mean_squared_error: 360575.5625\n",
      "Epoch 2050/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355534.2188 - mean_squared_error: 355534.2188\n",
      "Epoch 2051/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360672.1250 - mean_squared_error: 360672.1250\n",
      "Epoch 2052/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363112.6250 - mean_squared_error: 363112.6250\n",
      "Epoch 2053/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362607.7812 - mean_squared_error: 362607.7812\n",
      "Epoch 2054/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368051.0312 - mean_squared_error: 368051.0312\n",
      "Epoch 2055/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366392.2500 - mean_squared_error: 366392.2500\n",
      "Epoch 2056/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361009.8125 - mean_squared_error: 361009.8125\n",
      "Epoch 2057/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362099.8125 - mean_squared_error: 362099.8125\n",
      "Epoch 2058/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361283.2188 - mean_squared_error: 361283.2188\n",
      "Epoch 2059/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373923.2500 - mean_squared_error: 373923.2812\n",
      "Epoch 2060/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359005.5625 - mean_squared_error: 359005.5625\n",
      "Epoch 2061/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365128.4062 - mean_squared_error: 365128.4062\n",
      "Epoch 2062/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365767.9062 - mean_squared_error: 365767.9062\n",
      "Epoch 2063/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 370508.7188 - mean_squared_error: 370508.7188\n",
      "Epoch 2064/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 367425.3125 - mean_squared_error: 367425.3125\n",
      "Epoch 2065/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379240.1875 - mean_squared_error: 379240.1875\n",
      "Epoch 2066/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366865.8438 - mean_squared_error: 366865.8125\n",
      "Epoch 2067/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 363067.7812 - mean_squared_error: 363067.7812\n",
      "Epoch 2068/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361994.7812 - mean_squared_error: 361994.7812\n",
      "Epoch 2069/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359867.8750 - mean_squared_error: 359867.8750\n",
      "Epoch 2070/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360085.4688 - mean_squared_error: 360085.4688\n",
      "Epoch 2071/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 369074.8438 - mean_squared_error: 369074.8438\n",
      "Epoch 2072/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357719.6875 - mean_squared_error: 357719.6875\n",
      "Epoch 2073/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 363951.0312 - mean_squared_error: 363951.0312\n",
      "Epoch 2074/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359356.4375 - mean_squared_error: 359356.4375\n",
      "Epoch 2075/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354642.6562 - mean_squared_error: 354642.6562\n",
      "Epoch 2076/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359820.6562 - mean_squared_error: 359820.6562\n",
      "Epoch 2077/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 365515.9375 - mean_squared_error: 365515.9375\n",
      "Epoch 2078/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365801.9688 - mean_squared_error: 365801.9688\n",
      "Epoch 2079/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361841.3125 - mean_squared_error: 361841.3125\n",
      "Epoch 2080/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365966.9688 - mean_squared_error: 365966.9688\n",
      "Epoch 2081/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360016.3750 - mean_squared_error: 360016.3750\n",
      "Epoch 2082/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360816.7188 - mean_squared_error: 360816.7188\n",
      "Epoch 2083/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361084.5625 - mean_squared_error: 361084.6250\n",
      "Epoch 2084/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364579.5625 - mean_squared_error: 364579.5625\n",
      "Epoch 2085/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365474.0938 - mean_squared_error: 365474.0938\n",
      "Epoch 2086/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373651.1250 - mean_squared_error: 373651.0938\n",
      "Epoch 2087/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359686.1875 - mean_squared_error: 359686.1875\n",
      "Epoch 2088/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361307.0938 - mean_squared_error: 361307.0938\n",
      "Epoch 2089/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366656.1875 - mean_squared_error: 366656.1875\n",
      "Epoch 2090/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358418.2500 - mean_squared_error: 358418.2500\n",
      "Epoch 2091/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369508.8438 - mean_squared_error: 369508.8438\n",
      "Epoch 2092/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363328.2812 - mean_squared_error: 363328.2812\n",
      "Epoch 2093/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362808.1562 - mean_squared_error: 362808.1562\n",
      "Epoch 2094/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363229.1875 - mean_squared_error: 363229.1875\n",
      "Epoch 2095/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359477.6562 - mean_squared_error: 359477.6562\n",
      "Epoch 2096/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355465.0938 - mean_squared_error: 355465.0938\n",
      "Epoch 2097/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 363482.9688 - mean_squared_error: 363482.9688\n",
      "Epoch 2098/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364963.0000 - mean_squared_error: 364963.0312\n",
      "Epoch 2099/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359418.5312 - mean_squared_error: 359418.5312\n",
      "Epoch 2100/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354823.1250 - mean_squared_error: 354823.1250\n",
      "Epoch 2101/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365112.9375 - mean_squared_error: 365112.9375\n",
      "Epoch 2102/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359308.2812 - mean_squared_error: 359308.2812\n",
      "Epoch 2103/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 362051.8125 - mean_squared_error: 362051.8125\n",
      "Epoch 2104/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357058.3125 - mean_squared_error: 357058.3125\n",
      "Epoch 2105/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354121.6250 - mean_squared_error: 354121.6250\n",
      "Epoch 2106/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 365862.1562 - mean_squared_error: 365862.1562\n",
      "Epoch 2107/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 356941.4688 - mean_squared_error: 356941.4688\n",
      "Epoch 2108/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 360219.3438 - mean_squared_error: 360219.3438\n",
      "Epoch 2109/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 364466.0938 - mean_squared_error: 364466.0938\n",
      "Epoch 2110/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362283.8438 - mean_squared_error: 362283.8438\n",
      "Epoch 2111/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 367000.0625 - mean_squared_error: 367000.0625\n",
      "Epoch 2112/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361793.7812 - mean_squared_error: 361793.7812\n",
      "Epoch 2113/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357749.8750 - mean_squared_error: 357749.8750\n",
      "Epoch 2114/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354590.6250 - mean_squared_error: 354590.6250\n",
      "Epoch 2115/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365139.8750 - mean_squared_error: 365139.8750\n",
      "Epoch 2116/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358912.7500 - mean_squared_error: 358912.7500\n",
      "Epoch 2117/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361149.0625 - mean_squared_error: 361149.0625\n",
      "Epoch 2118/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361126.7500 - mean_squared_error: 361126.7500\n",
      "Epoch 2119/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356184.3125 - mean_squared_error: 356184.3125\n",
      "Epoch 2120/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362118.5938 - mean_squared_error: 362118.5938\n",
      "Epoch 2121/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360100.9062 - mean_squared_error: 360100.9062\n",
      "Epoch 2122/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359842.5000 - mean_squared_error: 359842.5000\n",
      "Epoch 2123/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357100.3750 - mean_squared_error: 357100.3750\n",
      "Epoch 2124/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362939.0312 - mean_squared_error: 362939.0312\n",
      "Epoch 2125/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353262.9375 - mean_squared_error: 353262.9375\n",
      "Epoch 2126/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354724.5312 - mean_squared_error: 354724.5312\n",
      "Epoch 2127/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360942.3750 - mean_squared_error: 360942.3438\n",
      "Epoch 2128/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356841.5312 - mean_squared_error: 356841.5312\n",
      "Epoch 2129/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353557.0938 - mean_squared_error: 353557.0938\n",
      "Epoch 2130/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356929.6250 - mean_squared_error: 356929.5938\n",
      "Epoch 2131/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355516.4062 - mean_squared_error: 355516.4062\n",
      "Epoch 2132/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356171.6250 - mean_squared_error: 356171.6250\n",
      "Epoch 2133/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357328.9688 - mean_squared_error: 357328.9688\n",
      "Epoch 2134/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357007.9375 - mean_squared_error: 357007.9375\n",
      "Epoch 2135/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358208.5625 - mean_squared_error: 358208.5625\n",
      "Epoch 2136/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358456.3750 - mean_squared_error: 358456.3750\n",
      "Epoch 2137/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356666.4688 - mean_squared_error: 356666.5000\n",
      "Epoch 2138/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353514.1562 - mean_squared_error: 353514.1562\n",
      "Epoch 2139/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354945.2188 - mean_squared_error: 354945.2188\n",
      "Epoch 2140/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356906.5938 - mean_squared_error: 356906.5938\n",
      "Epoch 2141/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359836.9688 - mean_squared_error: 359836.9688\n",
      "Epoch 2142/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 361258.5000 - mean_squared_error: 361258.5000\n",
      "Epoch 2143/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358307.4375 - mean_squared_error: 358307.4375\n",
      "Epoch 2144/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355532.4062 - mean_squared_error: 355532.4062\n",
      "Epoch 2145/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 357408.1875 - mean_squared_error: 357408.1875\n",
      "Epoch 2146/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360470.2188 - mean_squared_error: 360470.2188\n",
      "Epoch 2147/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358293.8750 - mean_squared_error: 358293.8750\n",
      "Epoch 2148/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355932.8750 - mean_squared_error: 355932.8750\n",
      "Epoch 2149/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354552.0000 - mean_squared_error: 354552.0000\n",
      "Epoch 2150/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356942.3750 - mean_squared_error: 356942.3438\n",
      "Epoch 2151/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357194.1875 - mean_squared_error: 357194.2188\n",
      "Epoch 2152/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350942.8750 - mean_squared_error: 350942.8750\n",
      "Epoch 2153/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 360195.0938 - mean_squared_error: 360195.0938\n",
      "Epoch 2154/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354939.6250 - mean_squared_error: 354939.6250\n",
      "Epoch 2155/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364401.7500 - mean_squared_error: 364401.7500\n",
      "Epoch 2156/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359719.4375 - mean_squared_error: 359719.4375\n",
      "Epoch 2157/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358280.5625 - mean_squared_error: 358280.5312\n",
      "Epoch 2158/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351839.9375 - mean_squared_error: 351839.9688\n",
      "Epoch 2159/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368244.0312 - mean_squared_error: 368244.0312\n",
      "Epoch 2160/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356930.9688 - mean_squared_error: 356930.9375\n",
      "Epoch 2161/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355191.8438 - mean_squared_error: 355191.8438\n",
      "Epoch 2162/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354323.9688 - mean_squared_error: 354323.9688\n",
      "Epoch 2163/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353645.5938 - mean_squared_error: 353645.5938\n",
      "Epoch 2164/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356327.4375 - mean_squared_error: 356327.4375\n",
      "Epoch 2165/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353564.7188 - mean_squared_error: 353564.7188\n",
      "Epoch 2166/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352475.6562 - mean_squared_error: 352475.6562\n",
      "Epoch 2167/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350068.8750 - mean_squared_error: 350068.8750\n",
      "Epoch 2168/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353470.7812 - mean_squared_error: 353470.8125\n",
      "Epoch 2169/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351317.9688 - mean_squared_error: 351317.9688\n",
      "Epoch 2170/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357247.8438 - mean_squared_error: 357247.8125\n",
      "Epoch 2171/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354602.8750 - mean_squared_error: 354602.8750\n",
      "Epoch 2172/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356309.9688 - mean_squared_error: 356309.9688\n",
      "Epoch 2173/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356859.2188 - mean_squared_error: 356859.2188\n",
      "Epoch 2174/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354284.6875 - mean_squared_error: 354284.7188\n",
      "Epoch 2175/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358142.4688 - mean_squared_error: 358142.4688\n",
      "Epoch 2176/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355130.6250 - mean_squared_error: 355130.6250\n",
      "Epoch 2177/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355950.5625 - mean_squared_error: 355950.5625\n",
      "Epoch 2178/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354187.1875 - mean_squared_error: 354187.1875\n",
      "Epoch 2179/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366171.3438 - mean_squared_error: 366171.3438\n",
      "Epoch 2180/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358975.8750 - mean_squared_error: 358975.8750\n",
      "Epoch 2181/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356632.3750 - mean_squared_error: 356632.3750\n",
      "Epoch 2182/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352738.4062 - mean_squared_error: 352738.4062\n",
      "Epoch 2183/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349688.4688 - mean_squared_error: 349688.4688\n",
      "Epoch 2184/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 350987.6250 - mean_squared_error: 350987.6250\n",
      "Epoch 2185/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356806.0000 - mean_squared_error: 356806.0000\n",
      "Epoch 2186/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354784.7812 - mean_squared_error: 354784.8125\n",
      "Epoch 2187/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354958.0938 - mean_squared_error: 354958.0625\n",
      "Epoch 2188/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352421.6875 - mean_squared_error: 352421.6875\n",
      "Epoch 2189/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358459.0938 - mean_squared_error: 358459.0938\n",
      "Epoch 2190/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356360.4375 - mean_squared_error: 356360.4375\n",
      "Epoch 2191/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 351966.7188 - mean_squared_error: 351966.7188\n",
      "Epoch 2192/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349365.4062 - mean_squared_error: 349365.4062\n",
      "Epoch 2193/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353025.3125 - mean_squared_error: 353025.3125\n",
      "Epoch 2194/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360945.2500 - mean_squared_error: 360945.2500\n",
      "Epoch 2195/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354730.0312 - mean_squared_error: 354730.0312\n",
      "Epoch 2196/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 363899.5625 - mean_squared_error: 363899.5625\n",
      "Epoch 2197/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354904.5312 - mean_squared_error: 354904.5312\n",
      "Epoch 2198/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354588.4375 - mean_squared_error: 354588.4375\n",
      "Epoch 2199/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353700.3125 - mean_squared_error: 353700.3125\n",
      "Epoch 2200/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351950.6250 - mean_squared_error: 351950.6250\n",
      "Epoch 2201/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357294.8750 - mean_squared_error: 357294.8750\n",
      "Epoch 2202/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357483.8750 - mean_squared_error: 357483.8750\n",
      "Epoch 2203/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358390.2188 - mean_squared_error: 358390.2188\n",
      "Epoch 2204/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355322.9375 - mean_squared_error: 355322.9375\n",
      "Epoch 2205/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357108.8750 - mean_squared_error: 357108.8750\n",
      "Epoch 2206/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353856.8125 - mean_squared_error: 353856.7812\n",
      "Epoch 2207/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363975.9062 - mean_squared_error: 363975.9062\n",
      "Epoch 2208/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350424.2500 - mean_squared_error: 350424.2500\n",
      "Epoch 2209/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350023.3438 - mean_squared_error: 350023.3438\n",
      "Epoch 2210/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356213.5312 - mean_squared_error: 356213.5312\n",
      "Epoch 2211/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355254.3125 - mean_squared_error: 355254.3125\n",
      "Epoch 2212/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347579.4375 - mean_squared_error: 347579.4375\n",
      "Epoch 2213/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350205.5625 - mean_squared_error: 350205.5625\n",
      "Epoch 2214/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349837.0938 - mean_squared_error: 349837.0938\n",
      "Epoch 2215/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355130.8750 - mean_squared_error: 355130.8750\n",
      "Epoch 2216/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346305.4688 - mean_squared_error: 346305.4688\n",
      "Epoch 2217/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351991.4375 - mean_squared_error: 351991.4375\n",
      "Epoch 2218/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345222.0000 - mean_squared_error: 345222.0000\n",
      "Epoch 2219/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351384.4688 - mean_squared_error: 351384.4688\n",
      "Epoch 2220/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356390.4062 - mean_squared_error: 356390.4062\n",
      "Epoch 2221/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350210.0938 - mean_squared_error: 350210.0938\n",
      "Epoch 2222/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 358522.8125 - mean_squared_error: 358522.8125\n",
      "Epoch 2223/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347005.8438 - mean_squared_error: 347005.8438\n",
      "Epoch 2224/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354819.9062 - mean_squared_error: 354819.9062\n",
      "Epoch 2225/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358531.4375 - mean_squared_error: 358531.4375\n",
      "Epoch 2226/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351607.5312 - mean_squared_error: 351607.5312\n",
      "Epoch 2227/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358002.1250 - mean_squared_error: 358002.1562\n",
      "Epoch 2228/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343458.2188 - mean_squared_error: 343458.2188\n",
      "Epoch 2229/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353808.0312 - mean_squared_error: 353808.0312\n",
      "Epoch 2230/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358119.5938 - mean_squared_error: 358119.5938\n",
      "Epoch 2231/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356623.6562 - mean_squared_error: 356623.6562\n",
      "Epoch 2232/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353341.8750 - mean_squared_error: 353341.8750\n",
      "Epoch 2233/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346776.2188 - mean_squared_error: 346776.2188\n",
      "Epoch 2234/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346291.6250 - mean_squared_error: 346291.6250\n",
      "Epoch 2235/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346735.7188 - mean_squared_error: 346735.7812\n",
      "Epoch 2236/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355081.4375 - mean_squared_error: 355081.4062\n",
      "Epoch 2237/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349863.3125 - mean_squared_error: 349863.3125\n",
      "Epoch 2238/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354574.2188 - mean_squared_error: 354574.2188\n",
      "Epoch 2239/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356681.9062 - mean_squared_error: 356681.9375\n",
      "Epoch 2240/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 353805.5625 - mean_squared_error: 353805.5625\n",
      "Epoch 2241/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357086.4688 - mean_squared_error: 357086.4688\n",
      "Epoch 2242/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354889.8750 - mean_squared_error: 354889.8750\n",
      "Epoch 2243/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352821.7500 - mean_squared_error: 352821.7500\n",
      "Epoch 2244/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353077.0312 - mean_squared_error: 353077.0000\n",
      "Epoch 2245/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349624.7500 - mean_squared_error: 349624.7500\n",
      "Epoch 2246/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348068.9688 - mean_squared_error: 348068.9688\n",
      "Epoch 2247/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351806.3438 - mean_squared_error: 351806.3438\n",
      "Epoch 2248/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354102.1250 - mean_squared_error: 354102.1250\n",
      "Epoch 2249/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358543.5625 - mean_squared_error: 358543.5625\n",
      "Epoch 2250/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351833.8438 - mean_squared_error: 351833.8438\n",
      "Epoch 2251/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352686.9375 - mean_squared_error: 352686.9375\n",
      "Epoch 2252/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352655.4062 - mean_squared_error: 352655.4062\n",
      "Epoch 2253/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353581.2500 - mean_squared_error: 353581.2500\n",
      "Epoch 2254/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358794.7500 - mean_squared_error: 358794.7500\n",
      "Epoch 2255/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351754.0938 - mean_squared_error: 351754.0938\n",
      "Epoch 2256/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348815.7188 - mean_squared_error: 348815.7188\n",
      "Epoch 2257/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358944.5000 - mean_squared_error: 358944.5000\n",
      "Epoch 2258/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350406.2500 - mean_squared_error: 350406.2500\n",
      "Epoch 2259/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346699.0625 - mean_squared_error: 346699.0625\n",
      "Epoch 2260/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352314.4375 - mean_squared_error: 352314.4375\n",
      "Epoch 2261/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347710.2188 - mean_squared_error: 347710.2188\n",
      "Epoch 2262/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346272.8438 - mean_squared_error: 346272.8438\n",
      "Epoch 2263/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 360835.4375 - mean_squared_error: 360835.4375\n",
      "Epoch 2264/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356858.4688 - mean_squared_error: 356858.4688\n",
      "Epoch 2265/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347523.6562 - mean_squared_error: 347523.6562\n",
      "Epoch 2266/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 353911.2812 - mean_squared_error: 353911.2812\n",
      "Epoch 2267/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357811.8750 - mean_squared_error: 357811.9062\n",
      "Epoch 2268/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349489.2500 - mean_squared_error: 349489.2500\n",
      "Epoch 2269/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350941.4375 - mean_squared_error: 350941.4375\n",
      "Epoch 2270/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349753.1562 - mean_squared_error: 349753.1562\n",
      "Epoch 2271/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352051.9062 - mean_squared_error: 352051.9062\n",
      "Epoch 2272/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345601.6562 - mean_squared_error: 345601.6562\n",
      "Epoch 2273/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351603.7500 - mean_squared_error: 351603.7500\n",
      "Epoch 2274/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350051.5000 - mean_squared_error: 350051.5000\n",
      "Epoch 2275/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343770.1875 - mean_squared_error: 343770.1875\n",
      "Epoch 2276/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359484.6250 - mean_squared_error: 359484.6250\n",
      "Epoch 2277/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348947.2188 - mean_squared_error: 348947.2188\n",
      "Epoch 2278/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346318.7188 - mean_squared_error: 346318.7188\n",
      "Epoch 2279/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353975.9375 - mean_squared_error: 353975.9375\n",
      "Epoch 2280/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 353507.0938 - mean_squared_error: 353507.0938\n",
      "Epoch 2281/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353439.6250 - mean_squared_error: 353439.5938\n",
      "Epoch 2282/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348452.5938 - mean_squared_error: 348452.5938\n",
      "Epoch 2283/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346425.2812 - mean_squared_error: 346425.2812\n",
      "Epoch 2284/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356969.5625 - mean_squared_error: 356969.5625\n",
      "Epoch 2285/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350030.9688 - mean_squared_error: 350030.9688\n",
      "Epoch 2286/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354238.7500 - mean_squared_error: 354238.7812\n",
      "Epoch 2287/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353882.3125 - mean_squared_error: 353882.3125\n",
      "Epoch 2288/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347936.7812 - mean_squared_error: 347936.7812\n",
      "Epoch 2289/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340096.5625 - mean_squared_error: 340096.5625\n",
      "Epoch 2290/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349216.6250 - mean_squared_error: 349216.6250\n",
      "Epoch 2291/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344922.4688 - mean_squared_error: 344922.4688\n",
      "Epoch 2292/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350965.0000 - mean_squared_error: 350965.0000\n",
      "Epoch 2293/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349457.6250 - mean_squared_error: 349457.6250\n",
      "Epoch 2294/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349079.5938 - mean_squared_error: 349079.5938\n",
      "Epoch 2295/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345647.0938 - mean_squared_error: 345647.0938\n",
      "Epoch 2296/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351439.6250 - mean_squared_error: 351439.6250\n",
      "Epoch 2297/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344262.2188 - mean_squared_error: 344262.2188\n",
      "Epoch 2298/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350218.1250 - mean_squared_error: 350218.1250\n",
      "Epoch 2299/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346225.6562 - mean_squared_error: 346225.6562\n",
      "Epoch 2300/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357159.1562 - mean_squared_error: 357159.1562\n",
      "Epoch 2301/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345982.0312 - mean_squared_error: 345982.0625\n",
      "Epoch 2302/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347356.6562 - mean_squared_error: 347356.6562\n",
      "Epoch 2303/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350215.0625 - mean_squared_error: 350215.0625\n",
      "Epoch 2304/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 354544.0000 - mean_squared_error: 354544.0000\n",
      "Epoch 2305/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349903.0938 - mean_squared_error: 349903.0938\n",
      "Epoch 2306/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352841.9062 - mean_squared_error: 352841.9062\n",
      "Epoch 2307/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357773.5625 - mean_squared_error: 357773.5625\n",
      "Epoch 2308/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352350.5312 - mean_squared_error: 352350.5312\n",
      "Epoch 2309/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352270.2500 - mean_squared_error: 352270.2500\n",
      "Epoch 2310/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355738.5312 - mean_squared_error: 355738.5312\n",
      "Epoch 2311/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337372.5938 - mean_squared_error: 337372.5938\n",
      "Epoch 2312/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350516.9375 - mean_squared_error: 350516.9375\n",
      "Epoch 2313/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349565.5312 - mean_squared_error: 349565.5625\n",
      "Epoch 2314/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349035.1562 - mean_squared_error: 349035.1562\n",
      "Epoch 2315/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353622.4375 - mean_squared_error: 353622.4375\n",
      "Epoch 2316/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346210.6250 - mean_squared_error: 346210.6250\n",
      "Epoch 2317/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346707.7188 - mean_squared_error: 346707.7188\n",
      "Epoch 2318/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348145.1250 - mean_squared_error: 348145.1250\n",
      "Epoch 2319/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358325.6562 - mean_squared_error: 358325.6562\n",
      "Epoch 2320/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345216.2500 - mean_squared_error: 345216.2500\n",
      "Epoch 2321/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352105.1250 - mean_squared_error: 352105.1250\n",
      "Epoch 2322/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348759.0312 - mean_squared_error: 348759.0000\n",
      "Epoch 2323/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352490.6250 - mean_squared_error: 352490.6250\n",
      "Epoch 2324/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352045.5312 - mean_squared_error: 352045.5312\n",
      "Epoch 2325/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351298.0938 - mean_squared_error: 351298.0938\n",
      "Epoch 2326/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346089.8438 - mean_squared_error: 346089.8438\n",
      "Epoch 2327/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343851.1875 - mean_squared_error: 343851.1875\n",
      "Epoch 2328/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344946.5938 - mean_squared_error: 344946.5938\n",
      "Epoch 2329/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350756.5938 - mean_squared_error: 350756.5938\n",
      "Epoch 2330/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348731.0312 - mean_squared_error: 348731.0312\n",
      "Epoch 2331/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351267.9062 - mean_squared_error: 351267.9062\n",
      "Epoch 2332/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348949.3438 - mean_squared_error: 348949.3750\n",
      "Epoch 2333/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356812.3125 - mean_squared_error: 356812.3125\n",
      "Epoch 2334/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352182.7500 - mean_squared_error: 352182.7500\n",
      "Epoch 2335/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352409.8750 - mean_squared_error: 352409.8750\n",
      "Epoch 2336/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342800.2188 - mean_squared_error: 342800.2188\n",
      "Epoch 2337/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348436.7500 - mean_squared_error: 348436.7188\n",
      "Epoch 2338/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345264.8438 - mean_squared_error: 345264.8438\n",
      "Epoch 2339/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341326.1875 - mean_squared_error: 341326.1875\n",
      "Epoch 2340/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357680.4688 - mean_squared_error: 357680.4688\n",
      "Epoch 2341/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355131.7188 - mean_squared_error: 355131.7188\n",
      "Epoch 2342/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344307.0625 - mean_squared_error: 344307.0625\n",
      "Epoch 2343/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348530.7188 - mean_squared_error: 348530.7188\n",
      "Epoch 2344/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357375.4062 - mean_squared_error: 357375.4062\n",
      "Epoch 2345/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349554.3125 - mean_squared_error: 349554.3125\n",
      "Epoch 2346/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349000.9688 - mean_squared_error: 349000.9375\n",
      "Epoch 2347/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355176.4062 - mean_squared_error: 355176.4062\n",
      "Epoch 2348/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345963.5938 - mean_squared_error: 345963.5938\n",
      "Epoch 2349/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351001.3750 - mean_squared_error: 351001.3750\n",
      "Epoch 2350/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342635.3750 - mean_squared_error: 342635.3750\n",
      "Epoch 2351/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354333.2812 - mean_squared_error: 354333.2812\n",
      "Epoch 2352/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358187.6562 - mean_squared_error: 358187.6562\n",
      "Epoch 2353/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352267.0625 - mean_squared_error: 352267.0625\n",
      "Epoch 2354/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 357355.9062 - mean_squared_error: 357355.9062\n",
      "Epoch 2355/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345853.6250 - mean_squared_error: 345853.6250\n",
      "Epoch 2356/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342421.0938 - mean_squared_error: 342421.0938\n",
      "Epoch 2357/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337021.3438 - mean_squared_error: 337021.3438\n",
      "Epoch 2358/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351952.9375 - mean_squared_error: 351952.9375\n",
      "Epoch 2359/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343108.6250 - mean_squared_error: 343108.6250\n",
      "Epoch 2360/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353931.0312 - mean_squared_error: 353931.0312\n",
      "Epoch 2361/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342299.1875 - mean_squared_error: 342299.1562\n",
      "Epoch 2362/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348246.2812 - mean_squared_error: 348246.2812\n",
      "Epoch 2363/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352265.6250 - mean_squared_error: 352265.6562\n",
      "Epoch 2364/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348304.4062 - mean_squared_error: 348304.4062\n",
      "Epoch 2365/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342270.5625 - mean_squared_error: 342270.5625\n",
      "Epoch 2366/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343669.7812 - mean_squared_error: 343669.7812\n",
      "Epoch 2367/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346998.0312 - mean_squared_error: 346998.0312\n",
      "Epoch 2368/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352922.7188 - mean_squared_error: 352922.7188\n",
      "Epoch 2369/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344858.3750 - mean_squared_error: 344858.3750\n",
      "Epoch 2370/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344071.6250 - mean_squared_error: 344071.6250\n",
      "Epoch 2371/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351070.1562 - mean_squared_error: 351070.1250\n",
      "Epoch 2372/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 346840.8750 - mean_squared_error: 346840.8750\n",
      "Epoch 2373/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343602.7188 - mean_squared_error: 343602.7188\n",
      "Epoch 2374/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352301.7812 - mean_squared_error: 352301.7812\n",
      "Epoch 2375/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346421.0625 - mean_squared_error: 346421.0938\n",
      "Epoch 2376/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342949.2500 - mean_squared_error: 342949.2500\n",
      "Epoch 2377/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346422.7188 - mean_squared_error: 346422.7188\n",
      "Epoch 2378/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346033.8438 - mean_squared_error: 346033.8438\n",
      "Epoch 2379/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348624.6562 - mean_squared_error: 348624.6562\n",
      "Epoch 2380/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348026.5625 - mean_squared_error: 348026.5625\n",
      "Epoch 2381/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348646.8438 - mean_squared_error: 348646.8438\n",
      "Epoch 2382/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352777.7500 - mean_squared_error: 352777.7500\n",
      "Epoch 2383/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354762.3438 - mean_squared_error: 354762.3438\n",
      "Epoch 2384/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351959.1875 - mean_squared_error: 351959.1875\n",
      "Epoch 2385/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351400.6875 - mean_squared_error: 351400.6875\n",
      "Epoch 2386/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352473.3438 - mean_squared_error: 352473.3438\n",
      "Epoch 2387/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351209.9688 - mean_squared_error: 351209.9688\n",
      "Epoch 2388/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348557.4062 - mean_squared_error: 348557.4062\n",
      "Epoch 2389/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348464.6562 - mean_squared_error: 348464.6562\n",
      "Epoch 2390/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344324.7188 - mean_squared_error: 344324.7188\n",
      "Epoch 2391/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347529.2500 - mean_squared_error: 347529.2500\n",
      "Epoch 2392/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343882.5625 - mean_squared_error: 343882.5625\n",
      "Epoch 2393/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343146.9062 - mean_squared_error: 343146.9062\n",
      "Epoch 2394/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359569.9688 - mean_squared_error: 359569.9688\n",
      "Epoch 2395/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348624.0625 - mean_squared_error: 348624.0625\n",
      "Epoch 2396/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343269.3125 - mean_squared_error: 343269.3125\n",
      "Epoch 2397/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349313.4062 - mean_squared_error: 349313.4062\n",
      "Epoch 2398/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346162.7188 - mean_squared_error: 346162.7188\n",
      "Epoch 2399/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340597.5000 - mean_squared_error: 340597.5000\n",
      "Epoch 2400/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359648.7188 - mean_squared_error: 359648.7188\n",
      "Epoch 2401/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345072.7188 - mean_squared_error: 345072.7188\n",
      "Epoch 2402/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346199.6250 - mean_squared_error: 346199.6250\n",
      "Epoch 2403/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356664.5938 - mean_squared_error: 356664.5938\n",
      "Epoch 2404/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352361.0625 - mean_squared_error: 352361.0625\n",
      "Epoch 2405/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349417.9688 - mean_squared_error: 349417.9688\n",
      "Epoch 2406/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352815.0312 - mean_squared_error: 352815.0312\n",
      "Epoch 2407/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342795.6250 - mean_squared_error: 342795.6250\n",
      "Epoch 2408/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345996.1250 - mean_squared_error: 345996.1250\n",
      "Epoch 2409/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338363.0000 - mean_squared_error: 338363.0000\n",
      "Epoch 2410/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352599.3438 - mean_squared_error: 352599.3438\n",
      "Epoch 2411/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351183.4688 - mean_squared_error: 351183.4688\n",
      "Epoch 2412/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350364.3750 - mean_squared_error: 350364.3750\n",
      "Epoch 2413/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346608.1250 - mean_squared_error: 346608.1250\n",
      "Epoch 2414/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344401.7812 - mean_squared_error: 344401.7812\n",
      "Epoch 2415/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352706.3125 - mean_squared_error: 352706.3125\n",
      "Epoch 2416/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 345865.0938 - mean_squared_error: 345865.0938\n",
      "Epoch 2417/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335675.6250 - mean_squared_error: 335675.6250\n",
      "Epoch 2418/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352323.1562 - mean_squared_error: 352323.1562\n",
      "Epoch 2419/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354815.2812 - mean_squared_error: 354815.3125\n",
      "Epoch 2420/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350174.0312 - mean_squared_error: 350174.0312\n",
      "Epoch 2421/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346487.0938 - mean_squared_error: 346487.0938\n",
      "Epoch 2422/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343319.8750 - mean_squared_error: 343319.8750\n",
      "Epoch 2423/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353344.7500 - mean_squared_error: 353344.7500\n",
      "Epoch 2424/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348667.6562 - mean_squared_error: 348667.6562\n",
      "Epoch 2425/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353545.1250 - mean_squared_error: 353545.1250\n",
      "Epoch 2426/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351569.9375 - mean_squared_error: 351569.9688\n",
      "Epoch 2427/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347149.1875 - mean_squared_error: 347149.1875\n",
      "Epoch 2428/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352350.4062 - mean_squared_error: 352350.4062\n",
      "Epoch 2429/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354009.7812 - mean_squared_error: 354009.7812\n",
      "Epoch 2430/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343246.7812 - mean_squared_error: 343246.7812\n",
      "Epoch 2431/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340101.6875 - mean_squared_error: 340101.6875\n",
      "Epoch 2432/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345103.9062 - mean_squared_error: 345103.9375\n",
      "Epoch 2433/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344029.5938 - mean_squared_error: 344029.5938\n",
      "Epoch 2434/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340357.6562 - mean_squared_error: 340357.6562\n",
      "Epoch 2435/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347550.3438 - mean_squared_error: 347550.4062\n",
      "Epoch 2436/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343587.5312 - mean_squared_error: 343587.5312\n",
      "Epoch 2437/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354102.3750 - mean_squared_error: 354102.3750\n",
      "Epoch 2438/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349612.0312 - mean_squared_error: 349612.0312\n",
      "Epoch 2439/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348343.2500 - mean_squared_error: 348343.2500\n",
      "Epoch 2440/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345704.6875 - mean_squared_error: 345704.6875\n",
      "Epoch 2441/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352109.9375 - mean_squared_error: 352109.9375\n",
      "Epoch 2442/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345641.2188 - mean_squared_error: 345641.2188\n",
      "Epoch 2443/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348368.2188 - mean_squared_error: 348368.2188\n",
      "Epoch 2444/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344089.1875 - mean_squared_error: 344089.1875\n",
      "Epoch 2445/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349319.4375 - mean_squared_error: 349319.4375\n",
      "Epoch 2446/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350657.0000 - mean_squared_error: 350657.0000\n",
      "Epoch 2447/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347997.8750 - mean_squared_error: 347997.8750\n",
      "Epoch 2448/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350856.5625 - mean_squared_error: 350856.5625\n",
      "Epoch 2449/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348441.1875 - mean_squared_error: 348441.1875\n",
      "Epoch 2450/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349085.8438 - mean_squared_error: 349085.8438\n",
      "Epoch 2451/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351013.0938 - mean_squared_error: 351013.0938\n",
      "Epoch 2452/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352309.3750 - mean_squared_error: 352309.3750\n",
      "Epoch 2453/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347976.4062 - mean_squared_error: 347976.4062\n",
      "Epoch 2454/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345557.8438 - mean_squared_error: 345557.8438\n",
      "Epoch 2455/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354168.2188 - mean_squared_error: 354168.2188\n",
      "Epoch 2456/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348740.7500 - mean_squared_error: 348740.7500\n",
      "Epoch 2457/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347874.3438 - mean_squared_error: 347874.3438\n",
      "Epoch 2458/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344272.5625 - mean_squared_error: 344272.5625\n",
      "Epoch 2459/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340267.1562 - mean_squared_error: 340267.1562\n",
      "Epoch 2460/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347774.8438 - mean_squared_error: 347774.8438\n",
      "Epoch 2461/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351113.3750 - mean_squared_error: 351113.3750\n",
      "Epoch 2462/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340341.7188 - mean_squared_error: 340341.7188\n",
      "Epoch 2463/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343463.7188 - mean_squared_error: 343463.7188\n",
      "Epoch 2464/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343923.7812 - mean_squared_error: 343923.7812\n",
      "Epoch 2465/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345881.0312 - mean_squared_error: 345881.0312\n",
      "Epoch 2466/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353202.5000 - mean_squared_error: 353202.5000\n",
      "Epoch 2467/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346242.2188 - mean_squared_error: 346242.2188\n",
      "Epoch 2468/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345883.6562 - mean_squared_error: 345883.6562\n",
      "Epoch 2469/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348733.7500 - mean_squared_error: 348733.7500\n",
      "Epoch 2470/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350189.9062 - mean_squared_error: 350189.9062\n",
      "Epoch 2471/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345546.0312 - mean_squared_error: 345546.0312\n",
      "Epoch 2472/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349588.3438 - mean_squared_error: 349588.3438\n",
      "Epoch 2473/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353183.5000 - mean_squared_error: 353183.5000\n",
      "Epoch 2474/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350778.4688 - mean_squared_error: 350778.4688\n",
      "Epoch 2475/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345135.9062 - mean_squared_error: 345135.9062\n",
      "Epoch 2476/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347044.7812 - mean_squared_error: 347044.7812\n",
      "Epoch 2477/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344878.0312 - mean_squared_error: 344878.0000\n",
      "Epoch 2478/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349374.0000 - mean_squared_error: 349374.0000\n",
      "Epoch 2479/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347051.9062 - mean_squared_error: 347051.9062\n",
      "Epoch 2480/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341550.6250 - mean_squared_error: 341550.6250\n",
      "Epoch 2481/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357065.9062 - mean_squared_error: 357065.9062\n",
      "Epoch 2482/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357284.2812 - mean_squared_error: 357284.2812\n",
      "Epoch 2483/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337289.3750 - mean_squared_error: 337289.3750\n",
      "Epoch 2484/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349406.5938 - mean_squared_error: 349406.5938\n",
      "Epoch 2485/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347455.9062 - mean_squared_error: 347455.9062\n",
      "Epoch 2486/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347773.5000 - mean_squared_error: 347773.5312\n",
      "Epoch 2487/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350123.8750 - mean_squared_error: 350123.8750\n",
      "Epoch 2488/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339437.2812 - mean_squared_error: 339437.2812\n",
      "Epoch 2489/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345660.4688 - mean_squared_error: 345660.4375\n",
      "Epoch 2490/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339566.5938 - mean_squared_error: 339566.5938\n",
      "Epoch 2491/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346189.3438 - mean_squared_error: 346189.3438\n",
      "Epoch 2492/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342708.4375 - mean_squared_error: 342708.4375\n",
      "Epoch 2493/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347124.0625 - mean_squared_error: 347124.0625\n",
      "Epoch 2494/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349170.4062 - mean_squared_error: 349170.4062\n",
      "Epoch 2495/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346854.6875 - mean_squared_error: 346854.6875\n",
      "Epoch 2496/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346119.3438 - mean_squared_error: 346119.3438\n",
      "Epoch 2497/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341854.5000 - mean_squared_error: 341854.5000\n",
      "Epoch 2498/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346617.6250 - mean_squared_error: 346617.6250\n",
      "Epoch 2499/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341175.8438 - mean_squared_error: 341175.8438\n",
      "Epoch 2500/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336923.1250 - mean_squared_error: 336923.1250\n",
      "Epoch 2501/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343230.0938 - mean_squared_error: 343230.0938\n",
      "Epoch 2502/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 345908.1562 - mean_squared_error: 345908.1562\n",
      "Epoch 2503/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346780.0312 - mean_squared_error: 346780.0312\n",
      "Epoch 2504/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 348226.2188 - mean_squared_error: 348226.2188\n",
      "Epoch 2505/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350919.9062 - mean_squared_error: 350919.9062\n",
      "Epoch 2506/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342168.1250 - mean_squared_error: 342168.1250\n",
      "Epoch 2507/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342087.4062 - mean_squared_error: 342087.4062\n",
      "Epoch 2508/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348214.5312 - mean_squared_error: 348214.5312\n",
      "Epoch 2509/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348602.1875 - mean_squared_error: 348602.2188\n",
      "Epoch 2510/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347670.1250 - mean_squared_error: 347670.1250\n",
      "Epoch 2511/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340642.9688 - mean_squared_error: 340642.9688\n",
      "Epoch 2512/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344029.4688 - mean_squared_error: 344029.4688\n",
      "Epoch 2513/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342526.6562 - mean_squared_error: 342526.6562\n",
      "Epoch 2514/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348055.4375 - mean_squared_error: 348055.4375\n",
      "Epoch 2515/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347112.9062 - mean_squared_error: 347112.9062\n",
      "Epoch 2516/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347853.9375 - mean_squared_error: 347853.9375\n",
      "Epoch 2517/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344068.0938 - mean_squared_error: 344068.0938\n",
      "Epoch 2518/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353937.7188 - mean_squared_error: 353937.7188\n",
      "Epoch 2519/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343632.0625 - mean_squared_error: 343632.0625\n",
      "Epoch 2520/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338140.0312 - mean_squared_error: 338140.0625\n",
      "Epoch 2521/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347264.3750 - mean_squared_error: 347264.3750\n",
      "Epoch 2522/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352338.6250 - mean_squared_error: 352338.6250\n",
      "Epoch 2523/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338651.4062 - mean_squared_error: 338651.4062\n",
      "Epoch 2524/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344084.1562 - mean_squared_error: 344084.1562\n",
      "Epoch 2525/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 356071.8750 - mean_squared_error: 356071.8750\n",
      "Epoch 2526/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351653.0938 - mean_squared_error: 351653.0938\n",
      "Epoch 2527/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351544.5938 - mean_squared_error: 351544.5938\n",
      "Epoch 2528/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338326.5312 - mean_squared_error: 338326.5312\n",
      "Epoch 2529/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344204.2812 - mean_squared_error: 344204.2812\n",
      "Epoch 2530/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349257.3750 - mean_squared_error: 349257.3750\n",
      "Epoch 2531/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344204.0938 - mean_squared_error: 344204.0938\n",
      "Epoch 2532/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344206.8438 - mean_squared_error: 344206.8438\n",
      "Epoch 2533/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348477.3750 - mean_squared_error: 348477.3750\n",
      "Epoch 2534/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345129.6875 - mean_squared_error: 345129.6875\n",
      "Epoch 2535/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343306.3125 - mean_squared_error: 343306.3125\n",
      "Epoch 2536/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337625.2812 - mean_squared_error: 337625.2812\n",
      "Epoch 2537/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352176.5000 - mean_squared_error: 352176.5000\n",
      "Epoch 2538/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342535.0312 - mean_squared_error: 342535.0312\n",
      "Epoch 2539/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344589.8750 - mean_squared_error: 344589.8750\n",
      "Epoch 2540/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346058.9062 - mean_squared_error: 346058.9062\n",
      "Epoch 2541/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347691.8438 - mean_squared_error: 347691.8438\n",
      "Epoch 2542/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347504.6250 - mean_squared_error: 347504.6250\n",
      "Epoch 2543/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348101.0938 - mean_squared_error: 348101.0938\n",
      "Epoch 2544/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334904.8438 - mean_squared_error: 334904.8438\n",
      "Epoch 2545/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350156.1875 - mean_squared_error: 350156.1562\n",
      "Epoch 2546/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348236.1250 - mean_squared_error: 348236.1250\n",
      "Epoch 2547/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348461.8125 - mean_squared_error: 348461.8125\n",
      "Epoch 2548/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339061.6562 - mean_squared_error: 339061.6562\n",
      "Epoch 2549/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340460.8750 - mean_squared_error: 340460.8750\n",
      "Epoch 2550/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337781.6250 - mean_squared_error: 337781.5938\n",
      "Epoch 2551/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342942.5000 - mean_squared_error: 342942.5000\n",
      "Epoch 2552/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345381.1875 - mean_squared_error: 345381.1875\n",
      "Epoch 2553/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345887.4375 - mean_squared_error: 345887.4375\n",
      "Epoch 2554/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348592.8750 - mean_squared_error: 348592.8750\n",
      "Epoch 2555/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347130.8125 - mean_squared_error: 347130.8125\n",
      "Epoch 2556/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342682.2188 - mean_squared_error: 342682.2500\n",
      "Epoch 2557/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343565.6562 - mean_squared_error: 343565.6562\n",
      "Epoch 2558/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343523.3125 - mean_squared_error: 343523.2812\n",
      "Epoch 2559/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351431.8750 - mean_squared_error: 351431.8750\n",
      "Epoch 2560/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345213.8438 - mean_squared_error: 345213.8438\n",
      "Epoch 2561/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341315.6250 - mean_squared_error: 341315.6250\n",
      "Epoch 2562/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356277.5625 - mean_squared_error: 356277.5938\n",
      "Epoch 2563/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346999.2812 - mean_squared_error: 346999.2812\n",
      "Epoch 2564/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349728.0000 - mean_squared_error: 349728.0000\n",
      "Epoch 2565/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343169.8438 - mean_squared_error: 343169.8438\n",
      "Epoch 2566/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343366.8438 - mean_squared_error: 343366.8438\n",
      "Epoch 2567/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344617.0000 - mean_squared_error: 344617.0000\n",
      "Epoch 2568/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342563.1250 - mean_squared_error: 342563.1250\n",
      "Epoch 2569/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348966.5312 - mean_squared_error: 348966.5312\n",
      "Epoch 2570/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336509.3125 - mean_squared_error: 336509.3125\n",
      "Epoch 2571/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347298.8750 - mean_squared_error: 347298.8750\n",
      "Epoch 2572/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 349160.5312 - mean_squared_error: 349160.5312\n",
      "Epoch 2573/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350689.9062 - mean_squared_error: 350689.9062\n",
      "Epoch 2574/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345820.0000 - mean_squared_error: 345820.0000\n",
      "Epoch 2575/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347180.7812 - mean_squared_error: 347180.7812\n",
      "Epoch 2576/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341457.0625 - mean_squared_error: 341457.0625\n",
      "Epoch 2577/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346800.8750 - mean_squared_error: 346800.8750\n",
      "Epoch 2578/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341629.2188 - mean_squared_error: 341629.2188\n",
      "Epoch 2579/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353094.0938 - mean_squared_error: 353094.0938\n",
      "Epoch 2580/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336991.5625 - mean_squared_error: 336991.5625\n",
      "Epoch 2581/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337583.5312 - mean_squared_error: 337583.5312\n",
      "Epoch 2582/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340848.4375 - mean_squared_error: 340848.4062\n",
      "Epoch 2583/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341240.2812 - mean_squared_error: 341240.2812\n",
      "Epoch 2584/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340511.5625 - mean_squared_error: 340511.5625\n",
      "Epoch 2585/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348081.9375 - mean_squared_error: 348081.9375\n",
      "Epoch 2586/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348922.7812 - mean_squared_error: 348922.7812\n",
      "Epoch 2587/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343233.9375 - mean_squared_error: 343233.9375\n",
      "Epoch 2588/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343843.1562 - mean_squared_error: 343843.1875\n",
      "Epoch 2589/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345495.1562 - mean_squared_error: 345495.1562\n",
      "Epoch 2590/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341776.7500 - mean_squared_error: 341776.7500\n",
      "Epoch 2591/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342393.8125 - mean_squared_error: 342393.8125\n",
      "Epoch 2592/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334639.0312 - mean_squared_error: 334639.0312\n",
      "Epoch 2593/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348491.8750 - mean_squared_error: 348491.8750\n",
      "Epoch 2594/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 337943.0625 - mean_squared_error: 337943.0625\n",
      "Epoch 2595/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346586.5312 - mean_squared_error: 346586.5312\n",
      "Epoch 2596/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352262.4375 - mean_squared_error: 352262.4375\n",
      "Epoch 2597/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335668.3438 - mean_squared_error: 335668.3438\n",
      "Epoch 2598/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349343.3438 - mean_squared_error: 349343.3750\n",
      "Epoch 2599/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353412.6562 - mean_squared_error: 353412.6562\n",
      "Epoch 2600/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344306.5625 - mean_squared_error: 344306.5625\n",
      "Epoch 2601/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348816.4375 - mean_squared_error: 348816.4375\n",
      "Epoch 2602/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337748.2812 - mean_squared_error: 337748.2812\n",
      "Epoch 2603/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341597.4062 - mean_squared_error: 341597.4062\n",
      "Epoch 2604/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345252.6875 - mean_squared_error: 345252.7188\n",
      "Epoch 2605/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337553.4375 - mean_squared_error: 337553.4375\n",
      "Epoch 2606/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336549.0312 - mean_squared_error: 336549.0312\n",
      "Epoch 2607/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347679.4688 - mean_squared_error: 347679.4688\n",
      "Epoch 2608/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341227.0625 - mean_squared_error: 341227.0625\n",
      "Epoch 2609/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342541.9375 - mean_squared_error: 342541.9375\n",
      "Epoch 2610/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342124.9375 - mean_squared_error: 342124.9375\n",
      "Epoch 2611/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341624.7500 - mean_squared_error: 341624.7500\n",
      "Epoch 2612/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340391.4688 - mean_squared_error: 340391.4688\n",
      "Epoch 2613/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345445.9375 - mean_squared_error: 345445.9375\n",
      "Epoch 2614/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349820.1875 - mean_squared_error: 349820.1875\n",
      "Epoch 2615/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344659.1250 - mean_squared_error: 344659.1250\n",
      "Epoch 2616/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340306.9375 - mean_squared_error: 340306.9375\n",
      "Epoch 2617/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350375.0625 - mean_squared_error: 350375.0625\n",
      "Epoch 2618/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351269.8438 - mean_squared_error: 351269.8438\n",
      "Epoch 2619/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341894.4375 - mean_squared_error: 341894.4375\n",
      "Epoch 2620/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351120.6562 - mean_squared_error: 351120.6562\n",
      "Epoch 2621/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343024.8125 - mean_squared_error: 343024.8125\n",
      "Epoch 2622/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333504.5938 - mean_squared_error: 333504.5938\n",
      "Epoch 2623/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349907.1875 - mean_squared_error: 349907.1875\n",
      "Epoch 2624/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351114.9688 - mean_squared_error: 351114.9688\n",
      "Epoch 2625/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340703.5000 - mean_squared_error: 340703.5000\n",
      "Epoch 2626/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343867.2812 - mean_squared_error: 343867.2812\n",
      "Epoch 2627/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346130.9062 - mean_squared_error: 346130.9062\n",
      "Epoch 2628/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339356.5312 - mean_squared_error: 339356.5625\n",
      "Epoch 2629/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346517.4062 - mean_squared_error: 346517.4062\n",
      "Epoch 2630/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346767.7188 - mean_squared_error: 346767.7188\n",
      "Epoch 2631/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344713.3750 - mean_squared_error: 344713.3750\n",
      "Epoch 2632/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352137.5938 - mean_squared_error: 352137.5938\n",
      "Epoch 2633/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342720.0000 - mean_squared_error: 342720.0000\n",
      "Epoch 2634/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340452.0625 - mean_squared_error: 340452.0625\n",
      "Epoch 2635/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343456.4062 - mean_squared_error: 343456.4062\n",
      "Epoch 2636/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 342756.1875 - mean_squared_error: 342756.1875\n",
      "Epoch 2637/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350075.8750 - mean_squared_error: 350075.8750\n",
      "Epoch 2638/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344442.6250 - mean_squared_error: 344442.6250\n",
      "Epoch 2639/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341867.0000 - mean_squared_error: 341867.0000\n",
      "Epoch 2640/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335546.9062 - mean_squared_error: 335546.9062\n",
      "Epoch 2641/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 352574.7188 - mean_squared_error: 352574.7188\n",
      "Epoch 2642/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343503.8750 - mean_squared_error: 343503.8750\n",
      "Epoch 2643/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351475.5000 - mean_squared_error: 351475.5000\n",
      "Epoch 2644/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345172.0000 - mean_squared_error: 345172.0000\n",
      "Epoch 2645/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349695.5625 - mean_squared_error: 349695.5938\n",
      "Epoch 2646/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345670.4375 - mean_squared_error: 345670.4375\n",
      "Epoch 2647/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341201.3125 - mean_squared_error: 341201.3125\n",
      "Epoch 2648/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345713.8750 - mean_squared_error: 345713.8750\n",
      "Epoch 2649/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 344488.5000 - mean_squared_error: 344488.5000\n",
      "Epoch 2650/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 340163.5938 - mean_squared_error: 340163.5938\n",
      "Epoch 2651/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 350377.5938 - mean_squared_error: 350377.5938\n",
      "Epoch 2652/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 344327.1250 - mean_squared_error: 344327.1250\n",
      "Epoch 2653/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339942.5312 - mean_squared_error: 339942.5312\n",
      "Epoch 2654/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339656.6562 - mean_squared_error: 339656.6562\n",
      "Epoch 2655/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343786.0000 - mean_squared_error: 343786.0000\n",
      "Epoch 2656/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346349.9375 - mean_squared_error: 346349.9375\n",
      "Epoch 2657/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343038.8750 - mean_squared_error: 343038.8750\n",
      "Epoch 2658/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347692.0938 - mean_squared_error: 347692.0938\n",
      "Epoch 2659/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348109.9062 - mean_squared_error: 348109.9375\n",
      "Epoch 2660/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347887.6562 - mean_squared_error: 347887.6562\n",
      "Epoch 2661/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345316.1250 - mean_squared_error: 345316.1250\n",
      "Epoch 2662/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342641.4375 - mean_squared_error: 342641.4375\n",
      "Epoch 2663/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342998.4062 - mean_squared_error: 342998.4062\n",
      "Epoch 2664/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342267.2500 - mean_squared_error: 342267.2500\n",
      "Epoch 2665/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340151.5000 - mean_squared_error: 340151.5000\n",
      "Epoch 2666/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346522.2812 - mean_squared_error: 346522.2812\n",
      "Epoch 2667/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346726.2500 - mean_squared_error: 346726.2500\n",
      "Epoch 2668/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344325.0625 - mean_squared_error: 344325.0625\n",
      "Epoch 2669/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340097.0312 - mean_squared_error: 340097.0000\n",
      "Epoch 2670/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343620.9688 - mean_squared_error: 343620.9688\n",
      "Epoch 2671/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347268.2188 - mean_squared_error: 347268.2188\n",
      "Epoch 2672/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336360.4062 - mean_squared_error: 336360.4062\n",
      "Epoch 2673/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354524.9062 - mean_squared_error: 354524.9062\n",
      "Epoch 2674/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342321.0938 - mean_squared_error: 342321.0938\n",
      "Epoch 2675/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346518.6250 - mean_squared_error: 346518.6250\n",
      "Epoch 2676/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344612.2500 - mean_squared_error: 344612.2500\n",
      "Epoch 2677/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345979.8750 - mean_squared_error: 345979.8750\n",
      "Epoch 2678/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346144.7188 - mean_squared_error: 346144.7188\n",
      "Epoch 2679/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342652.9688 - mean_squared_error: 342652.9688\n",
      "Epoch 2680/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350074.0312 - mean_squared_error: 350074.0312\n",
      "Epoch 2681/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 349545.3438 - mean_squared_error: 349545.3438\n",
      "Epoch 2682/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349265.5938 - mean_squared_error: 349265.5938\n",
      "Epoch 2683/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344530.1562 - mean_squared_error: 344530.1562\n",
      "Epoch 2684/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 357436.1562 - mean_squared_error: 357436.1562\n",
      "Epoch 2685/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 348905.1562 - mean_squared_error: 348905.1562\n",
      "Epoch 2686/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345965.7188 - mean_squared_error: 345965.7188\n",
      "Epoch 2687/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346060.8125 - mean_squared_error: 346060.8125\n",
      "Epoch 2688/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341378.1875 - mean_squared_error: 341378.1875\n",
      "Epoch 2689/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348239.2188 - mean_squared_error: 348239.2188\n",
      "Epoch 2690/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344189.5625 - mean_squared_error: 344189.5625\n",
      "Epoch 2691/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343265.3438 - mean_squared_error: 343265.3438\n",
      "Epoch 2692/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337445.0938 - mean_squared_error: 337445.0938\n",
      "Epoch 2693/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340966.9062 - mean_squared_error: 340966.9062\n",
      "Epoch 2694/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351358.6250 - mean_squared_error: 351358.6250\n",
      "Epoch 2695/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342183.7500 - mean_squared_error: 342183.7500\n",
      "Epoch 2696/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341501.4688 - mean_squared_error: 341501.4688\n",
      "Epoch 2697/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341987.0312 - mean_squared_error: 341987.0312\n",
      "Epoch 2698/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341604.9375 - mean_squared_error: 341604.9375\n",
      "Epoch 2699/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341202.9062 - mean_squared_error: 341202.9062\n",
      "Epoch 2700/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336411.7188 - mean_squared_error: 336411.7188\n",
      "Epoch 2701/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344878.8125 - mean_squared_error: 344878.8125\n",
      "Epoch 2702/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340948.9062 - mean_squared_error: 340948.9062\n",
      "Epoch 2703/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341567.9062 - mean_squared_error: 341567.9062\n",
      "Epoch 2704/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340314.3750 - mean_squared_error: 340314.3750\n",
      "Epoch 2705/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341438.5000 - mean_squared_error: 341438.5000\n",
      "Epoch 2706/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344767.8438 - mean_squared_error: 344767.8438\n",
      "Epoch 2707/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339208.7188 - mean_squared_error: 339208.7188\n",
      "Epoch 2708/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341694.8438 - mean_squared_error: 341694.8438\n",
      "Epoch 2709/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342186.8438 - mean_squared_error: 342186.8438\n",
      "Epoch 2710/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341816.7500 - mean_squared_error: 341816.7500\n",
      "Epoch 2711/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345050.3125 - mean_squared_error: 345050.3125\n",
      "Epoch 2712/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341450.0000 - mean_squared_error: 341450.0312\n",
      "Epoch 2713/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349987.0000 - mean_squared_error: 349987.0000\n",
      "Epoch 2714/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343596.3438 - mean_squared_error: 343596.3438\n",
      "Epoch 2715/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346302.9062 - mean_squared_error: 346302.9062\n",
      "Epoch 2716/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339372.9062 - mean_squared_error: 339372.9062\n",
      "Epoch 2717/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 343310.4062 - mean_squared_error: 343310.4062\n",
      "Epoch 2718/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344354.9688 - mean_squared_error: 344354.9688\n",
      "Epoch 2719/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344352.6250 - mean_squared_error: 344352.6250\n",
      "Epoch 2720/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345819.2188 - mean_squared_error: 345819.2188\n",
      "Epoch 2721/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338763.5000 - mean_squared_error: 338763.5000\n",
      "Epoch 2722/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348647.6562 - mean_squared_error: 348647.6562\n",
      "Epoch 2723/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339985.6250 - mean_squared_error: 339985.6250\n",
      "Epoch 2724/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341155.0625 - mean_squared_error: 341155.0625\n",
      "Epoch 2725/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343883.6250 - mean_squared_error: 343883.6250\n",
      "Epoch 2726/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347408.6562 - mean_squared_error: 347408.6562\n",
      "Epoch 2727/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349177.0312 - mean_squared_error: 349177.0312\n",
      "Epoch 2728/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339984.7812 - mean_squared_error: 339984.7812\n",
      "Epoch 2729/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341527.2500 - mean_squared_error: 341527.2500\n",
      "Epoch 2730/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347863.5312 - mean_squared_error: 347863.5312\n",
      "Epoch 2731/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342117.0312 - mean_squared_error: 342117.0312\n",
      "Epoch 2732/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352725.9688 - mean_squared_error: 352725.9688\n",
      "Epoch 2733/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 355797.4062 - mean_squared_error: 355797.4062\n",
      "Epoch 2734/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343938.4375 - mean_squared_error: 343938.4375\n",
      "Epoch 2735/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347206.7188 - mean_squared_error: 347206.7188\n",
      "Epoch 2736/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347621.7500 - mean_squared_error: 347621.7500\n",
      "Epoch 2737/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346429.8125 - mean_squared_error: 346429.8125\n",
      "Epoch 2738/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 343515.2188 - mean_squared_error: 343515.2188\n",
      "Epoch 2739/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343981.6562 - mean_squared_error: 343981.6562\n",
      "Epoch 2740/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341563.5312 - mean_squared_error: 341563.5312\n",
      "Epoch 2741/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348748.6875 - mean_squared_error: 348748.6875\n",
      "Epoch 2742/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346412.2500 - mean_squared_error: 346412.2500\n",
      "Epoch 2743/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340990.7500 - mean_squared_error: 340990.7500\n",
      "Epoch 2744/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342786.1875 - mean_squared_error: 342786.1875\n",
      "Epoch 2745/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341954.7500 - mean_squared_error: 341954.7500\n",
      "Epoch 2746/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344880.7500 - mean_squared_error: 344880.8125\n",
      "Epoch 2747/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344911.9688 - mean_squared_error: 344911.9688\n",
      "Epoch 2748/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336987.4062 - mean_squared_error: 336987.4062\n",
      "Epoch 2749/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339949.3750 - mean_squared_error: 339949.3750\n",
      "Epoch 2750/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337871.2812 - mean_squared_error: 337871.2812\n",
      "Epoch 2751/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340208.3438 - mean_squared_error: 340208.2812\n",
      "Epoch 2752/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342603.1875 - mean_squared_error: 342603.1875\n",
      "Epoch 2753/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346287.2812 - mean_squared_error: 346287.2812\n",
      "Epoch 2754/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346917.7812 - mean_squared_error: 346917.7812\n",
      "Epoch 2755/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346346.7188 - mean_squared_error: 346346.7188\n",
      "Epoch 2756/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346080.8125 - mean_squared_error: 346080.8125\n",
      "Epoch 2757/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 348446.7500 - mean_squared_error: 348446.7500\n",
      "Epoch 2758/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338500.7812 - mean_squared_error: 338500.7812\n",
      "Epoch 2759/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345386.5625 - mean_squared_error: 345386.5625\n",
      "Epoch 2760/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342336.3750 - mean_squared_error: 342336.3750\n",
      "Epoch 2761/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345251.2188 - mean_squared_error: 345251.2188\n",
      "Epoch 2762/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343834.9062 - mean_squared_error: 343834.9062\n",
      "Epoch 2763/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349312.3125 - mean_squared_error: 349312.3125\n",
      "Epoch 2764/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339118.2812 - mean_squared_error: 339118.2812\n",
      "Epoch 2765/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340970.2500 - mean_squared_error: 340970.2500\n",
      "Epoch 2766/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339127.0938 - mean_squared_error: 339127.0938\n",
      "Epoch 2767/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337196.4688 - mean_squared_error: 337196.4688\n",
      "Epoch 2768/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 345759.7812 - mean_squared_error: 345759.7812\n",
      "Epoch 2769/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339208.0312 - mean_squared_error: 339208.0312\n",
      "Epoch 2770/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345824.0000 - mean_squared_error: 345824.0000\n",
      "Epoch 2771/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345630.8438 - mean_squared_error: 345630.8438\n",
      "Epoch 2772/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336201.0938 - mean_squared_error: 336201.0938\n",
      "Epoch 2773/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333760.9688 - mean_squared_error: 333760.9688\n",
      "Epoch 2774/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345959.1562 - mean_squared_error: 345959.1562\n",
      "Epoch 2775/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351210.0312 - mean_squared_error: 351210.0312\n",
      "Epoch 2776/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341282.5312 - mean_squared_error: 341282.5312\n",
      "Epoch 2777/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339000.8125 - mean_squared_error: 339000.8125\n",
      "Epoch 2778/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341118.5938 - mean_squared_error: 341118.5938\n",
      "Epoch 2779/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342959.0312 - mean_squared_error: 342959.0312\n",
      "Epoch 2780/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335718.2188 - mean_squared_error: 335718.2188\n",
      "Epoch 2781/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348306.5938 - mean_squared_error: 348306.5938\n",
      "Epoch 2782/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342266.5625 - mean_squared_error: 342266.5938\n",
      "Epoch 2783/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348353.5625 - mean_squared_error: 348353.5625\n",
      "Epoch 2784/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337501.0938 - mean_squared_error: 337501.0938\n",
      "Epoch 2785/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341603.2500 - mean_squared_error: 341603.2500\n",
      "Epoch 2786/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337675.0938 - mean_squared_error: 337675.0938\n",
      "Epoch 2787/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347418.4688 - mean_squared_error: 347418.4688\n",
      "Epoch 2788/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345492.1562 - mean_squared_error: 345492.1562\n",
      "Epoch 2789/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340595.9375 - mean_squared_error: 340595.9375\n",
      "Epoch 2790/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342797.7500 - mean_squared_error: 342797.7500\n",
      "Epoch 2791/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345303.5000 - mean_squared_error: 345303.5000\n",
      "Epoch 2792/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347504.2188 - mean_squared_error: 347504.2188\n",
      "Epoch 2793/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341818.9688 - mean_squared_error: 341818.9688\n",
      "Epoch 2794/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344709.4375 - mean_squared_error: 344709.4375\n",
      "Epoch 2795/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336650.7812 - mean_squared_error: 336650.7812\n",
      "Epoch 2796/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340263.9062 - mean_squared_error: 340263.9062\n",
      "Epoch 2797/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346502.3125 - mean_squared_error: 346502.3125\n",
      "Epoch 2798/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346284.4688 - mean_squared_error: 346284.4688\n",
      "Epoch 2799/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341895.3125 - mean_squared_error: 341895.3125\n",
      "Epoch 2800/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345886.5000 - mean_squared_error: 345886.5000\n",
      "Epoch 2801/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336060.8125 - mean_squared_error: 336060.8125\n",
      "Epoch 2802/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340861.5312 - mean_squared_error: 340861.5312\n",
      "Epoch 2803/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345431.2500 - mean_squared_error: 345431.2500\n",
      "Epoch 2804/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346452.4062 - mean_squared_error: 346452.4062\n",
      "Epoch 2805/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343314.8438 - mean_squared_error: 343314.8438\n",
      "Epoch 2806/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 343464.0938 - mean_squared_error: 343464.0938\n",
      "Epoch 2807/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351364.7188 - mean_squared_error: 351364.7188\n",
      "Epoch 2808/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340656.2188 - mean_squared_error: 340656.2188\n",
      "Epoch 2809/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347568.2188 - mean_squared_error: 347568.2188\n",
      "Epoch 2810/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346610.2188 - mean_squared_error: 346610.2188\n",
      "Epoch 2811/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337624.3438 - mean_squared_error: 337624.3438\n",
      "Epoch 2812/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345033.0000 - mean_squared_error: 345033.0000\n",
      "Epoch 2813/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348764.2500 - mean_squared_error: 348764.2500\n",
      "Epoch 2814/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344864.5000 - mean_squared_error: 344864.5000\n",
      "Epoch 2815/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343486.9688 - mean_squared_error: 343486.9688\n",
      "Epoch 2816/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340313.6875 - mean_squared_error: 340313.6250\n",
      "Epoch 2817/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338943.2500 - mean_squared_error: 338943.2500\n",
      "Epoch 2818/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345216.4688 - mean_squared_error: 345216.4688\n",
      "Epoch 2819/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347012.8750 - mean_squared_error: 347012.8750\n",
      "Epoch 2820/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342942.1562 - mean_squared_error: 342942.1562\n",
      "Epoch 2821/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348247.4062 - mean_squared_error: 348247.4062\n",
      "Epoch 2822/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338514.5312 - mean_squared_error: 338514.5312\n",
      "Epoch 2823/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342624.7188 - mean_squared_error: 342624.7188\n",
      "Epoch 2824/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338010.2812 - mean_squared_error: 338010.2812\n",
      "Epoch 2825/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343235.8125 - mean_squared_error: 343235.8125\n",
      "Epoch 2826/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345311.2812 - mean_squared_error: 345311.2812\n",
      "Epoch 2827/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344250.6250 - mean_squared_error: 344250.6250\n",
      "Epoch 2828/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339243.5625 - mean_squared_error: 339243.5625\n",
      "Epoch 2829/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342247.9688 - mean_squared_error: 342247.9688\n",
      "Epoch 2830/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350258.5938 - mean_squared_error: 350258.5938\n",
      "Epoch 2831/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345006.8750 - mean_squared_error: 345006.8750\n",
      "Epoch 2832/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336894.6875 - mean_squared_error: 336894.6875\n",
      "Epoch 2833/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334981.0625 - mean_squared_error: 334981.0625\n",
      "Epoch 2834/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344234.4688 - mean_squared_error: 344234.4688\n",
      "Epoch 2835/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339257.0000 - mean_squared_error: 339257.0000\n",
      "Epoch 2836/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340039.4688 - mean_squared_error: 340039.4688\n",
      "Epoch 2837/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342726.7188 - mean_squared_error: 342726.7188\n",
      "Epoch 2838/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341875.9375 - mean_squared_error: 341875.9375\n",
      "Epoch 2839/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347175.3750 - mean_squared_error: 347175.3750\n",
      "Epoch 2840/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349686.9062 - mean_squared_error: 349686.9062\n",
      "Epoch 2841/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340526.6250 - mean_squared_error: 340526.6250\n",
      "Epoch 2842/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340078.5625 - mean_squared_error: 340078.5625\n",
      "Epoch 2843/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341141.1875 - mean_squared_error: 341141.1875\n",
      "Epoch 2844/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335797.1250 - mean_squared_error: 335797.1250\n",
      "Epoch 2845/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343824.8750 - mean_squared_error: 343824.8750\n",
      "Epoch 2846/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336534.6562 - mean_squared_error: 336534.6562\n",
      "Epoch 2847/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346167.7812 - mean_squared_error: 346167.7812\n",
      "Epoch 2848/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341477.6250 - mean_squared_error: 341477.6250\n",
      "Epoch 2849/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345091.5625 - mean_squared_error: 345091.5625\n",
      "Epoch 2850/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336200.7500 - mean_squared_error: 336200.7500\n",
      "Epoch 2851/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339513.4062 - mean_squared_error: 339513.4062\n",
      "Epoch 2852/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336461.6562 - mean_squared_error: 336461.6562\n",
      "Epoch 2853/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345327.2188 - mean_squared_error: 345327.2188\n",
      "Epoch 2854/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341207.4688 - mean_squared_error: 341207.4688\n",
      "Epoch 2855/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339495.2500 - mean_squared_error: 339495.2500\n",
      "Epoch 2856/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344266.8438 - mean_squared_error: 344266.8438\n",
      "Epoch 2857/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344658.8438 - mean_squared_error: 344658.8438\n",
      "Epoch 2858/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346827.6875 - mean_squared_error: 346827.6875\n",
      "Epoch 2859/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338401.6562 - mean_squared_error: 338401.6562\n",
      "Epoch 2860/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343661.2500 - mean_squared_error: 343661.2500\n",
      "Epoch 2861/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340226.7188 - mean_squared_error: 340226.7188\n",
      "Epoch 2862/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338409.1250 - mean_squared_error: 338409.1250\n",
      "Epoch 2863/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346329.4062 - mean_squared_error: 346329.4062\n",
      "Epoch 2864/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339178.8438 - mean_squared_error: 339178.8438\n",
      "Epoch 2865/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345155.9062 - mean_squared_error: 345155.9062\n",
      "Epoch 2866/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346126.2812 - mean_squared_error: 346126.2812\n",
      "Epoch 2867/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339182.9688 - mean_squared_error: 339182.9688\n",
      "Epoch 2868/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352101.3750 - mean_squared_error: 352101.3750\n",
      "Epoch 2869/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341860.9688 - mean_squared_error: 341860.9688\n",
      "Epoch 2870/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338091.1875 - mean_squared_error: 338091.1875\n",
      "Epoch 2871/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346549.0625 - mean_squared_error: 346549.0625\n",
      "Epoch 2872/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340623.2500 - mean_squared_error: 340623.2500\n",
      "Epoch 2873/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335712.9688 - mean_squared_error: 335712.9688\n",
      "Epoch 2874/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344468.8438 - mean_squared_error: 344468.8438\n",
      "Epoch 2875/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355219.6250 - mean_squared_error: 355219.6250\n",
      "Epoch 2876/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334603.2500 - mean_squared_error: 334603.2500\n",
      "Epoch 2877/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347288.9375 - mean_squared_error: 347288.9375\n",
      "Epoch 2878/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339678.9688 - mean_squared_error: 339678.9688\n",
      "Epoch 2879/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343939.7500 - mean_squared_error: 343939.7500\n",
      "Epoch 2880/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345402.9688 - mean_squared_error: 345403.0000\n",
      "Epoch 2881/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344804.4375 - mean_squared_error: 344804.4375\n",
      "Epoch 2882/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345928.9688 - mean_squared_error: 345928.9375\n",
      "Epoch 2883/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343376.9375 - mean_squared_error: 343376.9375\n",
      "Epoch 2884/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335480.9375 - mean_squared_error: 335480.9375\n",
      "Epoch 2885/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348170.9375 - mean_squared_error: 348170.9375\n",
      "Epoch 2886/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341768.0938 - mean_squared_error: 341768.0938\n",
      "Epoch 2887/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334703.4688 - mean_squared_error: 334703.4688\n",
      "Epoch 2888/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340366.5625 - mean_squared_error: 340366.5312\n",
      "Epoch 2889/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353005.0938 - mean_squared_error: 353005.0938\n",
      "Epoch 2890/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334172.3125 - mean_squared_error: 334172.3125\n",
      "Epoch 2891/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340883.0000 - mean_squared_error: 340883.0000\n",
      "Epoch 2892/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341198.2500 - mean_squared_error: 341198.2500\n",
      "Epoch 2893/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339090.5312 - mean_squared_error: 339090.5000\n",
      "Epoch 2894/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341138.2812 - mean_squared_error: 341138.2812\n",
      "Epoch 2895/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346573.8438 - mean_squared_error: 346573.8438\n",
      "Epoch 2896/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344895.0312 - mean_squared_error: 344895.0312\n",
      "Epoch 2897/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343574.6250 - mean_squared_error: 343574.6250\n",
      "Epoch 2898/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339618.8750 - mean_squared_error: 339618.8750\n",
      "Epoch 2899/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340560.8125 - mean_squared_error: 340560.8125\n",
      "Epoch 2900/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 338057.7812 - mean_squared_error: 338057.7812\n",
      "Epoch 2901/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338966.6875 - mean_squared_error: 338966.6875\n",
      "Epoch 2902/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340594.8125 - mean_squared_error: 340594.8125\n",
      "Epoch 2903/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333944.4062 - mean_squared_error: 333944.4062\n",
      "Epoch 2904/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342260.8750 - mean_squared_error: 342260.9062\n",
      "Epoch 2905/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341881.3125 - mean_squared_error: 341881.3125\n",
      "Epoch 2906/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343431.2812 - mean_squared_error: 343431.2812\n",
      "Epoch 2907/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345799.8750 - mean_squared_error: 345799.8750\n",
      "Epoch 2908/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342665.2500 - mean_squared_error: 342665.2500\n",
      "Epoch 2909/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339865.8750 - mean_squared_error: 339865.8750\n",
      "Epoch 2910/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337417.3750 - mean_squared_error: 337417.4062\n",
      "Epoch 2911/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343352.9375 - mean_squared_error: 343352.9375\n",
      "Epoch 2912/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347190.8125 - mean_squared_error: 347190.8125\n",
      "Epoch 2913/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342513.3750 - mean_squared_error: 342513.3750\n",
      "Epoch 2914/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348419.3438 - mean_squared_error: 348419.3438\n",
      "Epoch 2915/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334671.1562 - mean_squared_error: 334671.1562\n",
      "Epoch 2916/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339488.1875 - mean_squared_error: 339488.1875\n",
      "Epoch 2917/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333341.8438 - mean_squared_error: 333341.8438\n",
      "Epoch 2918/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 346373.5000 - mean_squared_error: 346373.5000\n",
      "Epoch 2919/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344010.1875 - mean_squared_error: 344010.1875\n",
      "Epoch 2920/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335722.2500 - mean_squared_error: 335722.2500\n",
      "Epoch 2921/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335679.0000 - mean_squared_error: 335679.0000\n",
      "Epoch 2922/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342531.7812 - mean_squared_error: 342531.7812\n",
      "Epoch 2923/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338987.9688 - mean_squared_error: 338987.9688\n",
      "Epoch 2924/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343132.0312 - mean_squared_error: 343132.0312\n",
      "Epoch 2925/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342085.4062 - mean_squared_error: 342085.4062\n",
      "Epoch 2926/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339356.8438 - mean_squared_error: 339356.8438\n",
      "Epoch 2927/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344291.3750 - mean_squared_error: 344291.3750\n",
      "Epoch 2928/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342626.5000 - mean_squared_error: 342626.4375\n",
      "Epoch 2929/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347504.6562 - mean_squared_error: 347504.6562\n",
      "Epoch 2930/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340305.9375 - mean_squared_error: 340305.9375\n",
      "Epoch 2931/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342858.1250 - mean_squared_error: 342858.1250\n",
      "Epoch 2932/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339461.8125 - mean_squared_error: 339461.8125\n",
      "Epoch 2933/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344059.7812 - mean_squared_error: 344059.7812\n",
      "Epoch 2934/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345076.8750 - mean_squared_error: 345076.8750\n",
      "Epoch 2935/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339728.5312 - mean_squared_error: 339728.5312\n",
      "Epoch 2936/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353462.3750 - mean_squared_error: 353462.3750\n",
      "Epoch 2937/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344263.9375 - mean_squared_error: 344263.9375\n",
      "Epoch 2938/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346316.2500 - mean_squared_error: 346316.2500\n",
      "Epoch 2939/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343120.0312 - mean_squared_error: 343120.0312\n",
      "Epoch 2940/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347832.0312 - mean_squared_error: 347832.0312\n",
      "Epoch 2941/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348750.3125 - mean_squared_error: 348750.3125\n",
      "Epoch 2942/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342213.0938 - mean_squared_error: 342213.0938\n",
      "Epoch 2943/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337217.9688 - mean_squared_error: 337217.9688\n",
      "Epoch 2944/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344278.4688 - mean_squared_error: 344278.4688\n",
      "Epoch 2945/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342611.5625 - mean_squared_error: 342611.5625\n",
      "Epoch 2946/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340675.0000 - mean_squared_error: 340675.0000\n",
      "Epoch 2947/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341538.0938 - mean_squared_error: 341538.0938\n",
      "Epoch 2948/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345660.9062 - mean_squared_error: 345660.9062\n",
      "Epoch 2949/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343622.0000 - mean_squared_error: 343622.0000\n",
      "Epoch 2950/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346147.2188 - mean_squared_error: 346147.2188\n",
      "Epoch 2951/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345587.0000 - mean_squared_error: 345587.0000\n",
      "Epoch 2952/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344648.7500 - mean_squared_error: 344648.7500\n",
      "Epoch 2953/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334102.7812 - mean_squared_error: 334102.7812\n",
      "Epoch 2954/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344850.4062 - mean_squared_error: 344850.4062\n",
      "Epoch 2955/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347170.1562 - mean_squared_error: 347170.1562\n",
      "Epoch 2956/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347355.2812 - mean_squared_error: 347355.2812\n",
      "Epoch 2957/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342831.3438 - mean_squared_error: 342831.3438\n",
      "Epoch 2958/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339421.8125 - mean_squared_error: 339421.8125\n",
      "Epoch 2959/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338464.0625 - mean_squared_error: 338464.0625\n",
      "Epoch 2960/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334205.8125 - mean_squared_error: 334205.8125\n",
      "Epoch 2961/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340902.5312 - mean_squared_error: 340902.5312\n",
      "Epoch 2962/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345168.8750 - mean_squared_error: 345168.8750\n",
      "Epoch 2963/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347891.3750 - mean_squared_error: 347891.3750\n",
      "Epoch 2964/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334358.4062 - mean_squared_error: 334358.4062\n",
      "Epoch 2965/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346532.9062 - mean_squared_error: 346532.9062\n",
      "Epoch 2966/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341356.3750 - mean_squared_error: 341356.3750\n",
      "Epoch 2967/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345965.2812 - mean_squared_error: 345965.2812\n",
      "Epoch 2968/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340161.5000 - mean_squared_error: 340161.5000\n",
      "Epoch 2969/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335759.7812 - mean_squared_error: 335759.7812\n",
      "Epoch 2970/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338236.3438 - mean_squared_error: 338236.3438\n",
      "Epoch 2971/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341526.6875 - mean_squared_error: 341526.6875\n",
      "Epoch 2972/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346548.1562 - mean_squared_error: 346548.1562\n",
      "Epoch 2973/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345288.0312 - mean_squared_error: 345288.0312\n",
      "Epoch 2974/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341928.3125 - mean_squared_error: 341928.3125\n",
      "Epoch 2975/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337785.0938 - mean_squared_error: 337785.0938\n",
      "Epoch 2976/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344988.5000 - mean_squared_error: 344988.5000\n",
      "Epoch 2977/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 330266.3438 - mean_squared_error: 330266.3438\n",
      "Epoch 2978/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342477.6250 - mean_squared_error: 342477.6250\n",
      "Epoch 2979/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343991.6875 - mean_squared_error: 343991.6875\n",
      "Epoch 2980/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342674.6250 - mean_squared_error: 342674.6250\n",
      "Epoch 2981/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344914.2812 - mean_squared_error: 344914.2812\n",
      "Epoch 2982/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335792.1875 - mean_squared_error: 335792.1875\n",
      "Epoch 2983/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346075.7188 - mean_squared_error: 346075.7188\n",
      "Epoch 2984/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344249.4688 - mean_squared_error: 344249.4688\n",
      "Epoch 2985/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345197.6562 - mean_squared_error: 345197.6562\n",
      "Epoch 2986/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336446.4375 - mean_squared_error: 336446.4375\n",
      "Epoch 2987/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339680.5000 - mean_squared_error: 339680.5000\n",
      "Epoch 2988/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332336.7812 - mean_squared_error: 332336.7812\n",
      "Epoch 2989/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346931.0312 - mean_squared_error: 346931.0312\n",
      "Epoch 2990/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334076.1875 - mean_squared_error: 334076.1875\n",
      "Epoch 2991/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336921.4688 - mean_squared_error: 336921.4688\n",
      "Epoch 2992/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345477.5938 - mean_squared_error: 345477.5938\n",
      "Epoch 2993/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340455.0938 - mean_squared_error: 340455.0938\n",
      "Epoch 2994/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346931.1250 - mean_squared_error: 346931.1250\n",
      "Epoch 2995/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340608.3750 - mean_squared_error: 340608.3750\n",
      "Epoch 2996/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343553.5625 - mean_squared_error: 343553.5625\n",
      "Epoch 2997/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343455.7500 - mean_squared_error: 343455.7500\n",
      "Epoch 2998/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351042.9375 - mean_squared_error: 351042.9375\n",
      "Epoch 2999/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344326.3750 - mean_squared_error: 344326.3750\n",
      "Epoch 3000/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342584.1562 - mean_squared_error: 342584.1562\n",
      "Epoch 3001/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337697.5938 - mean_squared_error: 337697.5938\n",
      "Epoch 3002/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346244.0938 - mean_squared_error: 346244.0938\n",
      "Epoch 3003/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333339.4062 - mean_squared_error: 333339.4062\n",
      "Epoch 3004/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343294.3438 - mean_squared_error: 343294.3438\n",
      "Epoch 3005/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337443.0312 - mean_squared_error: 337443.0312\n",
      "Epoch 3006/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345940.4062 - mean_squared_error: 345940.4062\n",
      "Epoch 3007/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335528.2812 - mean_squared_error: 335528.2812\n",
      "Epoch 3008/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 336397.5938 - mean_squared_error: 336397.5938\n",
      "Epoch 3009/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337365.1562 - mean_squared_error: 337365.1562\n",
      "Epoch 3010/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347614.6250 - mean_squared_error: 347614.6250\n",
      "Epoch 3011/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342396.8125 - mean_squared_error: 342396.8125\n",
      "Epoch 3012/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346479.7812 - mean_squared_error: 346479.7812\n",
      "Epoch 3013/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343869.8438 - mean_squared_error: 343869.8438\n",
      "Epoch 3014/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345864.8438 - mean_squared_error: 345864.8438\n",
      "Epoch 3015/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339167.3125 - mean_squared_error: 339167.3125\n",
      "Epoch 3016/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341327.0625 - mean_squared_error: 341327.0625\n",
      "Epoch 3017/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343723.3750 - mean_squared_error: 343723.3750\n",
      "Epoch 3018/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342899.2188 - mean_squared_error: 342899.2188\n",
      "Epoch 3019/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342253.0000 - mean_squared_error: 342253.0000\n",
      "Epoch 3020/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343612.3750 - mean_squared_error: 343612.3750\n",
      "Epoch 3021/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344110.1250 - mean_squared_error: 344110.1250\n",
      "Epoch 3022/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345148.0312 - mean_squared_error: 345148.0312\n",
      "Epoch 3023/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344816.3438 - mean_squared_error: 344816.3438\n",
      "Epoch 3024/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341166.7500 - mean_squared_error: 341166.7500\n",
      "Epoch 3025/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343996.1250 - mean_squared_error: 343996.1250\n",
      "Epoch 3026/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342092.1250 - mean_squared_error: 342092.1250\n",
      "Epoch 3027/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341667.8750 - mean_squared_error: 341667.8750\n",
      "Epoch 3028/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347987.0625 - mean_squared_error: 347987.0625\n",
      "Epoch 3029/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341630.5312 - mean_squared_error: 341630.5312\n",
      "Epoch 3030/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344218.2188 - mean_squared_error: 344218.2188\n",
      "Epoch 3031/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341152.2812 - mean_squared_error: 341152.2812\n",
      "Epoch 3032/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 340605.7500 - mean_squared_error: 340605.7500\n",
      "Epoch 3033/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347664.6875 - mean_squared_error: 347664.6875\n",
      "Epoch 3034/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340307.3750 - mean_squared_error: 340307.3750\n",
      "Epoch 3035/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339876.8750 - mean_squared_error: 339876.8750\n",
      "Epoch 3036/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347129.9688 - mean_squared_error: 347129.9688\n",
      "Epoch 3037/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343547.7812 - mean_squared_error: 343547.7812\n",
      "Epoch 3038/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338226.4688 - mean_squared_error: 338226.4688\n",
      "Epoch 3039/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332768.2500 - mean_squared_error: 332768.2500\n",
      "Epoch 3040/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338511.2812 - mean_squared_error: 338511.2812\n",
      "Epoch 3041/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344493.0000 - mean_squared_error: 344493.0000\n",
      "Epoch 3042/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342915.9062 - mean_squared_error: 342915.9062\n",
      "Epoch 3043/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350195.9688 - mean_squared_error: 350195.9688\n",
      "Epoch 3044/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355021.9375 - mean_squared_error: 355021.9375\n",
      "Epoch 3045/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348792.2188 - mean_squared_error: 348792.2188\n",
      "Epoch 3046/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 336933.5938 - mean_squared_error: 336933.5938\n",
      "Epoch 3047/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338452.2812 - mean_squared_error: 338452.2812\n",
      "Epoch 3048/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340211.4375 - mean_squared_error: 340211.4375\n",
      "Epoch 3049/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346483.1875 - mean_squared_error: 346483.1875\n",
      "Epoch 3050/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345996.1875 - mean_squared_error: 345996.1875\n",
      "Epoch 3051/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349248.6250 - mean_squared_error: 349248.6250\n",
      "Epoch 3052/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340331.2500 - mean_squared_error: 340331.2500\n",
      "Epoch 3053/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351255.5000 - mean_squared_error: 351255.5000\n",
      "Epoch 3054/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345989.6875 - mean_squared_error: 345989.6875\n",
      "Epoch 3055/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341930.5938 - mean_squared_error: 341930.5938\n",
      "Epoch 3056/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346505.1250 - mean_squared_error: 346505.1250\n",
      "Epoch 3057/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342411.0312 - mean_squared_error: 342411.0312\n",
      "Epoch 3058/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345390.3125 - mean_squared_error: 345390.3125\n",
      "Epoch 3059/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336193.9062 - mean_squared_error: 336193.9062\n",
      "Epoch 3060/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338458.1250 - mean_squared_error: 338458.1250\n",
      "Epoch 3061/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348850.6562 - mean_squared_error: 348850.6562\n",
      "Epoch 3062/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345935.5938 - mean_squared_error: 345935.5938\n",
      "Epoch 3063/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353259.6875 - mean_squared_error: 353259.6875\n",
      "Epoch 3064/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340283.7500 - mean_squared_error: 340283.7500\n",
      "Epoch 3065/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334946.3750 - mean_squared_error: 334946.3750\n",
      "Epoch 3066/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 339675.5625 - mean_squared_error: 339675.5625\n",
      "Epoch 3067/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336433.9375 - mean_squared_error: 336433.9375\n",
      "Epoch 3068/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346317.7500 - mean_squared_error: 346317.7500\n",
      "Epoch 3069/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342423.3125 - mean_squared_error: 342423.3125\n",
      "Epoch 3070/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344190.8125 - mean_squared_error: 344190.8125\n",
      "Epoch 3071/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349361.9062 - mean_squared_error: 349361.9062\n",
      "Epoch 3072/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342095.4375 - mean_squared_error: 342095.4375\n",
      "Epoch 3073/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342042.5000 - mean_squared_error: 342042.5000\n",
      "Epoch 3074/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337464.6250 - mean_squared_error: 337464.6250\n",
      "Epoch 3075/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340186.2500 - mean_squared_error: 340186.2500\n",
      "Epoch 3076/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337927.1562 - mean_squared_error: 337927.1562\n",
      "Epoch 3077/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341737.2500 - mean_squared_error: 341737.2500\n",
      "Epoch 3078/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341540.9375 - mean_squared_error: 341540.9375\n",
      "Epoch 3079/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341365.6562 - mean_squared_error: 341365.6562\n",
      "Epoch 3080/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341045.6562 - mean_squared_error: 341045.6562\n",
      "Epoch 3081/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342471.0000 - mean_squared_error: 342471.0000\n",
      "Epoch 3082/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340223.5000 - mean_squared_error: 340223.5000\n",
      "Epoch 3083/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341488.0938 - mean_squared_error: 341488.0938\n",
      "Epoch 3084/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340567.3750 - mean_squared_error: 340567.3750\n",
      "Epoch 3085/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 339494.9062 - mean_squared_error: 339494.9062\n",
      "Epoch 3086/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338450.2188 - mean_squared_error: 338450.2188\n",
      "Epoch 3087/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 338130.0312 - mean_squared_error: 338130.0312\n",
      "Epoch 3088/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345509.3438 - mean_squared_error: 345509.3438\n",
      "Epoch 3089/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341289.6562 - mean_squared_error: 341289.6562\n",
      "Epoch 3090/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334589.9375 - mean_squared_error: 334589.9375\n",
      "Epoch 3091/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341422.0000 - mean_squared_error: 341422.0000\n",
      "Epoch 3092/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 338491.4375 - mean_squared_error: 338491.4375\n",
      "Epoch 3093/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345932.5938 - mean_squared_error: 345932.5938\n",
      "Epoch 3094/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345161.1562 - mean_squared_error: 345161.1562\n",
      "Epoch 3095/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337266.0000 - mean_squared_error: 337266.0000\n",
      "Epoch 3096/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340125.2500 - mean_squared_error: 340125.2500\n",
      "Epoch 3097/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338202.0625 - mean_squared_error: 338202.0625\n",
      "Epoch 3098/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340420.6250 - mean_squared_error: 340420.6250\n",
      "Epoch 3099/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346217.2188 - mean_squared_error: 346217.2188\n",
      "Epoch 3100/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344399.1875 - mean_squared_error: 344399.1875\n",
      "Epoch 3101/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342143.1875 - mean_squared_error: 342143.1875\n",
      "Epoch 3102/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339593.7812 - mean_squared_error: 339593.7812\n",
      "Epoch 3103/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333397.7188 - mean_squared_error: 333397.7188\n",
      "Epoch 3104/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342566.7188 - mean_squared_error: 342566.7188\n",
      "Epoch 3105/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349007.2812 - mean_squared_error: 349007.2812\n",
      "Epoch 3106/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342895.3438 - mean_squared_error: 342895.3438\n",
      "Epoch 3107/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345939.2812 - mean_squared_error: 345939.2812\n",
      "Epoch 3108/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340074.4688 - mean_squared_error: 340074.4688\n",
      "Epoch 3109/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343300.5312 - mean_squared_error: 343300.5312\n",
      "Epoch 3110/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338331.0000 - mean_squared_error: 338331.0000\n",
      "Epoch 3111/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341161.3438 - mean_squared_error: 341161.3438\n",
      "Epoch 3112/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341258.1562 - mean_squared_error: 341258.1562\n",
      "Epoch 3113/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352974.0625 - mean_squared_error: 352974.0625\n",
      "Epoch 3114/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344049.2500 - mean_squared_error: 344049.2500\n",
      "Epoch 3115/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339167.4062 - mean_squared_error: 339167.4062\n",
      "Epoch 3116/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340614.4062 - mean_squared_error: 340614.4062\n",
      "Epoch 3117/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337682.0625 - mean_squared_error: 337682.0625\n",
      "Epoch 3118/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344997.1562 - mean_squared_error: 344997.1562\n",
      "Epoch 3119/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337138.7188 - mean_squared_error: 337138.7188\n",
      "Epoch 3120/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334649.6250 - mean_squared_error: 334649.6250\n",
      "Epoch 3121/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337280.4062 - mean_squared_error: 337280.4062\n",
      "Epoch 3122/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347767.5312 - mean_squared_error: 347767.5312\n",
      "Epoch 3123/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337190.4688 - mean_squared_error: 337190.4688\n",
      "Epoch 3124/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340072.7188 - mean_squared_error: 340072.7188\n",
      "Epoch 3125/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336133.5625 - mean_squared_error: 336133.5625\n",
      "Epoch 3126/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341209.7500 - mean_squared_error: 341209.7500\n",
      "Epoch 3127/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 342735.7188 - mean_squared_error: 342735.7188\n",
      "Epoch 3128/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344137.5000 - mean_squared_error: 344137.5000\n",
      "Epoch 3129/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340302.1875 - mean_squared_error: 340302.1875\n",
      "Epoch 3130/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343055.0000 - mean_squared_error: 343055.0000\n",
      "Epoch 3131/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339178.0312 - mean_squared_error: 339178.0312\n",
      "Epoch 3132/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344365.8750 - mean_squared_error: 344365.8750\n",
      "Epoch 3133/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339522.8750 - mean_squared_error: 339522.8750\n",
      "Epoch 3134/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345148.3438 - mean_squared_error: 345148.3438\n",
      "Epoch 3135/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344098.5312 - mean_squared_error: 344098.5312\n",
      "Epoch 3136/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351301.0312 - mean_squared_error: 351301.0312\n",
      "Epoch 3137/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344589.7500 - mean_squared_error: 344589.7500\n",
      "Epoch 3138/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344516.0625 - mean_squared_error: 344516.0625\n",
      "Epoch 3139/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349300.0000 - mean_squared_error: 349300.0000\n",
      "Epoch 3140/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345394.2812 - mean_squared_error: 345394.2812\n",
      "Epoch 3141/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 336524.7500 - mean_squared_error: 336524.7500\n",
      "Epoch 3142/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339172.6250 - mean_squared_error: 339172.6250\n",
      "Epoch 3143/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344472.0000 - mean_squared_error: 344472.0000\n",
      "Epoch 3144/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335621.9062 - mean_squared_error: 335621.9062\n",
      "Epoch 3145/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338214.9375 - mean_squared_error: 338214.9375\n",
      "Epoch 3146/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340349.0625 - mean_squared_error: 340349.0625\n",
      "Epoch 3147/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340838.1250 - mean_squared_error: 340838.1250\n",
      "Epoch 3148/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347267.0938 - mean_squared_error: 347267.0938\n",
      "Epoch 3149/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350106.4062 - mean_squared_error: 350106.4062\n",
      "Epoch 3150/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342117.5625 - mean_squared_error: 342117.5625\n",
      "Epoch 3151/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341523.2188 - mean_squared_error: 341523.2188\n",
      "Epoch 3152/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346634.5938 - mean_squared_error: 346634.5938\n",
      "Epoch 3153/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342983.8438 - mean_squared_error: 342983.8438\n",
      "Epoch 3154/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336170.9062 - mean_squared_error: 336170.9062\n",
      "Epoch 3155/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344240.4375 - mean_squared_error: 344240.4375\n",
      "Epoch 3156/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344608.9062 - mean_squared_error: 344608.9062\n",
      "Epoch 3157/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333797.6875 - mean_squared_error: 333797.6875\n",
      "Epoch 3158/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337032.6562 - mean_squared_error: 337032.6562\n",
      "Epoch 3159/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347272.0625 - mean_squared_error: 347272.0625\n",
      "Epoch 3160/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 335944.6562 - mean_squared_error: 335944.6562\n",
      "Epoch 3161/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343795.9688 - mean_squared_error: 343795.9688\n",
      "Epoch 3162/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342436.6250 - mean_squared_error: 342436.6250\n",
      "Epoch 3163/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335343.7500 - mean_squared_error: 335343.7500\n",
      "Epoch 3164/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 349231.0625 - mean_squared_error: 349231.0625\n",
      "Epoch 3165/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340370.7188 - mean_squared_error: 340370.6875\n",
      "Epoch 3166/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340248.8125 - mean_squared_error: 340248.8125\n",
      "Epoch 3167/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337428.2188 - mean_squared_error: 337428.2188\n",
      "Epoch 3168/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352714.5938 - mean_squared_error: 352714.5938\n",
      "Epoch 3169/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345049.9688 - mean_squared_error: 345049.9688\n",
      "Epoch 3170/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339987.0625 - mean_squared_error: 339987.0625\n",
      "Epoch 3171/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342744.2188 - mean_squared_error: 342744.2188\n",
      "Epoch 3172/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338286.6250 - mean_squared_error: 338286.6250\n",
      "Epoch 3173/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348058.5000 - mean_squared_error: 348058.5312\n",
      "Epoch 3174/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342813.8125 - mean_squared_error: 342813.8125\n",
      "Epoch 3175/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346729.8750 - mean_squared_error: 346729.8750\n",
      "Epoch 3176/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346640.7188 - mean_squared_error: 346640.7188\n",
      "Epoch 3177/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343656.6250 - mean_squared_error: 343656.6250\n",
      "Epoch 3178/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351176.0625 - mean_squared_error: 351176.0625\n",
      "Epoch 3179/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350711.8438 - mean_squared_error: 350711.8438\n",
      "Epoch 3180/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349951.5312 - mean_squared_error: 349951.5312\n",
      "Epoch 3181/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344012.9688 - mean_squared_error: 344012.9688\n",
      "Epoch 3182/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341056.6875 - mean_squared_error: 341056.6875\n",
      "Epoch 3183/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341620.4688 - mean_squared_error: 341620.4688\n",
      "Epoch 3184/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349497.5312 - mean_squared_error: 349497.5312\n",
      "Epoch 3185/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345642.6250 - mean_squared_error: 345642.6250\n",
      "Epoch 3186/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345538.8125 - mean_squared_error: 345538.8125\n",
      "Epoch 3187/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 344380.9688 - mean_squared_error: 344380.9688\n",
      "Epoch 3188/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346068.3750 - mean_squared_error: 346068.3750\n",
      "Epoch 3189/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350289.6875 - mean_squared_error: 350289.6875\n",
      "Epoch 3190/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344625.4375 - mean_squared_error: 344625.4375\n",
      "Epoch 3191/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335058.3750 - mean_squared_error: 335058.3750\n",
      "Epoch 3192/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353986.3750 - mean_squared_error: 353986.3750\n",
      "Epoch 3193/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341020.5000 - mean_squared_error: 341020.5000\n",
      "Epoch 3194/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342314.5000 - mean_squared_error: 342314.5000\n",
      "Epoch 3195/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340572.4375 - mean_squared_error: 340572.4375\n",
      "Epoch 3196/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341995.8750 - mean_squared_error: 341995.8750\n",
      "Epoch 3197/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338346.5938 - mean_squared_error: 338346.5938\n",
      "Epoch 3198/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340583.5312 - mean_squared_error: 340583.5312\n",
      "Epoch 3199/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341435.2188 - mean_squared_error: 341435.2188\n",
      "Epoch 3200/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337952.4062 - mean_squared_error: 337952.4062\n",
      "Epoch 3201/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348704.7188 - mean_squared_error: 348704.7188\n",
      "Epoch 3202/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336110.9062 - mean_squared_error: 336110.9062\n",
      "Epoch 3203/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339502.1875 - mean_squared_error: 339502.1875\n",
      "Epoch 3204/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345542.3750 - mean_squared_error: 345542.3750\n",
      "Epoch 3205/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343410.4688 - mean_squared_error: 343410.4688\n",
      "Epoch 3206/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343674.8438 - mean_squared_error: 343674.8438\n",
      "Epoch 3207/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345174.6250 - mean_squared_error: 345174.6250\n",
      "Epoch 3208/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341821.0938 - mean_squared_error: 341821.0938\n",
      "Epoch 3209/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345228.4688 - mean_squared_error: 345228.4375\n",
      "Epoch 3210/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338767.9375 - mean_squared_error: 338767.9375\n",
      "Epoch 3211/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339740.4062 - mean_squared_error: 339740.4062\n",
      "Epoch 3212/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343905.4062 - mean_squared_error: 343905.3750\n",
      "Epoch 3213/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334394.7188 - mean_squared_error: 334394.7188\n",
      "Epoch 3214/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346826.2812 - mean_squared_error: 346826.2812\n",
      "Epoch 3215/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349376.9688 - mean_squared_error: 349376.9688\n",
      "Epoch 3216/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345950.6250 - mean_squared_error: 345950.6250\n",
      "Epoch 3217/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342794.3438 - mean_squared_error: 342794.3438\n",
      "Epoch 3218/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334454.9062 - mean_squared_error: 334454.9062\n",
      "Epoch 3219/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351126.8438 - mean_squared_error: 351126.8438\n",
      "Epoch 3220/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342057.6562 - mean_squared_error: 342057.6562\n",
      "Epoch 3221/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349396.0000 - mean_squared_error: 349396.0000\n",
      "Epoch 3222/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346398.2812 - mean_squared_error: 346398.2812\n",
      "Epoch 3223/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341210.2812 - mean_squared_error: 341210.2812\n",
      "Epoch 3224/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346395.7188 - mean_squared_error: 346395.7188\n",
      "Epoch 3225/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338955.7500 - mean_squared_error: 338955.7500\n",
      "Epoch 3226/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341945.6875 - mean_squared_error: 341945.6875\n",
      "Epoch 3227/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339848.0000 - mean_squared_error: 339848.0000\n",
      "Epoch 3228/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349165.0625 - mean_squared_error: 349165.0625\n",
      "Epoch 3229/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336342.4375 - mean_squared_error: 336342.4375\n",
      "Epoch 3230/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344469.3125 - mean_squared_error: 344469.3125\n",
      "Epoch 3231/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340676.4688 - mean_squared_error: 340676.4688\n",
      "Epoch 3232/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343601.8125 - mean_squared_error: 343601.8125\n",
      "Epoch 3233/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343029.4688 - mean_squared_error: 343029.4688\n",
      "Epoch 3234/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350201.3750 - mean_squared_error: 350201.3750\n",
      "Epoch 3235/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344304.5625 - mean_squared_error: 344304.5625\n",
      "Epoch 3236/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335509.6562 - mean_squared_error: 335509.6562\n",
      "Epoch 3237/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351346.9062 - mean_squared_error: 351346.9062\n",
      "Epoch 3238/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343250.8438 - mean_squared_error: 343250.8438\n",
      "Epoch 3239/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347931.3438 - mean_squared_error: 347931.3438\n",
      "Epoch 3240/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343543.4062 - mean_squared_error: 343543.4062\n",
      "Epoch 3241/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344033.0000 - mean_squared_error: 344033.0000\n",
      "Epoch 3242/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341861.6562 - mean_squared_error: 341861.6562\n",
      "Epoch 3243/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343651.9688 - mean_squared_error: 343651.9688\n",
      "Epoch 3244/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341059.2500 - mean_squared_error: 341059.2500\n",
      "Epoch 3245/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331573.7188 - mean_squared_error: 331573.7500\n",
      "Epoch 3246/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351039.1875 - mean_squared_error: 351039.1875\n",
      "Epoch 3247/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348051.5938 - mean_squared_error: 348051.5938\n",
      "Epoch 3248/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351836.0938 - mean_squared_error: 351836.0938\n",
      "Epoch 3249/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340377.0938 - mean_squared_error: 340377.0938\n",
      "Epoch 3250/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341996.1875 - mean_squared_error: 341996.1875\n",
      "Epoch 3251/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347255.2812 - mean_squared_error: 347255.2812\n",
      "Epoch 3252/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341416.4062 - mean_squared_error: 341416.4062\n",
      "Epoch 3253/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341585.5625 - mean_squared_error: 341585.5625\n",
      "Epoch 3254/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343473.5000 - mean_squared_error: 343473.5000\n",
      "Epoch 3255/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340189.9688 - mean_squared_error: 340189.9688\n",
      "Epoch 3256/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348351.8750 - mean_squared_error: 348351.8750\n",
      "Epoch 3257/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337664.6250 - mean_squared_error: 337664.6250\n",
      "Epoch 3258/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338496.4375 - mean_squared_error: 338496.4375\n",
      "Epoch 3259/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351358.5312 - mean_squared_error: 351358.5312\n",
      "Epoch 3260/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344648.7500 - mean_squared_error: 344648.7500\n",
      "Epoch 3261/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339392.9688 - mean_squared_error: 339392.9688\n",
      "Epoch 3262/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339871.5312 - mean_squared_error: 339871.5312\n",
      "Epoch 3263/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344439.8750 - mean_squared_error: 344439.8750\n",
      "Epoch 3264/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 332575.0312 - mean_squared_error: 332575.0312\n",
      "Epoch 3265/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339913.5000 - mean_squared_error: 339913.5000\n",
      "Epoch 3266/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340928.5938 - mean_squared_error: 340928.5938\n",
      "Epoch 3267/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338838.7188 - mean_squared_error: 338838.7188\n",
      "Epoch 3268/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339362.5000 - mean_squared_error: 339362.5000\n",
      "Epoch 3269/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341679.7500 - mean_squared_error: 341679.7812\n",
      "Epoch 3270/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346437.5625 - mean_squared_error: 346437.5625\n",
      "Epoch 3271/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340681.0312 - mean_squared_error: 340681.0312\n",
      "Epoch 3272/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333206.9375 - mean_squared_error: 333206.9375\n",
      "Epoch 3273/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342589.5938 - mean_squared_error: 342589.5938\n",
      "Epoch 3274/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340720.7812 - mean_squared_error: 340720.7812\n",
      "Epoch 3275/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343026.0938 - mean_squared_error: 343026.0938\n",
      "Epoch 3276/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339242.6250 - mean_squared_error: 339242.6250\n",
      "Epoch 3277/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341461.4062 - mean_squared_error: 341461.4062\n",
      "Epoch 3278/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339113.6250 - mean_squared_error: 339113.6250\n",
      "Epoch 3279/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342974.4688 - mean_squared_error: 342974.4688\n",
      "Epoch 3280/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347615.8438 - mean_squared_error: 347615.8438\n",
      "Epoch 3281/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346485.0938 - mean_squared_error: 346485.0938\n",
      "Epoch 3282/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344621.0312 - mean_squared_error: 344621.0312\n",
      "Epoch 3283/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343032.0625 - mean_squared_error: 343032.0625\n",
      "Epoch 3284/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337746.4375 - mean_squared_error: 337746.4375\n",
      "Epoch 3285/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342878.8438 - mean_squared_error: 342878.8438\n",
      "Epoch 3286/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345375.5000 - mean_squared_error: 345375.5000\n",
      "Epoch 3287/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338493.7500 - mean_squared_error: 338493.7500\n",
      "Epoch 3288/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347030.3125 - mean_squared_error: 347030.3125\n",
      "Epoch 3289/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341532.2812 - mean_squared_error: 341532.2812\n",
      "Epoch 3290/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349430.4062 - mean_squared_error: 349430.4062\n",
      "Epoch 3291/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345724.2188 - mean_squared_error: 345724.2188\n",
      "Epoch 3292/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335886.6875 - mean_squared_error: 335886.6875\n",
      "Epoch 3293/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336191.7500 - mean_squared_error: 336191.7500\n",
      "Epoch 3294/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333832.1250 - mean_squared_error: 333832.1250\n",
      "Epoch 3295/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347654.7812 - mean_squared_error: 347654.7812\n",
      "Epoch 3296/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 339993.5938 - mean_squared_error: 339993.5938\n",
      "Epoch 3297/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338202.8750 - mean_squared_error: 338202.8750\n",
      "Epoch 3298/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337190.8750 - mean_squared_error: 337190.8750\n",
      "Epoch 3299/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348481.3750 - mean_squared_error: 348481.3750\n",
      "Epoch 3300/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341894.9375 - mean_squared_error: 341894.9375\n",
      "Epoch 3301/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341399.9375 - mean_squared_error: 341399.9375\n",
      "Epoch 3302/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340820.6250 - mean_squared_error: 340820.6250\n",
      "Epoch 3303/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341257.0625 - mean_squared_error: 341257.0625\n",
      "Epoch 3304/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350052.8750 - mean_squared_error: 350052.9062\n",
      "Epoch 3305/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339524.5312 - mean_squared_error: 339524.5312\n",
      "Epoch 3306/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340250.6250 - mean_squared_error: 340250.6250\n",
      "Epoch 3307/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347963.5312 - mean_squared_error: 347963.5312\n",
      "Epoch 3308/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338530.3750 - mean_squared_error: 338530.3750\n",
      "Epoch 3309/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345254.7500 - mean_squared_error: 345254.7500\n",
      "Epoch 3310/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346620.8125 - mean_squared_error: 346620.7812\n",
      "Epoch 3311/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344766.3750 - mean_squared_error: 344766.3750\n",
      "Epoch 3312/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346279.2188 - mean_squared_error: 346279.2188\n",
      "Epoch 3313/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342436.3438 - mean_squared_error: 342436.3438\n",
      "Epoch 3314/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346398.7812 - mean_squared_error: 346398.7812\n",
      "Epoch 3315/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341331.6250 - mean_squared_error: 341331.6562\n",
      "Epoch 3316/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 338485.2812 - mean_squared_error: 338485.2812\n",
      "Epoch 3317/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345970.6562 - mean_squared_error: 345970.6562\n",
      "Epoch 3318/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343886.0000 - mean_squared_error: 343886.0000\n",
      "Epoch 3319/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337536.0000 - mean_squared_error: 337536.0000\n",
      "Epoch 3320/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338329.3438 - mean_squared_error: 338329.3438\n",
      "Epoch 3321/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350025.6875 - mean_squared_error: 350025.6875\n",
      "Epoch 3322/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343364.0625 - mean_squared_error: 343364.0625\n",
      "Epoch 3323/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348271.3750 - mean_squared_error: 348271.3750\n",
      "Epoch 3324/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346065.3438 - mean_squared_error: 346065.3438\n",
      "Epoch 3325/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341424.6875 - mean_squared_error: 341424.6875\n",
      "Epoch 3326/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340677.0938 - mean_squared_error: 340677.0938\n",
      "Epoch 3327/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338871.3125 - mean_squared_error: 338871.3125\n",
      "Epoch 3328/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340251.6875 - mean_squared_error: 340251.6875\n",
      "Epoch 3329/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333286.5000 - mean_squared_error: 333286.5000\n",
      "Epoch 3330/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351846.6875 - mean_squared_error: 351846.6875\n",
      "Epoch 3331/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340587.2500 - mean_squared_error: 340587.2500\n",
      "Epoch 3332/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342923.0312 - mean_squared_error: 342923.0312\n",
      "Epoch 3333/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345112.8438 - mean_squared_error: 345112.8438\n",
      "Epoch 3334/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349342.4062 - mean_squared_error: 349342.4062\n",
      "Epoch 3335/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338232.8750 - mean_squared_error: 338232.8750\n",
      "Epoch 3336/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349558.8438 - mean_squared_error: 349558.8438\n",
      "Epoch 3337/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342814.5312 - mean_squared_error: 342814.5312\n",
      "Epoch 3338/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346909.9062 - mean_squared_error: 346909.9062\n",
      "Epoch 3339/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337846.4375 - mean_squared_error: 337846.4375\n",
      "Epoch 3340/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339848.4688 - mean_squared_error: 339848.4688\n",
      "Epoch 3341/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345847.8750 - mean_squared_error: 345847.8750\n",
      "Epoch 3342/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343560.3750 - mean_squared_error: 343560.3750\n",
      "Epoch 3343/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338151.1562 - mean_squared_error: 338151.1562\n",
      "Epoch 3344/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342498.9688 - mean_squared_error: 342498.9688\n",
      "Epoch 3345/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348290.8438 - mean_squared_error: 348290.8438\n",
      "Epoch 3346/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341925.5000 - mean_squared_error: 341925.5000\n",
      "Epoch 3347/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341789.9688 - mean_squared_error: 341789.9688\n",
      "Epoch 3348/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342926.6875 - mean_squared_error: 342926.6875\n",
      "Epoch 3349/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340326.9688 - mean_squared_error: 340326.9688\n",
      "Epoch 3350/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338386.8125 - mean_squared_error: 338386.8125\n",
      "Epoch 3351/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339069.9375 - mean_squared_error: 339069.9375\n",
      "Epoch 3352/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335846.5625 - mean_squared_error: 335846.5625\n",
      "Epoch 3353/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 350938.8438 - mean_squared_error: 350938.8438\n",
      "Epoch 3354/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 354678.0625 - mean_squared_error: 354678.0625\n",
      "Epoch 3355/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345365.0938 - mean_squared_error: 345365.0938\n",
      "Epoch 3356/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339127.0625 - mean_squared_error: 339127.0625\n",
      "Epoch 3357/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345632.7500 - mean_squared_error: 345632.7500\n",
      "Epoch 3358/5000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 350443.8750 - mean_squared_error: 350443.8750\n",
      "Epoch 3359/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342559.5625 - mean_squared_error: 342559.5625\n",
      "Epoch 3360/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345801.7812 - mean_squared_error: 345801.7812\n",
      "Epoch 3361/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347522.3750 - mean_squared_error: 347522.3750\n",
      "Epoch 3362/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343408.0938 - mean_squared_error: 343408.0938\n",
      "Epoch 3363/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350070.2188 - mean_squared_error: 350070.2188\n",
      "Epoch 3364/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345885.3125 - mean_squared_error: 345885.3125\n",
      "Epoch 3365/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347291.5938 - mean_squared_error: 347291.5938\n",
      "Epoch 3366/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353018.3750 - mean_squared_error: 353018.3750\n",
      "Epoch 3367/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353565.4375 - mean_squared_error: 353565.4375\n",
      "Epoch 3368/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340493.6875 - mean_squared_error: 340493.6875\n",
      "Epoch 3369/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345891.8438 - mean_squared_error: 345891.8438\n",
      "Epoch 3370/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347214.3125 - mean_squared_error: 347214.3125\n",
      "Epoch 3371/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336591.0000 - mean_squared_error: 336591.0000\n",
      "Epoch 3372/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342376.6250 - mean_squared_error: 342376.6250\n",
      "Epoch 3373/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342084.4062 - mean_squared_error: 342084.4062\n",
      "Epoch 3374/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342262.4062 - mean_squared_error: 342262.4062\n",
      "Epoch 3375/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334212.3438 - mean_squared_error: 334212.3438\n",
      "Epoch 3376/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342961.8750 - mean_squared_error: 342961.8750\n",
      "Epoch 3377/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342907.0000 - mean_squared_error: 342907.0000\n",
      "Epoch 3378/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339873.9688 - mean_squared_error: 339873.9688\n",
      "Epoch 3379/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340954.5000 - mean_squared_error: 340954.5000\n",
      "Epoch 3380/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348523.3750 - mean_squared_error: 348523.3750\n",
      "Epoch 3381/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347807.9688 - mean_squared_error: 347807.9688\n",
      "Epoch 3382/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341063.6875 - mean_squared_error: 341063.6875\n",
      "Epoch 3383/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350436.5312 - mean_squared_error: 350436.5625\n",
      "Epoch 3384/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344079.5938 - mean_squared_error: 344079.5938\n",
      "Epoch 3385/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 352369.0000 - mean_squared_error: 352369.0000\n",
      "Epoch 3386/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339612.2812 - mean_squared_error: 339612.2812\n",
      "Epoch 3387/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351600.0938 - mean_squared_error: 351600.0938\n",
      "Epoch 3388/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345853.0625 - mean_squared_error: 345853.0625\n",
      "Epoch 3389/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332298.7812 - mean_squared_error: 332298.7812\n",
      "Epoch 3390/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344548.0938 - mean_squared_error: 344548.0938\n",
      "Epoch 3391/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342822.1562 - mean_squared_error: 342822.1562\n",
      "Epoch 3392/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339136.2812 - mean_squared_error: 339136.2812\n",
      "Epoch 3393/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351048.4062 - mean_squared_error: 351048.4062\n",
      "Epoch 3394/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347780.6250 - mean_squared_error: 347780.6250\n",
      "Epoch 3395/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 345181.5938 - mean_squared_error: 345181.5938\n",
      "Epoch 3396/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339046.0625 - mean_squared_error: 339046.0625\n",
      "Epoch 3397/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340485.1250 - mean_squared_error: 340485.1250\n",
      "Epoch 3398/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338721.6562 - mean_squared_error: 338721.6562\n",
      "Epoch 3399/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345333.5938 - mean_squared_error: 345333.5938\n",
      "Epoch 3400/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347026.7188 - mean_squared_error: 347026.7188\n",
      "Epoch 3401/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338328.2500 - mean_squared_error: 338328.2500\n",
      "Epoch 3402/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350730.4688 - mean_squared_error: 350730.4688\n",
      "Epoch 3403/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346885.3750 - mean_squared_error: 346885.3750\n",
      "Epoch 3404/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349058.0625 - mean_squared_error: 349058.0625\n",
      "Epoch 3405/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342678.7188 - mean_squared_error: 342678.7188\n",
      "Epoch 3406/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348292.6875 - mean_squared_error: 348292.6875\n",
      "Epoch 3407/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342529.9062 - mean_squared_error: 342529.9062\n",
      "Epoch 3408/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339565.8750 - mean_squared_error: 339565.8750\n",
      "Epoch 3409/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336625.0000 - mean_squared_error: 336625.0000\n",
      "Epoch 3410/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347141.9375 - mean_squared_error: 347141.9375\n",
      "Epoch 3411/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 346819.2500 - mean_squared_error: 346819.2500\n",
      "Epoch 3412/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334173.9375 - mean_squared_error: 334173.9375\n",
      "Epoch 3413/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340555.7812 - mean_squared_error: 340555.7812\n",
      "Epoch 3414/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348693.6875 - mean_squared_error: 348693.6875\n",
      "Epoch 3415/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337515.5625 - mean_squared_error: 337515.5625\n",
      "Epoch 3416/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335633.8750 - mean_squared_error: 335633.8750\n",
      "Epoch 3417/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347249.8438 - mean_squared_error: 347249.8438\n",
      "Epoch 3418/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338495.5000 - mean_squared_error: 338495.5000\n",
      "Epoch 3419/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335569.7188 - mean_squared_error: 335569.7188\n",
      "Epoch 3420/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336729.1562 - mean_squared_error: 336729.1562\n",
      "Epoch 3421/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346482.9062 - mean_squared_error: 346482.9062\n",
      "Epoch 3422/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339850.6875 - mean_squared_error: 339850.6875\n",
      "Epoch 3423/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343207.1250 - mean_squared_error: 343207.1250\n",
      "Epoch 3424/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331597.3438 - mean_squared_error: 331597.3438\n",
      "Epoch 3425/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 350599.6250 - mean_squared_error: 350599.6250\n",
      "Epoch 3426/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342344.5625 - mean_squared_error: 342344.5625\n",
      "Epoch 3427/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342779.0938 - mean_squared_error: 342779.0938\n",
      "Epoch 3428/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 347634.3438 - mean_squared_error: 347634.3438\n",
      "Epoch 3429/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336424.8125 - mean_squared_error: 336424.8125\n",
      "Epoch 3430/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340110.2500 - mean_squared_error: 340110.2500\n",
      "Epoch 3431/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338951.0938 - mean_squared_error: 338951.0938\n",
      "Epoch 3432/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336288.9062 - mean_squared_error: 336288.9062\n",
      "Epoch 3433/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 336694.1562 - mean_squared_error: 336694.1562\n",
      "Epoch 3434/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343411.5938 - mean_squared_error: 343411.5938\n",
      "Epoch 3435/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339537.5938 - mean_squared_error: 339537.5938\n",
      "Epoch 3436/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343789.5938 - mean_squared_error: 343789.5938\n",
      "Epoch 3437/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350719.9062 - mean_squared_error: 350719.9062\n",
      "Epoch 3438/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340520.6250 - mean_squared_error: 340520.6250\n",
      "Epoch 3439/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339466.6562 - mean_squared_error: 339466.7188\n",
      "Epoch 3440/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346088.7500 - mean_squared_error: 346088.7500\n",
      "Epoch 3441/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332306.6875 - mean_squared_error: 332306.6875\n",
      "Epoch 3442/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344244.2812 - mean_squared_error: 344244.2812\n",
      "Epoch 3443/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338043.4375 - mean_squared_error: 338043.4688\n",
      "Epoch 3444/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341931.0938 - mean_squared_error: 341931.0938\n",
      "Epoch 3445/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342624.4375 - mean_squared_error: 342624.4375\n",
      "Epoch 3446/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342654.5312 - mean_squared_error: 342654.5312\n",
      "Epoch 3447/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343125.3438 - mean_squared_error: 343125.2812\n",
      "Epoch 3448/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344685.7812 - mean_squared_error: 344685.7812\n",
      "Epoch 3449/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343977.9375 - mean_squared_error: 343977.9375\n",
      "Epoch 3450/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 346165.3125 - mean_squared_error: 346165.3125\n",
      "Epoch 3451/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337981.1562 - mean_squared_error: 337981.1875\n",
      "Epoch 3452/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334802.0312 - mean_squared_error: 334802.0312\n",
      "Epoch 3453/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349010.6875 - mean_squared_error: 349010.6875\n",
      "Epoch 3454/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338106.9375 - mean_squared_error: 338106.9062\n",
      "Epoch 3455/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347230.7812 - mean_squared_error: 347230.7812\n",
      "Epoch 3456/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 344044.2500 - mean_squared_error: 344044.2500\n",
      "Epoch 3457/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336314.3750 - mean_squared_error: 336314.3750\n",
      "Epoch 3458/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348914.0938 - mean_squared_error: 348914.0938\n",
      "Epoch 3459/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348767.7500 - mean_squared_error: 348767.7500\n",
      "Epoch 3460/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344409.4688 - mean_squared_error: 344409.4688\n",
      "Epoch 3461/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337833.3750 - mean_squared_error: 337833.3750\n",
      "Epoch 3462/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344792.1250 - mean_squared_error: 344792.1250\n",
      "Epoch 3463/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339356.8125 - mean_squared_error: 339356.8125\n",
      "Epoch 3464/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344262.9688 - mean_squared_error: 344262.9688\n",
      "Epoch 3465/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339537.1250 - mean_squared_error: 339537.1250\n",
      "Epoch 3466/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348094.0625 - mean_squared_error: 348094.0625\n",
      "Epoch 3467/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345310.5312 - mean_squared_error: 345310.5312\n",
      "Epoch 3468/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339566.4062 - mean_squared_error: 339566.4062\n",
      "Epoch 3469/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337426.9688 - mean_squared_error: 337426.9688\n",
      "Epoch 3470/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343864.7812 - mean_squared_error: 343864.7812\n",
      "Epoch 3471/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335750.0625 - mean_squared_error: 335750.0625\n",
      "Epoch 3472/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337054.8750 - mean_squared_error: 337054.8750\n",
      "Epoch 3473/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347606.8750 - mean_squared_error: 347606.8750\n",
      "Epoch 3474/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348492.5312 - mean_squared_error: 348492.5312\n",
      "Epoch 3475/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342651.3438 - mean_squared_error: 342651.3438\n",
      "Epoch 3476/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340352.2188 - mean_squared_error: 340352.1875\n",
      "Epoch 3477/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341807.5312 - mean_squared_error: 341807.5312\n",
      "Epoch 3478/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 325923.2812 - mean_squared_error: 325923.2812\n",
      "Epoch 3479/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344617.8125 - mean_squared_error: 344617.8125\n",
      "Epoch 3480/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341158.6562 - mean_squared_error: 341158.6562\n",
      "Epoch 3481/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338999.0000 - mean_squared_error: 338999.0000\n",
      "Epoch 3482/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341867.3750 - mean_squared_error: 341867.3750\n",
      "Epoch 3483/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342403.3125 - mean_squared_error: 342403.3125\n",
      "Epoch 3484/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343096.4375 - mean_squared_error: 343096.4375\n",
      "Epoch 3485/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340662.8125 - mean_squared_error: 340662.8125\n",
      "Epoch 3486/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348143.3438 - mean_squared_error: 348143.3438\n",
      "Epoch 3487/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344121.0000 - mean_squared_error: 344121.0000\n",
      "Epoch 3488/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 343625.6250 - mean_squared_error: 343625.6250\n",
      "Epoch 3489/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339116.4375 - mean_squared_error: 339116.4375\n",
      "Epoch 3490/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344850.0312 - mean_squared_error: 344850.0312\n",
      "Epoch 3491/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343114.5938 - mean_squared_error: 343114.5938\n",
      "Epoch 3492/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340595.2500 - mean_squared_error: 340595.2500\n",
      "Epoch 3493/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347981.9688 - mean_squared_error: 347981.9688\n",
      "Epoch 3494/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341613.0625 - mean_squared_error: 341613.0625\n",
      "Epoch 3495/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345572.2500 - mean_squared_error: 345572.2500\n",
      "Epoch 3496/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337791.5625 - mean_squared_error: 337791.5625\n",
      "Epoch 3497/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345671.3750 - mean_squared_error: 345671.3750\n",
      "Epoch 3498/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342006.5625 - mean_squared_error: 342006.5625\n",
      "Epoch 3499/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338569.6562 - mean_squared_error: 338569.6562\n",
      "Epoch 3500/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336608.7500 - mean_squared_error: 336608.7500\n",
      "Epoch 3501/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337592.5000 - mean_squared_error: 337592.5000\n",
      "Epoch 3502/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336606.1562 - mean_squared_error: 336606.1562\n",
      "Epoch 3503/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347030.8750 - mean_squared_error: 347030.8750\n",
      "Epoch 3504/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 347701.5312 - mean_squared_error: 347701.5312\n",
      "Epoch 3505/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341472.4375 - mean_squared_error: 341472.4375\n",
      "Epoch 3506/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348623.6875 - mean_squared_error: 348623.6875\n",
      "Epoch 3507/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341399.9375 - mean_squared_error: 341399.9375\n",
      "Epoch 3508/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339805.8438 - mean_squared_error: 339805.8438\n",
      "Epoch 3509/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338211.3750 - mean_squared_error: 338211.3750\n",
      "Epoch 3510/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 339360.8125 - mean_squared_error: 339360.8125\n",
      "Epoch 3511/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344334.0625 - mean_squared_error: 344334.0625\n",
      "Epoch 3512/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343285.3750 - mean_squared_error: 343285.3750\n",
      "Epoch 3513/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 351686.5312 - mean_squared_error: 351686.5312\n",
      "Epoch 3514/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 345311.0000 - mean_squared_error: 345311.0000\n",
      "Epoch 3515/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353189.9062 - mean_squared_error: 353189.9062\n",
      "Epoch 3516/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 353091.9062 - mean_squared_error: 353091.9062\n",
      "Epoch 3517/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336913.8438 - mean_squared_error: 336913.8438\n",
      "Epoch 3518/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343076.2188 - mean_squared_error: 343076.2188\n",
      "Epoch 3519/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343823.6250 - mean_squared_error: 343823.5938\n",
      "Epoch 3520/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335245.7500 - mean_squared_error: 335245.7500\n",
      "Epoch 3521/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 336776.0000 - mean_squared_error: 336776.0000\n",
      "Epoch 3522/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345574.4062 - mean_squared_error: 345574.4062\n",
      "Epoch 3523/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 338940.2188 - mean_squared_error: 338940.2188\n",
      "Epoch 3524/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 348996.0938 - mean_squared_error: 348996.0938\n",
      "Epoch 3525/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340631.6562 - mean_squared_error: 340631.6562\n",
      "Epoch 3526/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337849.8750 - mean_squared_error: 337849.8750\n",
      "Epoch 3527/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335932.6562 - mean_squared_error: 335932.6562\n",
      "Epoch 3528/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344752.0625 - mean_squared_error: 344752.0625\n",
      "Epoch 3529/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 341592.8750 - mean_squared_error: 341592.8750\n",
      "Epoch 3530/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 340460.6250 - mean_squared_error: 340460.6250\n",
      "Epoch 3531/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332065.3750 - mean_squared_error: 332065.3750\n",
      "Epoch 3532/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 354011.2188 - mean_squared_error: 354011.2188\n",
      "Epoch 3533/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 335558.1875 - mean_squared_error: 335558.1875\n",
      "Epoch 3534/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333991.5625 - mean_squared_error: 333991.5625\n",
      "Epoch 3535/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344602.9062 - mean_squared_error: 344602.9062\n",
      "Epoch 3536/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 340850.6250 - mean_squared_error: 340850.6250\n",
      "Epoch 3537/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342627.0938 - mean_squared_error: 342627.0938\n",
      "Epoch 3538/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 344388.4375 - mean_squared_error: 344388.4375\n",
      "Epoch 3539/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342510.6562 - mean_squared_error: 342510.6562\n",
      "Epoch 3540/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 331255.3750 - mean_squared_error: 331255.3750\n",
      "Epoch 3541/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345652.4062 - mean_squared_error: 345652.4062\n",
      "Epoch 3542/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334589.3125 - mean_squared_error: 334589.3125\n",
      "Epoch 3543/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334999.1875 - mean_squared_error: 334999.1875\n",
      "Epoch 3544/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350317.8750 - mean_squared_error: 350317.8750\n",
      "Epoch 3545/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331961.8438 - mean_squared_error: 331961.8438\n",
      "Epoch 3546/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341972.8125 - mean_squared_error: 341972.8125\n",
      "Epoch 3547/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 334290.7500 - mean_squared_error: 334290.7500\n",
      "Epoch 3548/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 332213.8750 - mean_squared_error: 332213.8750\n",
      "Epoch 3549/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351840.3125 - mean_squared_error: 351840.3125\n",
      "Epoch 3550/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342639.7812 - mean_squared_error: 342639.7812\n",
      "Epoch 3551/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338549.0000 - mean_squared_error: 338549.0000\n",
      "Epoch 3552/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349112.5938 - mean_squared_error: 349112.5938\n",
      "Epoch 3553/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344727.7812 - mean_squared_error: 344727.7812\n",
      "Epoch 3554/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334309.6875 - mean_squared_error: 334309.6875\n",
      "Epoch 3555/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338066.0000 - mean_squared_error: 338066.0000\n",
      "Epoch 3556/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338651.9375 - mean_squared_error: 338651.9375\n",
      "Epoch 3557/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337256.2812 - mean_squared_error: 337256.2812\n",
      "Epoch 3558/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 337928.6562 - mean_squared_error: 337928.6562\n",
      "Epoch 3559/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 331258.6875 - mean_squared_error: 331258.6875\n",
      "Epoch 3560/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 318466.1562 - mean_squared_error: 318466.1562\n",
      "Epoch 3561/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 324513.5000 - mean_squared_error: 324513.5000\n",
      "Epoch 3562/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 318756.9062 - mean_squared_error: 318756.9062\n",
      "Epoch 3563/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 319295.8125 - mean_squared_error: 319295.8125\n",
      "Epoch 3564/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316136.2500 - mean_squared_error: 316136.2500\n",
      "Epoch 3565/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 318718.8438 - mean_squared_error: 318718.8438\n",
      "Epoch 3566/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 317037.7812 - mean_squared_error: 317037.7812\n",
      "Epoch 3567/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 316612.8438 - mean_squared_error: 316612.8438\n",
      "Epoch 3568/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 312543.0625 - mean_squared_error: 312543.0625\n",
      "Epoch 3569/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305615.4062 - mean_squared_error: 305615.4062\n",
      "Epoch 3570/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 315821.9062 - mean_squared_error: 315821.9062\n",
      "Epoch 3571/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307753.4688 - mean_squared_error: 307753.4688\n",
      "Epoch 3572/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 314048.8750 - mean_squared_error: 314048.8750\n",
      "Epoch 3573/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 319533.5312 - mean_squared_error: 319533.5312\n",
      "Epoch 3574/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 315656.1250 - mean_squared_error: 315656.1250\n",
      "Epoch 3575/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 309382.1250 - mean_squared_error: 309382.1250\n",
      "Epoch 3576/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 310662.0312 - mean_squared_error: 310662.0312\n",
      "Epoch 3577/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306016.9375 - mean_squared_error: 306016.9375\n",
      "Epoch 3578/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 312120.8438 - mean_squared_error: 312120.8438\n",
      "Epoch 3579/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295265.0312 - mean_squared_error: 295265.0312\n",
      "Epoch 3580/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297428.7812 - mean_squared_error: 297428.7812\n",
      "Epoch 3581/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297783.3438 - mean_squared_error: 297783.3438\n",
      "Epoch 3582/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292095.1562 - mean_squared_error: 292095.1562\n",
      "Epoch 3583/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297752.0000 - mean_squared_error: 297752.0000\n",
      "Epoch 3584/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297731.0000 - mean_squared_error: 297731.0312\n",
      "Epoch 3585/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300208.6562 - mean_squared_error: 300208.6562\n",
      "Epoch 3586/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303046.6250 - mean_squared_error: 303046.6250\n",
      "Epoch 3587/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301278.3438 - mean_squared_error: 301278.3438\n",
      "Epoch 3588/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297435.1562 - mean_squared_error: 297435.1562\n",
      "Epoch 3589/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304554.3125 - mean_squared_error: 304554.3125\n",
      "Epoch 3590/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305375.2812 - mean_squared_error: 305375.2812\n",
      "Epoch 3591/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299223.9062 - mean_squared_error: 299223.9062\n",
      "Epoch 3592/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306132.1562 - mean_squared_error: 306132.1562\n",
      "Epoch 3593/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303155.5938 - mean_squared_error: 303155.5938\n",
      "Epoch 3594/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306126.3750 - mean_squared_error: 306126.3750\n",
      "Epoch 3595/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300187.8438 - mean_squared_error: 300187.8438\n",
      "Epoch 3596/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299252.0625 - mean_squared_error: 299252.0625\n",
      "Epoch 3597/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297550.8125 - mean_squared_error: 297550.8125\n",
      "Epoch 3598/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299389.1562 - mean_squared_error: 299389.1562\n",
      "Epoch 3599/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293038.9688 - mean_squared_error: 293038.9688\n",
      "Epoch 3600/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307092.0312 - mean_squared_error: 307092.0312\n",
      "Epoch 3601/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 298117.6250 - mean_squared_error: 298117.6250\n",
      "Epoch 3602/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299974.9688 - mean_squared_error: 299974.9688\n",
      "Epoch 3603/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305999.5000 - mean_squared_error: 305999.5000\n",
      "Epoch 3604/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307788.4375 - mean_squared_error: 307788.4375\n",
      "Epoch 3605/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294899.9062 - mean_squared_error: 294899.9062\n",
      "Epoch 3606/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295863.8438 - mean_squared_error: 295863.8438\n",
      "Epoch 3607/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286845.9688 - mean_squared_error: 286845.9688\n",
      "Epoch 3608/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304003.6250 - mean_squared_error: 304003.6250\n",
      "Epoch 3609/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294551.7188 - mean_squared_error: 294551.7188\n",
      "Epoch 3610/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296947.2500 - mean_squared_error: 296947.2500\n",
      "Epoch 3611/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296610.2188 - mean_squared_error: 296610.2188\n",
      "Epoch 3612/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294079.2812 - mean_squared_error: 294079.2812\n",
      "Epoch 3613/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296957.8438 - mean_squared_error: 296957.8438\n",
      "Epoch 3614/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299464.5000 - mean_squared_error: 299464.5000\n",
      "Epoch 3615/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304674.4688 - mean_squared_error: 304674.4688\n",
      "Epoch 3616/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299240.9375 - mean_squared_error: 299240.9375\n",
      "Epoch 3617/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292279.3750 - mean_squared_error: 292279.3750\n",
      "Epoch 3618/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299429.0312 - mean_squared_error: 299429.0312\n",
      "Epoch 3619/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283898.8125 - mean_squared_error: 283898.8125\n",
      "Epoch 3620/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299060.8750 - mean_squared_error: 299060.8750\n",
      "Epoch 3621/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296346.9375 - mean_squared_error: 296346.9375\n",
      "Epoch 3622/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 304558.4375 - mean_squared_error: 304558.4375\n",
      "Epoch 3623/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 303379.5312 - mean_squared_error: 303379.5312\n",
      "Epoch 3624/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303759.2500 - mean_squared_error: 303759.2500\n",
      "Epoch 3625/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294246.7812 - mean_squared_error: 294246.7812\n",
      "Epoch 3626/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290443.8125 - mean_squared_error: 290443.8125\n",
      "Epoch 3627/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290179.9688 - mean_squared_error: 290179.9688\n",
      "Epoch 3628/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301517.8125 - mean_squared_error: 301517.8125\n",
      "Epoch 3629/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302559.0000 - mean_squared_error: 302559.0000\n",
      "Epoch 3630/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297748.4375 - mean_squared_error: 297748.4375\n",
      "Epoch 3631/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283451.1875 - mean_squared_error: 283451.1875\n",
      "Epoch 3632/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290146.1250 - mean_squared_error: 290146.1250\n",
      "Epoch 3633/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 248713.5469 - mean_squared_error: 248713.5469\n",
      "Epoch 3634/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 195732.7812 - mean_squared_error: 195732.7812\n",
      "Epoch 3635/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 223834.0781 - mean_squared_error: 223834.0781\n",
      "Epoch 3636/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 228853.8281 - mean_squared_error: 228853.8281\n",
      "Epoch 3637/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 315035.2812 - mean_squared_error: 315035.2812\n",
      "Epoch 3638/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 229072.6719 - mean_squared_error: 229072.6719\n",
      "Epoch 3639/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299925.5312 - mean_squared_error: 299925.5312\n",
      "Epoch 3640/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305901.1250 - mean_squared_error: 305901.1250\n",
      "Epoch 3641/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293010.3750 - mean_squared_error: 293010.3750\n",
      "Epoch 3642/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297086.5000 - mean_squared_error: 297086.4688\n",
      "Epoch 3643/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301338.0312 - mean_squared_error: 301338.0312\n",
      "Epoch 3644/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296279.2812 - mean_squared_error: 296279.2812\n",
      "Epoch 3645/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303715.3125 - mean_squared_error: 303715.3125\n",
      "Epoch 3646/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 293604.2500 - mean_squared_error: 293604.2500\n",
      "Epoch 3647/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303531.6250 - mean_squared_error: 303531.6562\n",
      "Epoch 3648/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293835.3438 - mean_squared_error: 293835.3438\n",
      "Epoch 3649/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294861.9688 - mean_squared_error: 294861.9688\n",
      "Epoch 3650/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303462.1875 - mean_squared_error: 303462.1875\n",
      "Epoch 3651/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291363.7812 - mean_squared_error: 291363.7812\n",
      "Epoch 3652/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295000.9688 - mean_squared_error: 295000.9688\n",
      "Epoch 3653/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289865.3125 - mean_squared_error: 289865.3125\n",
      "Epoch 3654/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296073.4062 - mean_squared_error: 296073.4062\n",
      "Epoch 3655/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292213.0625 - mean_squared_error: 292213.0625\n",
      "Epoch 3656/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297789.0000 - mean_squared_error: 297789.0000\n",
      "Epoch 3657/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297321.8125 - mean_squared_error: 297321.8125\n",
      "Epoch 3658/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300947.0312 - mean_squared_error: 300947.0312\n",
      "Epoch 3659/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290371.6562 - mean_squared_error: 290371.6562\n",
      "Epoch 3660/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295396.8750 - mean_squared_error: 295396.8750\n",
      "Epoch 3661/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299029.5312 - mean_squared_error: 299029.5312\n",
      "Epoch 3662/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301273.2188 - mean_squared_error: 301273.2188\n",
      "Epoch 3663/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294851.2812 - mean_squared_error: 294851.2812\n",
      "Epoch 3664/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298215.5000 - mean_squared_error: 298215.5000\n",
      "Epoch 3665/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299000.9062 - mean_squared_error: 299000.9062\n",
      "Epoch 3666/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299188.4688 - mean_squared_error: 299188.4688\n",
      "Epoch 3667/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297640.3125 - mean_squared_error: 297640.3125\n",
      "Epoch 3668/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290127.3750 - mean_squared_error: 290127.3750\n",
      "Epoch 3669/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294682.4688 - mean_squared_error: 294682.4688\n",
      "Epoch 3670/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295820.0938 - mean_squared_error: 295820.0938\n",
      "Epoch 3671/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299425.8750 - mean_squared_error: 299425.8750\n",
      "Epoch 3672/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292319.8125 - mean_squared_error: 292319.8125\n",
      "Epoch 3673/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291185.3750 - mean_squared_error: 291185.3750\n",
      "Epoch 3674/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296732.0625 - mean_squared_error: 296732.0625\n",
      "Epoch 3675/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297020.9375 - mean_squared_error: 297020.9375\n",
      "Epoch 3676/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293302.2812 - mean_squared_error: 293302.2812\n",
      "Epoch 3677/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298237.1562 - mean_squared_error: 298237.1562\n",
      "Epoch 3678/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292072.1250 - mean_squared_error: 292072.1250\n",
      "Epoch 3679/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298360.6562 - mean_squared_error: 298360.6562\n",
      "Epoch 3680/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294406.1875 - mean_squared_error: 294406.1875\n",
      "Epoch 3681/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304014.6250 - mean_squared_error: 304014.5938\n",
      "Epoch 3682/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291752.2812 - mean_squared_error: 291752.2812\n",
      "Epoch 3683/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288668.3750 - mean_squared_error: 288668.3438\n",
      "Epoch 3684/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297094.2500 - mean_squared_error: 297094.2500\n",
      "Epoch 3685/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298791.0625 - mean_squared_error: 298791.0625\n",
      "Epoch 3686/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 281199.0312 - mean_squared_error: 281199.0312\n",
      "Epoch 3687/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296062.0625 - mean_squared_error: 296062.0625\n",
      "Epoch 3688/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292391.4688 - mean_squared_error: 292391.4688\n",
      "Epoch 3689/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299762.3750 - mean_squared_error: 299762.3750\n",
      "Epoch 3690/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299924.8750 - mean_squared_error: 299924.8750\n",
      "Epoch 3691/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293186.0938 - mean_squared_error: 293186.0625\n",
      "Epoch 3692/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 298835.8125 - mean_squared_error: 298835.8125\n",
      "Epoch 3693/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291227.4062 - mean_squared_error: 291227.4062\n",
      "Epoch 3694/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293806.5625 - mean_squared_error: 293806.5625\n",
      "Epoch 3695/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294567.6875 - mean_squared_error: 294567.6875\n",
      "Epoch 3696/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299503.1250 - mean_squared_error: 299503.1250\n",
      "Epoch 3697/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289500.3125 - mean_squared_error: 289500.3125\n",
      "Epoch 3698/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296117.8438 - mean_squared_error: 296117.7812\n",
      "Epoch 3699/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292724.2500 - mean_squared_error: 292724.2500\n",
      "Epoch 3700/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294462.2500 - mean_squared_error: 294462.2500\n",
      "Epoch 3701/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297509.5312 - mean_squared_error: 297509.5312\n",
      "Epoch 3702/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296007.9375 - mean_squared_error: 296007.9375\n",
      "Epoch 3703/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293221.7188 - mean_squared_error: 293221.7188\n",
      "Epoch 3704/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302769.5625 - mean_squared_error: 302769.5625\n",
      "Epoch 3705/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296307.8750 - mean_squared_error: 296307.8750\n",
      "Epoch 3706/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287232.0312 - mean_squared_error: 287232.0312\n",
      "Epoch 3707/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296294.0938 - mean_squared_error: 296294.0938\n",
      "Epoch 3708/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303374.6875 - mean_squared_error: 303374.6875\n",
      "Epoch 3709/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301039.4688 - mean_squared_error: 301039.4688\n",
      "Epoch 3710/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292261.0312 - mean_squared_error: 292261.0312\n",
      "Epoch 3711/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291691.5625 - mean_squared_error: 291691.5625\n",
      "Epoch 3712/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298280.8438 - mean_squared_error: 298280.8438\n",
      "Epoch 3713/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296814.2188 - mean_squared_error: 296814.2188\n",
      "Epoch 3714/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297549.9062 - mean_squared_error: 297549.9062\n",
      "Epoch 3715/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291338.7812 - mean_squared_error: 291338.7812\n",
      "Epoch 3716/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 293883.0000 - mean_squared_error: 293883.0000\n",
      "Epoch 3717/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298593.5000 - mean_squared_error: 298593.5000\n",
      "Epoch 3718/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292998.0312 - mean_squared_error: 292998.0312\n",
      "Epoch 3719/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297567.0312 - mean_squared_error: 297567.0312\n",
      "Epoch 3720/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290920.0000 - mean_squared_error: 290920.0000\n",
      "Epoch 3721/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291089.0938 - mean_squared_error: 291089.0938\n",
      "Epoch 3722/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292816.6875 - mean_squared_error: 292816.6875\n",
      "Epoch 3723/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 297044.3750 - mean_squared_error: 297044.3750\n",
      "Epoch 3724/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291338.3750 - mean_squared_error: 291338.4062\n",
      "Epoch 3725/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302818.8750 - mean_squared_error: 302818.8750\n",
      "Epoch 3726/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303823.6562 - mean_squared_error: 303823.6562\n",
      "Epoch 3727/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297131.0312 - mean_squared_error: 297131.0000\n",
      "Epoch 3728/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292713.2812 - mean_squared_error: 292713.2812\n",
      "Epoch 3729/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288088.7812 - mean_squared_error: 288088.7812\n",
      "Epoch 3730/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303351.2188 - mean_squared_error: 303351.2500\n",
      "Epoch 3731/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293354.9062 - mean_squared_error: 293354.9062\n",
      "Epoch 3732/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292692.9688 - mean_squared_error: 292692.9375\n",
      "Epoch 3733/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284484.3125 - mean_squared_error: 284484.3125\n",
      "Epoch 3734/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294686.6875 - mean_squared_error: 294686.7188\n",
      "Epoch 3735/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298038.8438 - mean_squared_error: 298038.8438\n",
      "Epoch 3736/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296328.4688 - mean_squared_error: 296328.4688\n",
      "Epoch 3737/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296447.3438 - mean_squared_error: 296447.3438\n",
      "Epoch 3738/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303568.5625 - mean_squared_error: 303568.5625\n",
      "Epoch 3739/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290707.2812 - mean_squared_error: 290707.2812\n",
      "Epoch 3740/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285097.0625 - mean_squared_error: 285097.0625\n",
      "Epoch 3741/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293957.3125 - mean_squared_error: 293957.3125\n",
      "Epoch 3742/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299956.7500 - mean_squared_error: 299956.7500\n",
      "Epoch 3743/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295571.3750 - mean_squared_error: 295571.3750\n",
      "Epoch 3744/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290863.0938 - mean_squared_error: 290863.0938\n",
      "Epoch 3745/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292674.3750 - mean_squared_error: 292674.3750\n",
      "Epoch 3746/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289822.0312 - mean_squared_error: 289822.0312\n",
      "Epoch 3747/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295848.5938 - mean_squared_error: 295848.5938\n",
      "Epoch 3748/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301406.2812 - mean_squared_error: 301406.2812\n",
      "Epoch 3749/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300055.9062 - mean_squared_error: 300055.9062\n",
      "Epoch 3750/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292677.7812 - mean_squared_error: 292677.7812\n",
      "Epoch 3751/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301937.6562 - mean_squared_error: 301937.6562\n",
      "Epoch 3752/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294342.8438 - mean_squared_error: 294342.8125\n",
      "Epoch 3753/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293187.5000 - mean_squared_error: 293187.5000\n",
      "Epoch 3754/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298431.2188 - mean_squared_error: 298431.2188\n",
      "Epoch 3755/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295839.2188 - mean_squared_error: 295839.2188\n",
      "Epoch 3756/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294565.6250 - mean_squared_error: 294565.6250\n",
      "Epoch 3757/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300494.5938 - mean_squared_error: 300494.5938\n",
      "Epoch 3758/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299998.4688 - mean_squared_error: 299998.4688\n",
      "Epoch 3759/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296714.3750 - mean_squared_error: 296714.3750\n",
      "Epoch 3760/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297054.1250 - mean_squared_error: 297054.1250\n",
      "Epoch 3761/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292360.8438 - mean_squared_error: 292360.8438\n",
      "Epoch 3762/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296877.6562 - mean_squared_error: 296877.6562\n",
      "Epoch 3763/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293219.4688 - mean_squared_error: 293219.4688\n",
      "Epoch 3764/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293009.8125 - mean_squared_error: 293009.8125\n",
      "Epoch 3765/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292237.9375 - mean_squared_error: 292237.9375\n",
      "Epoch 3766/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302554.4688 - mean_squared_error: 302554.4688\n",
      "Epoch 3767/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291754.9062 - mean_squared_error: 291754.9062\n",
      "Epoch 3768/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299386.0625 - mean_squared_error: 299386.0625\n",
      "Epoch 3769/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291417.9375 - mean_squared_error: 291417.9375\n",
      "Epoch 3770/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294512.0000 - mean_squared_error: 294512.0312\n",
      "Epoch 3771/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295043.3125 - mean_squared_error: 295043.3125\n",
      "Epoch 3772/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293659.9688 - mean_squared_error: 293659.9688\n",
      "Epoch 3773/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 292803.3125 - mean_squared_error: 292803.2500\n",
      "Epoch 3774/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291184.2500 - mean_squared_error: 291184.2812\n",
      "Epoch 3775/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295334.2500 - mean_squared_error: 295334.2500\n",
      "Epoch 3776/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299630.5625 - mean_squared_error: 299630.5625\n",
      "Epoch 3777/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285896.5938 - mean_squared_error: 285896.5938\n",
      "Epoch 3778/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296250.4375 - mean_squared_error: 296250.4375\n",
      "Epoch 3779/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291754.4688 - mean_squared_error: 291754.4688\n",
      "Epoch 3780/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293433.5938 - mean_squared_error: 293433.5938\n",
      "Epoch 3781/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288015.9062 - mean_squared_error: 288015.9062\n",
      "Epoch 3782/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288736.5938 - mean_squared_error: 288736.5938\n",
      "Epoch 3783/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293622.3750 - mean_squared_error: 293622.3750\n",
      "Epoch 3784/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293982.1562 - mean_squared_error: 293982.1875\n",
      "Epoch 3785/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290279.1875 - mean_squared_error: 290279.1562\n",
      "Epoch 3786/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303570.0625 - mean_squared_error: 303570.0625\n",
      "Epoch 3787/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290792.4062 - mean_squared_error: 290792.4062\n",
      "Epoch 3788/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293482.7188 - mean_squared_error: 293482.6875\n",
      "Epoch 3789/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295630.5312 - mean_squared_error: 295630.5312\n",
      "Epoch 3790/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301980.1562 - mean_squared_error: 301980.1562\n",
      "Epoch 3791/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291760.0312 - mean_squared_error: 291760.0312\n",
      "Epoch 3792/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299741.0938 - mean_squared_error: 299741.0938\n",
      "Epoch 3793/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297203.6250 - mean_squared_error: 297203.6250\n",
      "Epoch 3794/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290906.1250 - mean_squared_error: 290906.1250\n",
      "Epoch 3795/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292304.1562 - mean_squared_error: 292304.1562\n",
      "Epoch 3796/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295242.8125 - mean_squared_error: 295242.8125\n",
      "Epoch 3797/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290793.4688 - mean_squared_error: 290793.4688\n",
      "Epoch 3798/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 285114.3750 - mean_squared_error: 285114.3750\n",
      "Epoch 3799/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300501.9375 - mean_squared_error: 300501.9375\n",
      "Epoch 3800/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291612.1875 - mean_squared_error: 291612.1875\n",
      "Epoch 3801/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293213.8750 - mean_squared_error: 293213.8750\n",
      "Epoch 3802/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292554.5312 - mean_squared_error: 292554.5312\n",
      "Epoch 3803/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295878.1875 - mean_squared_error: 295878.1875\n",
      "Epoch 3804/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288429.3750 - mean_squared_error: 288429.3750\n",
      "Epoch 3805/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293377.5312 - mean_squared_error: 293377.5312\n",
      "Epoch 3806/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296648.0625 - mean_squared_error: 296648.0625\n",
      "Epoch 3807/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296360.0938 - mean_squared_error: 296360.0938\n",
      "Epoch 3808/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287984.4062 - mean_squared_error: 287984.4062\n",
      "Epoch 3809/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292656.5312 - mean_squared_error: 292656.5312\n",
      "Epoch 3810/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292093.0000 - mean_squared_error: 292093.0000\n",
      "Epoch 3811/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298129.3750 - mean_squared_error: 298129.3438\n",
      "Epoch 3812/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288318.5000 - mean_squared_error: 288318.5000\n",
      "Epoch 3813/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295950.2812 - mean_squared_error: 295950.2812\n",
      "Epoch 3814/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292929.8438 - mean_squared_error: 292929.8438\n",
      "Epoch 3815/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294776.2500 - mean_squared_error: 294776.2500\n",
      "Epoch 3816/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297045.4062 - mean_squared_error: 297045.4062\n",
      "Epoch 3817/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298894.3438 - mean_squared_error: 298894.3438\n",
      "Epoch 3818/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295230.4375 - mean_squared_error: 295230.4375\n",
      "Epoch 3819/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296732.3750 - mean_squared_error: 296732.3750\n",
      "Epoch 3820/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296108.9062 - mean_squared_error: 296108.9062\n",
      "Epoch 3821/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294970.4375 - mean_squared_error: 294970.4375\n",
      "Epoch 3822/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293778.5000 - mean_squared_error: 293778.5000\n",
      "Epoch 3823/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300963.4688 - mean_squared_error: 300963.4688\n",
      "Epoch 3824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 292668.1562 - mean_squared_error: 292668.1562\n",
      "Epoch 3825/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292293.1562 - mean_squared_error: 292293.1562\n",
      "Epoch 3826/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289841.3438 - mean_squared_error: 289841.3125\n",
      "Epoch 3827/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285466.6562 - mean_squared_error: 285466.6562\n",
      "Epoch 3828/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295551.0938 - mean_squared_error: 295551.1562\n",
      "Epoch 3829/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304944.9688 - mean_squared_error: 304944.9688\n",
      "Epoch 3830/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 285526.6250 - mean_squared_error: 285526.6250\n",
      "Epoch 3831/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297758.6875 - mean_squared_error: 297758.6875\n",
      "Epoch 3832/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295687.1875 - mean_squared_error: 295687.1875\n",
      "Epoch 3833/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295715.6250 - mean_squared_error: 295715.6250\n",
      "Epoch 3834/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297263.5312 - mean_squared_error: 297263.5312\n",
      "Epoch 3835/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292632.0000 - mean_squared_error: 292632.0000\n",
      "Epoch 3836/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302586.3750 - mean_squared_error: 302586.3750\n",
      "Epoch 3837/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 290118.6562 - mean_squared_error: 290118.6562\n",
      "Epoch 3838/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290323.8750 - mean_squared_error: 290323.8750\n",
      "Epoch 3839/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294241.8438 - mean_squared_error: 294241.8438\n",
      "Epoch 3840/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299302.3125 - mean_squared_error: 299302.3125\n",
      "Epoch 3841/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296408.9688 - mean_squared_error: 296408.9688\n",
      "Epoch 3842/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302754.1562 - mean_squared_error: 302754.1562\n",
      "Epoch 3843/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294530.8125 - mean_squared_error: 294530.8125\n",
      "Epoch 3844/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298095.7812 - mean_squared_error: 298095.7812\n",
      "Epoch 3845/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295249.5938 - mean_squared_error: 295249.5938\n",
      "Epoch 3846/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292290.7500 - mean_squared_error: 292290.7500\n",
      "Epoch 3847/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296921.8750 - mean_squared_error: 296921.8750\n",
      "Epoch 3848/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303925.7812 - mean_squared_error: 303925.7812\n",
      "Epoch 3849/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292681.0000 - mean_squared_error: 292681.0000\n",
      "Epoch 3850/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295470.4375 - mean_squared_error: 295470.4375\n",
      "Epoch 3851/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299987.4688 - mean_squared_error: 299987.4688\n",
      "Epoch 3852/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293862.9062 - mean_squared_error: 293862.9062\n",
      "Epoch 3853/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295119.9062 - mean_squared_error: 295119.9062\n",
      "Epoch 3854/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291321.8750 - mean_squared_error: 291321.8750\n",
      "Epoch 3855/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294184.1562 - mean_squared_error: 294184.1562\n",
      "Epoch 3856/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291791.2188 - mean_squared_error: 291791.2188\n",
      "Epoch 3857/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289870.8438 - mean_squared_error: 289870.8438\n",
      "Epoch 3858/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294924.4375 - mean_squared_error: 294924.4375\n",
      "Epoch 3859/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293777.0938 - mean_squared_error: 293777.0938\n",
      "Epoch 3860/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294605.4688 - mean_squared_error: 294605.4688\n",
      "Epoch 3861/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296835.7500 - mean_squared_error: 296835.7812\n",
      "Epoch 3862/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291755.3125 - mean_squared_error: 291755.3125\n",
      "Epoch 3863/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293087.3125 - mean_squared_error: 293087.3125\n",
      "Epoch 3864/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295798.2188 - mean_squared_error: 295798.2188\n",
      "Epoch 3865/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295185.4688 - mean_squared_error: 295185.4688\n",
      "Epoch 3866/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296540.3750 - mean_squared_error: 296540.3750\n",
      "Epoch 3867/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294763.6562 - mean_squared_error: 294763.6562\n",
      "Epoch 3868/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296485.2500 - mean_squared_error: 296485.2500\n",
      "Epoch 3869/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295752.5938 - mean_squared_error: 295752.5938\n",
      "Epoch 3870/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293224.7188 - mean_squared_error: 293224.7188\n",
      "Epoch 3871/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293750.2812 - mean_squared_error: 293750.2812\n",
      "Epoch 3872/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292615.8438 - mean_squared_error: 292615.8438\n",
      "Epoch 3873/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296921.9375 - mean_squared_error: 296921.9375\n",
      "Epoch 3874/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296977.8125 - mean_squared_error: 296977.8125\n",
      "Epoch 3875/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290572.3750 - mean_squared_error: 290572.3750\n",
      "Epoch 3876/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297631.4375 - mean_squared_error: 297631.4375\n",
      "Epoch 3877/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291579.7812 - mean_squared_error: 291579.8438\n",
      "Epoch 3878/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290456.5000 - mean_squared_error: 290456.4688\n",
      "Epoch 3879/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291293.8438 - mean_squared_error: 291293.8438\n",
      "Epoch 3880/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297249.9062 - mean_squared_error: 297249.9062\n",
      "Epoch 3881/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292344.4062 - mean_squared_error: 292344.4062\n",
      "Epoch 3882/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295623.6875 - mean_squared_error: 295623.6875\n",
      "Epoch 3883/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295818.1250 - mean_squared_error: 295818.1250\n",
      "Epoch 3884/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296966.0312 - mean_squared_error: 296966.0312\n",
      "Epoch 3885/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291360.5000 - mean_squared_error: 291360.5000\n",
      "Epoch 3886/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290276.4375 - mean_squared_error: 290276.4375\n",
      "Epoch 3887/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295366.5625 - mean_squared_error: 295366.5625\n",
      "Epoch 3888/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289779.4688 - mean_squared_error: 289779.4688\n",
      "Epoch 3889/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288589.2500 - mean_squared_error: 288589.2500\n",
      "Epoch 3890/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297824.7188 - mean_squared_error: 297824.7188\n",
      "Epoch 3891/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296422.6875 - mean_squared_error: 296422.6875\n",
      "Epoch 3892/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300377.5625 - mean_squared_error: 300377.5625\n",
      "Epoch 3893/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291708.3125 - mean_squared_error: 291708.3125\n",
      "Epoch 3894/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302354.4062 - mean_squared_error: 302354.4062\n",
      "Epoch 3895/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296098.5312 - mean_squared_error: 296098.5625\n",
      "Epoch 3896/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288776.0312 - mean_squared_error: 288776.0312\n",
      "Epoch 3897/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298123.3125 - mean_squared_error: 298123.3125\n",
      "Epoch 3898/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298343.6562 - mean_squared_error: 298343.6250\n",
      "Epoch 3899/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292560.1875 - mean_squared_error: 292560.1875\n",
      "Epoch 3900/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296526.0625 - mean_squared_error: 296526.0625\n",
      "Epoch 3901/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298700.6250 - mean_squared_error: 298700.6250\n",
      "Epoch 3902/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296030.8438 - mean_squared_error: 296030.8438\n",
      "Epoch 3903/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292677.1250 - mean_squared_error: 292677.1250\n",
      "Epoch 3904/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289660.7188 - mean_squared_error: 289660.7188\n",
      "Epoch 3905/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289114.3750 - mean_squared_error: 289114.3750\n",
      "Epoch 3906/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294868.9062 - mean_squared_error: 294868.9062\n",
      "Epoch 3907/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297867.8125 - mean_squared_error: 297867.8125\n",
      "Epoch 3908/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292136.1250 - mean_squared_error: 292136.1250\n",
      "Epoch 3909/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291135.7500 - mean_squared_error: 291135.7500\n",
      "Epoch 3910/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289029.3750 - mean_squared_error: 289029.3750\n",
      "Epoch 3911/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287700.9688 - mean_squared_error: 287700.9688\n",
      "Epoch 3912/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298565.7188 - mean_squared_error: 298565.7188\n",
      "Epoch 3913/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302041.7188 - mean_squared_error: 302041.7188\n",
      "Epoch 3914/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291673.8125 - mean_squared_error: 291673.8125\n",
      "Epoch 3915/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287951.0938 - mean_squared_error: 287951.0938\n",
      "Epoch 3916/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299391.2188 - mean_squared_error: 299391.2188\n",
      "Epoch 3917/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290635.4062 - mean_squared_error: 290635.4062\n",
      "Epoch 3918/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294493.4688 - mean_squared_error: 294493.4688\n",
      "Epoch 3919/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 297739.9688 - mean_squared_error: 297739.9688\n",
      "Epoch 3920/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295661.4375 - mean_squared_error: 295661.4375\n",
      "Epoch 3921/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283067.7500 - mean_squared_error: 283067.7500\n",
      "Epoch 3922/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300280.5938 - mean_squared_error: 300280.5938\n",
      "Epoch 3923/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288527.4688 - mean_squared_error: 288527.4688\n",
      "Epoch 3924/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284820.4062 - mean_squared_error: 284820.3750\n",
      "Epoch 3925/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283012.9688 - mean_squared_error: 283012.9688\n",
      "Epoch 3926/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 282158.5312 - mean_squared_error: 282158.5312\n",
      "Epoch 3927/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 281603.9375 - mean_squared_error: 281603.9688\n",
      "Epoch 3928/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283916.6250 - mean_squared_error: 283916.6250\n",
      "Epoch 3929/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 308965.9375 - mean_squared_error: 308965.9375\n",
      "Epoch 3930/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290108.1562 - mean_squared_error: 290108.1562\n",
      "Epoch 3931/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295114.5625 - mean_squared_error: 295114.5625\n",
      "Epoch 3932/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294905.1875 - mean_squared_error: 294905.1875\n",
      "Epoch 3933/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301207.9688 - mean_squared_error: 301207.9688\n",
      "Epoch 3934/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300771.8438 - mean_squared_error: 300771.9062\n",
      "Epoch 3935/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306432.9062 - mean_squared_error: 306432.9062\n",
      "Epoch 3936/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295019.0625 - mean_squared_error: 295019.0625\n",
      "Epoch 3937/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300204.3125 - mean_squared_error: 300204.3125\n",
      "Epoch 3938/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299773.7188 - mean_squared_error: 299773.6875\n",
      "Epoch 3939/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296068.4375 - mean_squared_error: 296068.4375\n",
      "Epoch 3940/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293970.8125 - mean_squared_error: 293970.7812\n",
      "Epoch 3941/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290894.8438 - mean_squared_error: 290894.8438\n",
      "Epoch 3942/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 295454.3750 - mean_squared_error: 295454.3750\n",
      "Epoch 3943/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298012.7812 - mean_squared_error: 298012.7812\n",
      "Epoch 3944/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295210.8125 - mean_squared_error: 295210.8125\n",
      "Epoch 3945/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293666.0000 - mean_squared_error: 293666.0000\n",
      "Epoch 3946/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298453.6250 - mean_squared_error: 298453.6250\n",
      "Epoch 3947/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288991.5625 - mean_squared_error: 288991.5625\n",
      "Epoch 3948/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302730.5000 - mean_squared_error: 302730.5000\n",
      "Epoch 3949/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297470.6562 - mean_squared_error: 297470.6562\n",
      "Epoch 3950/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292811.2500 - mean_squared_error: 292811.2500\n",
      "Epoch 3951/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287224.1250 - mean_squared_error: 287224.1250\n",
      "Epoch 3952/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298962.7188 - mean_squared_error: 298962.7188\n",
      "Epoch 3953/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293338.3125 - mean_squared_error: 293338.3125\n",
      "Epoch 3954/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293872.1875 - mean_squared_error: 293872.1875\n",
      "Epoch 3955/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298859.4062 - mean_squared_error: 298859.4062\n",
      "Epoch 3956/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 296843.6562 - mean_squared_error: 296843.6562\n",
      "Epoch 3957/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297285.0938 - mean_squared_error: 297285.0938\n",
      "Epoch 3958/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304095.2500 - mean_squared_error: 304095.2500\n",
      "Epoch 3959/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305005.0625 - mean_squared_error: 305005.0625\n",
      "Epoch 3960/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296652.3438 - mean_squared_error: 296652.3438\n",
      "Epoch 3961/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299933.9062 - mean_squared_error: 299933.9062\n",
      "Epoch 3962/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299810.9688 - mean_squared_error: 299810.9688\n",
      "Epoch 3963/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300009.6875 - mean_squared_error: 300009.6875\n",
      "Epoch 3964/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 293398.5938 - mean_squared_error: 293398.5938\n",
      "Epoch 3965/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302673.0625 - mean_squared_error: 302673.0625\n",
      "Epoch 3966/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296051.6250 - mean_squared_error: 296051.6250\n",
      "Epoch 3967/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297671.4062 - mean_squared_error: 297671.4062\n",
      "Epoch 3968/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299125.3125 - mean_squared_error: 299125.3125\n",
      "Epoch 3969/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297215.5312 - mean_squared_error: 297215.5000\n",
      "Epoch 3970/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289756.0000 - mean_squared_error: 289756.0000\n",
      "Epoch 3971/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291292.4062 - mean_squared_error: 291292.4062\n",
      "Epoch 3972/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296660.3750 - mean_squared_error: 296660.3750\n",
      "Epoch 3973/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295580.7812 - mean_squared_error: 295580.7812\n",
      "Epoch 3974/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292946.7188 - mean_squared_error: 292946.7188\n",
      "Epoch 3975/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293734.4062 - mean_squared_error: 293734.4062\n",
      "Epoch 3976/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301233.8438 - mean_squared_error: 301233.8750\n",
      "Epoch 3977/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298920.3750 - mean_squared_error: 298920.3750\n",
      "Epoch 3978/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298443.6250 - mean_squared_error: 298443.6250\n",
      "Epoch 3979/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 310407.7188 - mean_squared_error: 310407.7188\n",
      "Epoch 3980/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296328.6875 - mean_squared_error: 296328.6875\n",
      "Epoch 3981/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290723.3750 - mean_squared_error: 290723.3750\n",
      "Epoch 3982/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302162.0938 - mean_squared_error: 302162.0938\n",
      "Epoch 3983/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 305441.8125 - mean_squared_error: 305441.8125\n",
      "Epoch 3984/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297491.2500 - mean_squared_error: 297491.2500\n",
      "Epoch 3985/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290838.4688 - mean_squared_error: 290838.4688\n",
      "Epoch 3986/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 300814.6250 - mean_squared_error: 300814.5938\n",
      "Epoch 3987/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304822.1875 - mean_squared_error: 304822.1875\n",
      "Epoch 3988/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293261.8125 - mean_squared_error: 293261.8125\n",
      "Epoch 3989/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294080.5000 - mean_squared_error: 294080.5000\n",
      "Epoch 3990/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287839.0312 - mean_squared_error: 287839.0312\n",
      "Epoch 3991/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297745.5312 - mean_squared_error: 297745.5312\n",
      "Epoch 3992/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295807.8750 - mean_squared_error: 295807.8750\n",
      "Epoch 3993/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297252.1875 - mean_squared_error: 297252.1875\n",
      "Epoch 3994/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294626.6250 - mean_squared_error: 294626.6250\n",
      "Epoch 3995/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301711.2812 - mean_squared_error: 301711.2812\n",
      "Epoch 3996/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294801.8750 - mean_squared_error: 294801.8750\n",
      "Epoch 3997/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296495.1250 - mean_squared_error: 296495.1250\n",
      "Epoch 3998/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301763.1562 - mean_squared_error: 301763.1250\n",
      "Epoch 3999/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294370.5625 - mean_squared_error: 294370.5625\n",
      "Epoch 4000/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296677.3125 - mean_squared_error: 296677.3125\n",
      "Epoch 4001/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295849.2812 - mean_squared_error: 295849.2812\n",
      "Epoch 4002/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295687.6562 - mean_squared_error: 295687.6562\n",
      "Epoch 4003/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299181.2812 - mean_squared_error: 299181.2812\n",
      "Epoch 4004/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294453.8438 - mean_squared_error: 294453.8438\n",
      "Epoch 4005/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290594.1875 - mean_squared_error: 290594.1875\n",
      "Epoch 4006/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297016.7812 - mean_squared_error: 297016.7812\n",
      "Epoch 4007/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291381.9688 - mean_squared_error: 291381.9688\n",
      "Epoch 4008/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298140.5000 - mean_squared_error: 298140.5000\n",
      "Epoch 4009/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298160.3750 - mean_squared_error: 298160.3750\n",
      "Epoch 4010/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298420.0312 - mean_squared_error: 298420.0312\n",
      "Epoch 4011/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299818.9062 - mean_squared_error: 299818.9062\n",
      "Epoch 4012/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294080.7188 - mean_squared_error: 294080.7188\n",
      "Epoch 4013/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297260.7500 - mean_squared_error: 297260.7500\n",
      "Epoch 4014/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293814.6875 - mean_squared_error: 293814.6875\n",
      "Epoch 4015/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305678.1250 - mean_squared_error: 305678.1250\n",
      "Epoch 4016/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299658.7188 - mean_squared_error: 299658.7500\n",
      "Epoch 4017/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294458.0312 - mean_squared_error: 294458.0312\n",
      "Epoch 4018/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293728.9375 - mean_squared_error: 293728.9375\n",
      "Epoch 4019/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294449.0938 - mean_squared_error: 294449.0938\n",
      "Epoch 4020/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293484.9688 - mean_squared_error: 293484.9375\n",
      "Epoch 4021/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294481.3438 - mean_squared_error: 294481.3438\n",
      "Epoch 4022/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306171.3750 - mean_squared_error: 306171.3750\n",
      "Epoch 4023/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299780.3750 - mean_squared_error: 299780.3750\n",
      "Epoch 4024/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298907.8750 - mean_squared_error: 298907.9062\n",
      "Epoch 4025/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298155.5625 - mean_squared_error: 298155.5625\n",
      "Epoch 4026/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292785.3125 - mean_squared_error: 292785.3125\n",
      "Epoch 4027/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304903.6250 - mean_squared_error: 304903.6250\n",
      "Epoch 4028/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299473.6562 - mean_squared_error: 299473.6562\n",
      "Epoch 4029/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299912.5938 - mean_squared_error: 299912.5938\n",
      "Epoch 4030/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299517.2188 - mean_squared_error: 299517.2188\n",
      "Epoch 4031/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299029.0000 - mean_squared_error: 299028.9688\n",
      "Epoch 4032/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303477.0938 - mean_squared_error: 303477.0938\n",
      "Epoch 4033/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300755.1250 - mean_squared_error: 300755.1250\n",
      "Epoch 4034/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301791.8125 - mean_squared_error: 301791.8125\n",
      "Epoch 4035/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302718.0938 - mean_squared_error: 302718.0938\n",
      "Epoch 4036/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293143.3750 - mean_squared_error: 293143.3750\n",
      "Epoch 4037/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296946.7188 - mean_squared_error: 296946.7188\n",
      "Epoch 4038/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291965.6562 - mean_squared_error: 291965.6562\n",
      "Epoch 4039/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302086.6875 - mean_squared_error: 302086.6875\n",
      "Epoch 4040/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308787.3750 - mean_squared_error: 308787.3750\n",
      "Epoch 4041/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296185.0938 - mean_squared_error: 296185.0938\n",
      "Epoch 4042/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294098.5938 - mean_squared_error: 294098.5938\n",
      "Epoch 4043/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295692.7188 - mean_squared_error: 295692.7188\n",
      "Epoch 4044/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292177.3125 - mean_squared_error: 292177.3125\n",
      "Epoch 4045/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300982.3750 - mean_squared_error: 300982.3750\n",
      "Epoch 4046/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287121.1875 - mean_squared_error: 287121.1875\n",
      "Epoch 4047/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287526.3750 - mean_squared_error: 287526.3750\n",
      "Epoch 4048/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297212.0000 - mean_squared_error: 297212.0000\n",
      "Epoch 4049/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291340.0938 - mean_squared_error: 291340.1250\n",
      "Epoch 4050/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299980.7188 - mean_squared_error: 299980.7188\n",
      "Epoch 4051/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303855.7188 - mean_squared_error: 303855.7188\n",
      "Epoch 4052/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293956.5938 - mean_squared_error: 293956.5938\n",
      "Epoch 4053/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293199.5312 - mean_squared_error: 293199.5312\n",
      "Epoch 4054/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291904.2500 - mean_squared_error: 291904.2500\n",
      "Epoch 4055/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301524.3438 - mean_squared_error: 301524.3125\n",
      "Epoch 4056/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290131.4375 - mean_squared_error: 290131.4375\n",
      "Epoch 4057/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299103.6875 - mean_squared_error: 299103.6875\n",
      "Epoch 4058/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294800.0625 - mean_squared_error: 294800.0625\n",
      "Epoch 4059/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290709.7188 - mean_squared_error: 290709.7188\n",
      "Epoch 4060/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299467.4375 - mean_squared_error: 299467.4375\n",
      "Epoch 4061/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296514.4688 - mean_squared_error: 296514.4688\n",
      "Epoch 4062/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298748.5938 - mean_squared_error: 298748.5625\n",
      "Epoch 4063/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299814.6562 - mean_squared_error: 299814.6562\n",
      "Epoch 4064/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297239.8438 - mean_squared_error: 297239.8438\n",
      "Epoch 4065/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301262.1250 - mean_squared_error: 301262.1250\n",
      "Epoch 4066/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291203.2500 - mean_squared_error: 291203.2188\n",
      "Epoch 4067/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301920.4375 - mean_squared_error: 301920.4375\n",
      "Epoch 4068/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298312.1562 - mean_squared_error: 298312.1562\n",
      "Epoch 4069/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295415.0312 - mean_squared_error: 295415.0312\n",
      "Epoch 4070/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283257.8125 - mean_squared_error: 283257.8125\n",
      "Epoch 4071/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291219.9062 - mean_squared_error: 291219.9062\n",
      "Epoch 4072/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301653.5000 - mean_squared_error: 301653.5000\n",
      "Epoch 4073/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289544.1250 - mean_squared_error: 289544.1250\n",
      "Epoch 4074/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301546.7188 - mean_squared_error: 301546.7188\n",
      "Epoch 4075/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296058.5312 - mean_squared_error: 296058.5312\n",
      "Epoch 4076/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296126.5938 - mean_squared_error: 296126.5938\n",
      "Epoch 4077/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298803.9062 - mean_squared_error: 298803.9062\n",
      "Epoch 4078/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303238.4688 - mean_squared_error: 303238.4688\n",
      "Epoch 4079/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298929.0938 - mean_squared_error: 298929.0938\n",
      "Epoch 4080/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293685.4062 - mean_squared_error: 293685.4062\n",
      "Epoch 4081/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288843.1875 - mean_squared_error: 288843.1875\n",
      "Epoch 4082/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304826.9688 - mean_squared_error: 304826.9688\n",
      "Epoch 4083/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299774.3438 - mean_squared_error: 299774.3750\n",
      "Epoch 4084/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 305311.0938 - mean_squared_error: 305311.0938\n",
      "Epoch 4085/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291970.3750 - mean_squared_error: 291970.3750\n",
      "Epoch 4086/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292446.9375 - mean_squared_error: 292446.9375\n",
      "Epoch 4087/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301335.1562 - mean_squared_error: 301335.1875\n",
      "Epoch 4088/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 300380.3125 - mean_squared_error: 300380.3125\n",
      "Epoch 4089/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294535.7812 - mean_squared_error: 294535.7812\n",
      "Epoch 4090/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293103.1875 - mean_squared_error: 293103.1875\n",
      "Epoch 4091/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291807.7188 - mean_squared_error: 291807.7188\n",
      "Epoch 4092/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298988.4062 - mean_squared_error: 298988.4062\n",
      "Epoch 4093/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301376.2500 - mean_squared_error: 301376.2500\n",
      "Epoch 4094/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300306.5938 - mean_squared_error: 300306.5938\n",
      "Epoch 4095/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292277.6875 - mean_squared_error: 292277.6875\n",
      "Epoch 4096/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298081.2500 - mean_squared_error: 298081.2500\n",
      "Epoch 4097/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292865.1875 - mean_squared_error: 292865.1875\n",
      "Epoch 4098/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297105.4688 - mean_squared_error: 297105.5000\n",
      "Epoch 4099/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295330.3438 - mean_squared_error: 295330.3438\n",
      "Epoch 4100/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306555.5938 - mean_squared_error: 306555.5938\n",
      "Epoch 4101/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295296.6250 - mean_squared_error: 295296.6250\n",
      "Epoch 4102/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292245.3438 - mean_squared_error: 292245.3438\n",
      "Epoch 4103/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298293.3438 - mean_squared_error: 298293.3438\n",
      "Epoch 4104/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298652.0625 - mean_squared_error: 298652.0625\n",
      "Epoch 4105/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285741.8438 - mean_squared_error: 285741.8438\n",
      "Epoch 4106/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295439.5312 - mean_squared_error: 295439.5312\n",
      "Epoch 4107/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304817.2500 - mean_squared_error: 304817.2500\n",
      "Epoch 4108/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296927.7812 - mean_squared_error: 296927.7812\n",
      "Epoch 4109/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296733.3438 - mean_squared_error: 296733.3438\n",
      "Epoch 4110/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296431.5312 - mean_squared_error: 296431.5312\n",
      "Epoch 4111/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297460.1562 - mean_squared_error: 297460.1562\n",
      "Epoch 4112/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 287478.1562 - mean_squared_error: 287478.1562\n",
      "Epoch 4113/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302395.2812 - mean_squared_error: 302395.2812\n",
      "Epoch 4114/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297913.1875 - mean_squared_error: 297913.1875\n",
      "Epoch 4115/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291934.7188 - mean_squared_error: 291934.7188\n",
      "Epoch 4116/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303806.7812 - mean_squared_error: 303806.7812\n",
      "Epoch 4117/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299789.8125 - mean_squared_error: 299789.8125\n",
      "Epoch 4118/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293154.5938 - mean_squared_error: 293154.5938\n",
      "Epoch 4119/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295817.0938 - mean_squared_error: 295817.0938\n",
      "Epoch 4120/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295116.1250 - mean_squared_error: 295116.1250\n",
      "Epoch 4121/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306454.4688 - mean_squared_error: 306454.4688\n",
      "Epoch 4122/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 306236.6875 - mean_squared_error: 306236.6875\n",
      "Epoch 4123/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301812.5000 - mean_squared_error: 301812.5000\n",
      "Epoch 4124/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 292130.5312 - mean_squared_error: 292130.5312\n",
      "Epoch 4125/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301627.6875 - mean_squared_error: 301627.6875\n",
      "Epoch 4126/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294344.6250 - mean_squared_error: 294344.6250\n",
      "Epoch 4127/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296344.2812 - mean_squared_error: 296344.2812\n",
      "Epoch 4128/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300596.4375 - mean_squared_error: 300596.4375\n",
      "Epoch 4129/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 297465.2812 - mean_squared_error: 297465.2812\n",
      "Epoch 4130/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300266.2188 - mean_squared_error: 300266.2188\n",
      "Epoch 4131/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303191.4375 - mean_squared_error: 303191.4375\n",
      "Epoch 4132/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287938.7188 - mean_squared_error: 287938.7188\n",
      "Epoch 4133/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301329.3750 - mean_squared_error: 301329.3750\n",
      "Epoch 4134/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303272.5312 - mean_squared_error: 303272.5000\n",
      "Epoch 4135/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291834.9062 - mean_squared_error: 291834.9062\n",
      "Epoch 4136/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293856.0000 - mean_squared_error: 293856.0000\n",
      "Epoch 4137/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295198.6562 - mean_squared_error: 295198.6562\n",
      "Epoch 4138/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293758.4688 - mean_squared_error: 293758.4688\n",
      "Epoch 4139/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301036.2500 - mean_squared_error: 301036.2500\n",
      "Epoch 4140/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301993.9688 - mean_squared_error: 301993.9688\n",
      "Epoch 4141/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292488.5625 - mean_squared_error: 292488.5625\n",
      "Epoch 4142/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301018.7812 - mean_squared_error: 301018.7812\n",
      "Epoch 4143/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300309.6875 - mean_squared_error: 300309.6562\n",
      "Epoch 4144/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294018.7188 - mean_squared_error: 294018.7188\n",
      "Epoch 4145/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301227.5000 - mean_squared_error: 301227.5000\n",
      "Epoch 4146/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300222.5625 - mean_squared_error: 300222.5625\n",
      "Epoch 4147/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301366.6875 - mean_squared_error: 301366.6875\n",
      "Epoch 4148/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301044.0312 - mean_squared_error: 301044.0312\n",
      "Epoch 4149/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297838.2500 - mean_squared_error: 297838.2500\n",
      "Epoch 4150/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303852.3750 - mean_squared_error: 303852.3750\n",
      "Epoch 4151/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298371.5938 - mean_squared_error: 298371.5938\n",
      "Epoch 4152/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296297.3125 - mean_squared_error: 296297.3125\n",
      "Epoch 4153/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296495.7188 - mean_squared_error: 296495.7188\n",
      "Epoch 4154/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296852.2812 - mean_squared_error: 296852.2812\n",
      "Epoch 4155/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290664.5625 - mean_squared_error: 290664.5625\n",
      "Epoch 4156/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302812.5938 - mean_squared_error: 302812.5938\n",
      "Epoch 4157/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289490.7812 - mean_squared_error: 289490.7812\n",
      "Epoch 4158/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301545.3438 - mean_squared_error: 301545.3438\n",
      "Epoch 4159/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293138.0000 - mean_squared_error: 293138.0000\n",
      "Epoch 4160/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299972.3750 - mean_squared_error: 299972.3750\n",
      "Epoch 4161/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296911.7188 - mean_squared_error: 296911.7188\n",
      "Epoch 4162/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293580.0312 - mean_squared_error: 293580.0312\n",
      "Epoch 4163/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294274.3438 - mean_squared_error: 294274.3438\n",
      "Epoch 4164/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304263.4062 - mean_squared_error: 304263.4062\n",
      "Epoch 4165/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297624.0938 - mean_squared_error: 297624.0938\n",
      "Epoch 4166/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287696.0312 - mean_squared_error: 287696.0312\n",
      "Epoch 4167/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300249.1250 - mean_squared_error: 300249.1250\n",
      "Epoch 4168/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293778.0000 - mean_squared_error: 293778.0000\n",
      "Epoch 4169/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299564.0938 - mean_squared_error: 299564.0938\n",
      "Epoch 4170/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300717.1875 - mean_squared_error: 300717.1875\n",
      "Epoch 4171/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304528.0938 - mean_squared_error: 304528.0938\n",
      "Epoch 4172/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294927.7500 - mean_squared_error: 294927.7500\n",
      "Epoch 4173/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299076.1250 - mean_squared_error: 299076.1250\n",
      "Epoch 4174/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296395.7500 - mean_squared_error: 296395.7500\n",
      "Epoch 4175/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299968.8125 - mean_squared_error: 299968.8125\n",
      "Epoch 4176/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301211.0938 - mean_squared_error: 301211.0938\n",
      "Epoch 4177/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300741.8125 - mean_squared_error: 300741.8125\n",
      "Epoch 4178/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295620.2500 - mean_squared_error: 295620.2500\n",
      "Epoch 4179/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302226.5625 - mean_squared_error: 302226.5625\n",
      "Epoch 4180/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301017.1875 - mean_squared_error: 301017.1562\n",
      "Epoch 4181/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292820.2188 - mean_squared_error: 292820.2188\n",
      "Epoch 4182/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300009.4688 - mean_squared_error: 300009.4688\n",
      "Epoch 4183/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300898.8125 - mean_squared_error: 300898.8125\n",
      "Epoch 4184/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291686.6562 - mean_squared_error: 291686.6562\n",
      "Epoch 4185/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289394.7188 - mean_squared_error: 289394.7188\n",
      "Epoch 4186/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300177.9062 - mean_squared_error: 300177.9062\n",
      "Epoch 4187/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291981.8750 - mean_squared_error: 291981.9062\n",
      "Epoch 4188/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298354.8125 - mean_squared_error: 298354.8438\n",
      "Epoch 4189/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295122.9375 - mean_squared_error: 295122.9375\n",
      "Epoch 4190/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306520.0938 - mean_squared_error: 306520.0938\n",
      "Epoch 4191/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295875.6250 - mean_squared_error: 295875.6250\n",
      "Epoch 4192/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302061.4375 - mean_squared_error: 302061.4375\n",
      "Epoch 4193/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295390.8750 - mean_squared_error: 295390.8750\n",
      "Epoch 4194/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299550.5938 - mean_squared_error: 299550.5938\n",
      "Epoch 4195/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299108.2812 - mean_squared_error: 299108.2812\n",
      "Epoch 4196/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308457.6562 - mean_squared_error: 308457.6562\n",
      "Epoch 4197/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290015.1875 - mean_squared_error: 290015.1875\n",
      "Epoch 4198/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294777.2188 - mean_squared_error: 294777.2188\n",
      "Epoch 4199/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290200.1250 - mean_squared_error: 290200.1250\n",
      "Epoch 4200/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300155.3438 - mean_squared_error: 300155.3438\n",
      "Epoch 4201/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297276.6250 - mean_squared_error: 297276.6250\n",
      "Epoch 4202/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304483.2188 - mean_squared_error: 304483.2188\n",
      "Epoch 4203/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 307402.4688 - mean_squared_error: 307402.4688\n",
      "Epoch 4204/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291083.6875 - mean_squared_error: 291083.6875\n",
      "Epoch 4205/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292111.4062 - mean_squared_error: 292111.4375\n",
      "Epoch 4206/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299269.8750 - mean_squared_error: 299269.8750\n",
      "Epoch 4207/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293378.7500 - mean_squared_error: 293378.7500\n",
      "Epoch 4208/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298926.8750 - mean_squared_error: 298926.8750\n",
      "Epoch 4209/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306943.1875 - mean_squared_error: 306943.1875\n",
      "Epoch 4210/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301688.2188 - mean_squared_error: 301688.2188\n",
      "Epoch 4211/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303996.8125 - mean_squared_error: 303996.8125\n",
      "Epoch 4212/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304162.7500 - mean_squared_error: 304162.7500\n",
      "Epoch 4213/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299353.1562 - mean_squared_error: 299353.1562\n",
      "Epoch 4214/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301883.9062 - mean_squared_error: 301883.9062\n",
      "Epoch 4215/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297848.6562 - mean_squared_error: 297848.6562\n",
      "Epoch 4216/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306832.1250 - mean_squared_error: 306832.1250\n",
      "Epoch 4217/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293452.4688 - mean_squared_error: 293452.4688\n",
      "Epoch 4218/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302552.2812 - mean_squared_error: 302552.2812\n",
      "Epoch 4219/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303182.4688 - mean_squared_error: 303182.4688\n",
      "Epoch 4220/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 290585.0000 - mean_squared_error: 290585.0312\n",
      "Epoch 4221/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290699.3750 - mean_squared_error: 290699.3750\n",
      "Epoch 4222/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291199.9688 - mean_squared_error: 291199.9375\n",
      "Epoch 4223/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299238.8750 - mean_squared_error: 299238.8750\n",
      "Epoch 4224/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293623.4375 - mean_squared_error: 293623.4375\n",
      "Epoch 4225/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298198.1875 - mean_squared_error: 298198.1875\n",
      "Epoch 4226/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292143.3750 - mean_squared_error: 292143.3750\n",
      "Epoch 4227/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302639.1875 - mean_squared_error: 302639.1875\n",
      "Epoch 4228/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301241.1562 - mean_squared_error: 301241.1562\n",
      "Epoch 4229/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293497.4062 - mean_squared_error: 293497.4062\n",
      "Epoch 4230/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295157.3438 - mean_squared_error: 295157.3125\n",
      "Epoch 4231/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301886.6562 - mean_squared_error: 301886.6562\n",
      "Epoch 4232/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303020.5938 - mean_squared_error: 303020.6250\n",
      "Epoch 4233/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293701.0938 - mean_squared_error: 293701.0938\n",
      "Epoch 4234/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299401.0625 - mean_squared_error: 299401.0625\n",
      "Epoch 4235/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303228.6875 - mean_squared_error: 303228.6875\n",
      "Epoch 4236/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292916.4062 - mean_squared_error: 292916.4062\n",
      "Epoch 4237/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294888.7500 - mean_squared_error: 294888.7500\n",
      "Epoch 4238/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292353.1875 - mean_squared_error: 292353.1875\n",
      "Epoch 4239/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295202.5312 - mean_squared_error: 295202.5312\n",
      "Epoch 4240/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289861.6250 - mean_squared_error: 289861.6250\n",
      "Epoch 4241/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291459.9062 - mean_squared_error: 291459.9062\n",
      "Epoch 4242/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303473.0625 - mean_squared_error: 303473.0625\n",
      "Epoch 4243/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304058.9062 - mean_squared_error: 304058.9062\n",
      "Epoch 4244/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302717.4375 - mean_squared_error: 302717.4375\n",
      "Epoch 4245/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293317.5938 - mean_squared_error: 293317.5938\n",
      "Epoch 4246/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289520.3125 - mean_squared_error: 289520.3125\n",
      "Epoch 4247/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288200.0938 - mean_squared_error: 288200.0938\n",
      "Epoch 4248/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294031.2500 - mean_squared_error: 294031.2500\n",
      "Epoch 4249/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299883.7812 - mean_squared_error: 299883.7812\n",
      "Epoch 4250/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294056.0625 - mean_squared_error: 294056.0625\n",
      "Epoch 4251/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295252.2500 - mean_squared_error: 295252.2500\n",
      "Epoch 4252/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295676.6250 - mean_squared_error: 295676.6250\n",
      "Epoch 4253/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299470.2188 - mean_squared_error: 299470.2188\n",
      "Epoch 4254/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 295413.2500 - mean_squared_error: 295413.2500\n",
      "Epoch 4255/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297408.4375 - mean_squared_error: 297408.4375\n",
      "Epoch 4256/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289905.5312 - mean_squared_error: 289905.5312\n",
      "Epoch 4257/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292235.2500 - mean_squared_error: 292235.2500\n",
      "Epoch 4258/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297851.9688 - mean_squared_error: 297851.9688\n",
      "Epoch 4259/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299002.0938 - mean_squared_error: 299002.0938\n",
      "Epoch 4260/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296106.0312 - mean_squared_error: 296106.0000\n",
      "Epoch 4261/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296785.8438 - mean_squared_error: 296785.8750\n",
      "Epoch 4262/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298771.0938 - mean_squared_error: 298771.0938\n",
      "Epoch 4263/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299181.2188 - mean_squared_error: 299181.1875\n",
      "Epoch 4264/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297215.5312 - mean_squared_error: 297215.5312\n",
      "Epoch 4265/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299188.3125 - mean_squared_error: 299188.3125\n",
      "Epoch 4266/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295350.5000 - mean_squared_error: 295350.5000\n",
      "Epoch 4267/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297666.9062 - mean_squared_error: 297666.9062\n",
      "Epoch 4268/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299512.2188 - mean_squared_error: 299512.2188\n",
      "Epoch 4269/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290965.9062 - mean_squared_error: 290965.9062\n",
      "Epoch 4270/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297628.1250 - mean_squared_error: 297628.1250\n",
      "Epoch 4271/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297865.6562 - mean_squared_error: 297865.6562\n",
      "Epoch 4272/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291801.6875 - mean_squared_error: 291801.6875\n",
      "Epoch 4273/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296846.7812 - mean_squared_error: 296846.7812\n",
      "Epoch 4274/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291075.3750 - mean_squared_error: 291075.3750\n",
      "Epoch 4275/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300265.3438 - mean_squared_error: 300265.3438\n",
      "Epoch 4276/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295397.0000 - mean_squared_error: 295397.0000\n",
      "Epoch 4277/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296122.4062 - mean_squared_error: 296122.4062\n",
      "Epoch 4278/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300809.1562 - mean_squared_error: 300809.1562\n",
      "Epoch 4279/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294145.3125 - mean_squared_error: 294145.3125\n",
      "Epoch 4280/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293729.0938 - mean_squared_error: 293729.0938\n",
      "Epoch 4281/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293862.1250 - mean_squared_error: 293862.1250\n",
      "Epoch 4282/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296738.1875 - mean_squared_error: 296738.1875\n",
      "Epoch 4283/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295468.7812 - mean_squared_error: 295468.7812\n",
      "Epoch 4284/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300026.5312 - mean_squared_error: 300026.5312\n",
      "Epoch 4285/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301504.2812 - mean_squared_error: 301504.2812\n",
      "Epoch 4286/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296873.3438 - mean_squared_error: 296873.3438\n",
      "Epoch 4287/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297845.0938 - mean_squared_error: 297845.0938\n",
      "Epoch 4288/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289826.1875 - mean_squared_error: 289826.1875\n",
      "Epoch 4289/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297037.0312 - mean_squared_error: 297037.0312\n",
      "Epoch 4290/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290177.5312 - mean_squared_error: 290177.5312\n",
      "Epoch 4291/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300319.6875 - mean_squared_error: 300319.6875\n",
      "Epoch 4292/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297171.0938 - mean_squared_error: 297171.0938\n",
      "Epoch 4293/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298093.5312 - mean_squared_error: 298093.5312\n",
      "Epoch 4294/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 301229.5938 - mean_squared_error: 301229.5938\n",
      "Epoch 4295/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298901.1250 - mean_squared_error: 298901.1250\n",
      "Epoch 4296/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291596.5000 - mean_squared_error: 291596.5000\n",
      "Epoch 4297/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 281081.1562 - mean_squared_error: 281081.1562\n",
      "Epoch 4298/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288996.0938 - mean_squared_error: 288996.0938\n",
      "Epoch 4299/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 294554.1875 - mean_squared_error: 294554.1875\n",
      "Epoch 4300/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298591.0000 - mean_squared_error: 298591.0000\n",
      "Epoch 4301/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297705.7188 - mean_squared_error: 297705.7188\n",
      "Epoch 4302/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294073.7500 - mean_squared_error: 294073.8125\n",
      "Epoch 4303/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292351.6875 - mean_squared_error: 292351.6875\n",
      "Epoch 4304/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291252.5000 - mean_squared_error: 291252.5000\n",
      "Epoch 4305/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300015.0000 - mean_squared_error: 300014.9688\n",
      "Epoch 4306/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290338.3125 - mean_squared_error: 290338.3125\n",
      "Epoch 4307/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293472.4062 - mean_squared_error: 293472.3750\n",
      "Epoch 4308/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287904.7812 - mean_squared_error: 287904.7812\n",
      "Epoch 4309/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287504.0938 - mean_squared_error: 287504.0938\n",
      "Epoch 4310/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298435.4375 - mean_squared_error: 298435.4375\n",
      "Epoch 4311/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293738.0938 - mean_squared_error: 293738.0938\n",
      "Epoch 4312/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293770.6562 - mean_squared_error: 293770.6562\n",
      "Epoch 4313/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290391.5938 - mean_squared_error: 290391.5938\n",
      "Epoch 4314/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 282754.0625 - mean_squared_error: 282754.0625\n",
      "Epoch 4315/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296698.5312 - mean_squared_error: 296698.5312\n",
      "Epoch 4316/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294657.0312 - mean_squared_error: 294657.0312\n",
      "Epoch 4317/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 302517.7812 - mean_squared_error: 302517.7812\n",
      "Epoch 4318/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303654.0000 - mean_squared_error: 303654.0000\n",
      "Epoch 4319/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293338.5625 - mean_squared_error: 293338.5625\n",
      "Epoch 4320/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301123.5000 - mean_squared_error: 301123.5000\n",
      "Epoch 4321/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301041.0625 - mean_squared_error: 301041.0625\n",
      "Epoch 4322/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294317.3438 - mean_squared_error: 294317.3438\n",
      "Epoch 4323/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299401.2812 - mean_squared_error: 299401.2812\n",
      "Epoch 4324/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292456.5000 - mean_squared_error: 292456.5000\n",
      "Epoch 4325/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296035.9062 - mean_squared_error: 296035.9062\n",
      "Epoch 4326/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293220.1562 - mean_squared_error: 293220.1562\n",
      "Epoch 4327/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299673.9375 - mean_squared_error: 299673.9375\n",
      "Epoch 4328/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 297844.6250 - mean_squared_error: 297844.6250\n",
      "Epoch 4329/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294476.9375 - mean_squared_error: 294476.9375\n",
      "Epoch 4330/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293595.4062 - mean_squared_error: 293595.4062\n",
      "Epoch 4331/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304538.6875 - mean_squared_error: 304538.6875\n",
      "Epoch 4332/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291625.7500 - mean_squared_error: 291625.7500\n",
      "Epoch 4333/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300846.7500 - mean_squared_error: 300846.7500\n",
      "Epoch 4334/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299717.6250 - mean_squared_error: 299717.6250\n",
      "Epoch 4335/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293614.9375 - mean_squared_error: 293614.9375\n",
      "Epoch 4336/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304355.1875 - mean_squared_error: 304355.1875\n",
      "Epoch 4337/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289305.2812 - mean_squared_error: 289305.2812\n",
      "Epoch 4338/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300613.0938 - mean_squared_error: 300613.0938\n",
      "Epoch 4339/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295385.2500 - mean_squared_error: 295385.2812\n",
      "Epoch 4340/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297711.5312 - mean_squared_error: 297711.5312\n",
      "Epoch 4341/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299479.1875 - mean_squared_error: 299479.1875\n",
      "Epoch 4342/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290967.9375 - mean_squared_error: 290967.9375\n",
      "Epoch 4343/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295274.0000 - mean_squared_error: 295274.0000\n",
      "Epoch 4344/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298264.9375 - mean_squared_error: 298264.9375\n",
      "Epoch 4345/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291845.3750 - mean_squared_error: 291845.3750\n",
      "Epoch 4346/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296624.1875 - mean_squared_error: 296624.1875\n",
      "Epoch 4347/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290260.4375 - mean_squared_error: 290260.4375\n",
      "Epoch 4348/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298988.0000 - mean_squared_error: 298988.0000\n",
      "Epoch 4349/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294757.9062 - mean_squared_error: 294757.9062\n",
      "Epoch 4350/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299386.6562 - mean_squared_error: 299386.6562\n",
      "Epoch 4351/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296753.8125 - mean_squared_error: 296753.8125\n",
      "Epoch 4352/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 298610.5312 - mean_squared_error: 298610.5312\n",
      "Epoch 4353/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299635.8750 - mean_squared_error: 299635.8750\n",
      "Epoch 4354/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297768.5625 - mean_squared_error: 297768.5625\n",
      "Epoch 4355/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 286325.4375 - mean_squared_error: 286325.4375\n",
      "Epoch 4356/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 309150.1875 - mean_squared_error: 309150.1875\n",
      "Epoch 4357/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295747.5000 - mean_squared_error: 295747.5000\n",
      "Epoch 4358/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292477.0312 - mean_squared_error: 292477.0312\n",
      "Epoch 4359/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288869.8438 - mean_squared_error: 288869.8438\n",
      "Epoch 4360/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294656.0312 - mean_squared_error: 294656.0312\n",
      "Epoch 4361/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292862.1250 - mean_squared_error: 292862.1250\n",
      "Epoch 4362/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291844.9375 - mean_squared_error: 291844.9375\n",
      "Epoch 4363/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291777.7812 - mean_squared_error: 291777.7812\n",
      "Epoch 4364/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296465.9375 - mean_squared_error: 296465.9375\n",
      "Epoch 4365/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295341.8438 - mean_squared_error: 295341.8438\n",
      "Epoch 4366/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291319.1875 - mean_squared_error: 291319.1875\n",
      "Epoch 4367/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288696.6562 - mean_squared_error: 288696.6562\n",
      "Epoch 4368/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298817.4062 - mean_squared_error: 298817.4062\n",
      "Epoch 4369/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293087.8750 - mean_squared_error: 293087.8750\n",
      "Epoch 4370/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295426.0938 - mean_squared_error: 295426.1250\n",
      "Epoch 4371/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297790.7500 - mean_squared_error: 297790.7500\n",
      "Epoch 4372/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307945.9375 - mean_squared_error: 307945.9375\n",
      "Epoch 4373/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299887.7188 - mean_squared_error: 299887.7188\n",
      "Epoch 4374/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293218.4375 - mean_squared_error: 293218.4688\n",
      "Epoch 4375/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294106.0000 - mean_squared_error: 294106.0000\n",
      "Epoch 4376/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303017.2188 - mean_squared_error: 303017.2188\n",
      "Epoch 4377/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291475.1562 - mean_squared_error: 291475.1562\n",
      "Epoch 4378/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295675.5312 - mean_squared_error: 295675.5312\n",
      "Epoch 4379/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294419.7188 - mean_squared_error: 294419.6875\n",
      "Epoch 4380/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295798.6562 - mean_squared_error: 295798.6562\n",
      "Epoch 4381/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292783.5312 - mean_squared_error: 292783.5312\n",
      "Epoch 4382/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303441.4062 - mean_squared_error: 303441.4062\n",
      "Epoch 4383/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295028.7188 - mean_squared_error: 295028.7188\n",
      "Epoch 4384/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300984.2812 - mean_squared_error: 300984.2812\n",
      "Epoch 4385/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289538.8125 - mean_squared_error: 289538.8125\n",
      "Epoch 4386/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297686.9375 - mean_squared_error: 297686.9375\n",
      "Epoch 4387/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294800.6562 - mean_squared_error: 294800.6562\n",
      "Epoch 4388/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295537.3750 - mean_squared_error: 295537.3750\n",
      "Epoch 4389/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298957.0625 - mean_squared_error: 298957.0625\n",
      "Epoch 4390/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296738.1875 - mean_squared_error: 296738.1875\n",
      "Epoch 4391/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290315.8438 - mean_squared_error: 290315.8438\n",
      "Epoch 4392/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288898.5000 - mean_squared_error: 288898.5000\n",
      "Epoch 4393/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287501.8125 - mean_squared_error: 287501.8125\n",
      "Epoch 4394/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302544.4688 - mean_squared_error: 302544.4688\n",
      "Epoch 4395/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283867.3438 - mean_squared_error: 283867.3438\n",
      "Epoch 4396/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293906.2500 - mean_squared_error: 293906.2500\n",
      "Epoch 4397/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285457.0938 - mean_squared_error: 285457.0938\n",
      "Epoch 4398/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299133.8125 - mean_squared_error: 299133.8125\n",
      "Epoch 4399/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291442.8125 - mean_squared_error: 291442.7812\n",
      "Epoch 4400/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295735.5000 - mean_squared_error: 295735.5000\n",
      "Epoch 4401/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293851.7188 - mean_squared_error: 293851.6875\n",
      "Epoch 4402/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294871.9062 - mean_squared_error: 294871.9062\n",
      "Epoch 4403/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293470.0000 - mean_squared_error: 293470.0000\n",
      "Epoch 4404/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301345.7188 - mean_squared_error: 301345.7188\n",
      "Epoch 4405/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290060.1250 - mean_squared_error: 290060.1250\n",
      "Epoch 4406/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298146.0625 - mean_squared_error: 298146.0625\n",
      "Epoch 4407/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292041.2188 - mean_squared_error: 292041.2188\n",
      "Epoch 4408/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292687.1875 - mean_squared_error: 292687.1875\n",
      "Epoch 4409/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298396.5000 - mean_squared_error: 298396.5000\n",
      "Epoch 4410/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295148.2188 - mean_squared_error: 295148.2188\n",
      "Epoch 4411/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289924.2188 - mean_squared_error: 289924.2188\n",
      "Epoch 4412/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294915.6875 - mean_squared_error: 294915.6875\n",
      "Epoch 4413/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287340.8438 - mean_squared_error: 287340.8438\n",
      "Epoch 4414/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287110.9688 - mean_squared_error: 287110.9688\n",
      "Epoch 4415/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297066.2812 - mean_squared_error: 297066.2812\n",
      "Epoch 4416/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294542.4375 - mean_squared_error: 294542.4375\n",
      "Epoch 4417/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290980.0312 - mean_squared_error: 290980.0312\n",
      "Epoch 4418/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292317.7188 - mean_squared_error: 292317.7188\n",
      "Epoch 4419/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296195.6562 - mean_squared_error: 296195.6562\n",
      "Epoch 4420/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296171.5312 - mean_squared_error: 296171.5312\n",
      "Epoch 4421/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300000.7188 - mean_squared_error: 300000.7188\n",
      "Epoch 4422/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295888.1875 - mean_squared_error: 295888.1875\n",
      "Epoch 4423/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291089.3438 - mean_squared_error: 291089.3438\n",
      "Epoch 4424/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287034.3750 - mean_squared_error: 287034.3750\n",
      "Epoch 4425/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293901.4375 - mean_squared_error: 293901.4375\n",
      "Epoch 4426/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297001.5000 - mean_squared_error: 297001.5000\n",
      "Epoch 4427/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 279775.2188 - mean_squared_error: 279775.2188\n",
      "Epoch 4428/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291630.7500 - mean_squared_error: 291630.7500\n",
      "Epoch 4429/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289362.6875 - mean_squared_error: 289362.6875\n",
      "Epoch 4430/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293476.7500 - mean_squared_error: 293476.7500\n",
      "Epoch 4431/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291946.9375 - mean_squared_error: 291946.9375\n",
      "Epoch 4432/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298129.3438 - mean_squared_error: 298129.3750\n",
      "Epoch 4433/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298751.2500 - mean_squared_error: 298751.2500\n",
      "Epoch 4434/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295648.3750 - mean_squared_error: 295648.3750\n",
      "Epoch 4435/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295059.6875 - mean_squared_error: 295059.6875\n",
      "Epoch 4436/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292805.9062 - mean_squared_error: 292805.9062\n",
      "Epoch 4437/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296188.5625 - mean_squared_error: 296188.5625\n",
      "Epoch 4438/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303395.7812 - mean_squared_error: 303395.7812\n",
      "Epoch 4439/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300421.9062 - mean_squared_error: 300421.9062\n",
      "Epoch 4440/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292676.4062 - mean_squared_error: 292676.4062\n",
      "Epoch 4441/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296704.9375 - mean_squared_error: 296704.9375\n",
      "Epoch 4442/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295422.0000 - mean_squared_error: 295422.0000\n",
      "Epoch 4443/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297454.4375 - mean_squared_error: 297454.4375\n",
      "Epoch 4444/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297586.3438 - mean_squared_error: 297586.3438\n",
      "Epoch 4445/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304276.8750 - mean_squared_error: 304276.8750\n",
      "Epoch 4446/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297648.3438 - mean_squared_error: 297648.3438\n",
      "Epoch 4447/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301963.0000 - mean_squared_error: 301963.0000\n",
      "Epoch 4448/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296709.9688 - mean_squared_error: 296709.9688\n",
      "Epoch 4449/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296501.7500 - mean_squared_error: 296501.7500\n",
      "Epoch 4450/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299988.3125 - mean_squared_error: 299988.3125\n",
      "Epoch 4451/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302239.6562 - mean_squared_error: 302239.6562\n",
      "Epoch 4452/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289027.7188 - mean_squared_error: 289027.7188\n",
      "Epoch 4453/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293041.6875 - mean_squared_error: 293041.6875\n",
      "Epoch 4454/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295943.2500 - mean_squared_error: 295943.2500\n",
      "Epoch 4455/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301342.0000 - mean_squared_error: 301342.0000\n",
      "Epoch 4456/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304852.1562 - mean_squared_error: 304852.1562\n",
      "Epoch 4457/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301580.8438 - mean_squared_error: 301580.8438\n",
      "Epoch 4458/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287372.1562 - mean_squared_error: 287372.1562\n",
      "Epoch 4459/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 299869.4062 - mean_squared_error: 299869.4062\n",
      "Epoch 4460/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291090.3750 - mean_squared_error: 291090.3750\n",
      "Epoch 4461/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294943.5000 - mean_squared_error: 294943.5000\n",
      "Epoch 4462/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296826.4375 - mean_squared_error: 296826.4375\n",
      "Epoch 4463/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296682.9688 - mean_squared_error: 296682.9688\n",
      "Epoch 4464/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295233.6875 - mean_squared_error: 295233.6875\n",
      "Epoch 4465/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300885.0312 - mean_squared_error: 300885.0000\n",
      "Epoch 4466/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293661.8750 - mean_squared_error: 293661.8438\n",
      "Epoch 4467/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287122.6250 - mean_squared_error: 287122.6250\n",
      "Epoch 4468/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288123.1562 - mean_squared_error: 288123.1250\n",
      "Epoch 4469/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290638.8438 - mean_squared_error: 290638.8438\n",
      "Epoch 4470/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301501.6562 - mean_squared_error: 301501.6562\n",
      "Epoch 4471/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296353.2188 - mean_squared_error: 296353.2188\n",
      "Epoch 4472/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 299865.7188 - mean_squared_error: 299865.7188\n",
      "Epoch 4473/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290497.8750 - mean_squared_error: 290497.8750\n",
      "Epoch 4474/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297579.5000 - mean_squared_error: 297579.5000\n",
      "Epoch 4475/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294762.7188 - mean_squared_error: 294762.7188\n",
      "Epoch 4476/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298954.2812 - mean_squared_error: 298954.2812\n",
      "Epoch 4477/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295819.7500 - mean_squared_error: 295819.7500\n",
      "Epoch 4478/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295517.3750 - mean_squared_error: 295517.3750\n",
      "Epoch 4479/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293677.9375 - mean_squared_error: 293677.9375\n",
      "Epoch 4480/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294668.7500 - mean_squared_error: 294668.7500\n",
      "Epoch 4481/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294335.7812 - mean_squared_error: 294335.8125\n",
      "Epoch 4482/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297465.3125 - mean_squared_error: 297465.3125\n",
      "Epoch 4483/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288996.4062 - mean_squared_error: 288996.4062\n",
      "Epoch 4484/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 299689.0938 - mean_squared_error: 299689.0938\n",
      "Epoch 4485/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290781.1562 - mean_squared_error: 290781.1875\n",
      "Epoch 4486/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298611.5000 - mean_squared_error: 298611.5000\n",
      "Epoch 4487/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286390.4062 - mean_squared_error: 286390.4062\n",
      "Epoch 4488/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299360.8125 - mean_squared_error: 299360.8125\n",
      "Epoch 4489/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287553.0938 - mean_squared_error: 287553.0938\n",
      "Epoch 4490/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296782.7500 - mean_squared_error: 296782.7500\n",
      "Epoch 4491/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293800.1875 - mean_squared_error: 293800.1875\n",
      "Epoch 4492/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294214.5312 - mean_squared_error: 294214.5312\n",
      "Epoch 4493/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293749.8438 - mean_squared_error: 293749.8438\n",
      "Epoch 4494/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291141.4062 - mean_squared_error: 291141.4062\n",
      "Epoch 4495/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294334.4688 - mean_squared_error: 294334.4688\n",
      "Epoch 4496/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296999.5000 - mean_squared_error: 296999.5000\n",
      "Epoch 4497/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286424.1562 - mean_squared_error: 286424.1562\n",
      "Epoch 4498/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300135.2188 - mean_squared_error: 300135.2188\n",
      "Epoch 4499/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296619.7500 - mean_squared_error: 296619.7812\n",
      "Epoch 4500/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290874.4688 - mean_squared_error: 290874.4688\n",
      "Epoch 4501/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294725.7188 - mean_squared_error: 294725.7188\n",
      "Epoch 4502/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291242.5938 - mean_squared_error: 291242.5938\n",
      "Epoch 4503/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 297742.5000 - mean_squared_error: 297742.5000\n",
      "Epoch 4504/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295333.3750 - mean_squared_error: 295333.3750\n",
      "Epoch 4505/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298102.3438 - mean_squared_error: 298102.3438\n",
      "Epoch 4506/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295526.1562 - mean_squared_error: 295526.1562\n",
      "Epoch 4507/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294478.3125 - mean_squared_error: 294478.3125\n",
      "Epoch 4508/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294579.6875 - mean_squared_error: 294579.6875\n",
      "Epoch 4509/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293833.3125 - mean_squared_error: 293833.3125\n",
      "Epoch 4510/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292295.7500 - mean_squared_error: 292295.7500\n",
      "Epoch 4511/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292073.6562 - mean_squared_error: 292073.6562\n",
      "Epoch 4512/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290946.6875 - mean_squared_error: 290946.6875\n",
      "Epoch 4513/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294232.7500 - mean_squared_error: 294232.7500\n",
      "Epoch 4514/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 298912.0625 - mean_squared_error: 298912.0312\n",
      "Epoch 4515/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297007.2500 - mean_squared_error: 297007.2500\n",
      "Epoch 4516/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307214.7500 - mean_squared_error: 307214.7500\n",
      "Epoch 4517/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291443.6562 - mean_squared_error: 291443.6250\n",
      "Epoch 4518/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292135.0000 - mean_squared_error: 292135.0000\n",
      "Epoch 4519/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291669.5312 - mean_squared_error: 291669.5312\n",
      "Epoch 4520/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291962.7500 - mean_squared_error: 291962.7500\n",
      "Epoch 4521/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299040.0938 - mean_squared_error: 299040.0938\n",
      "Epoch 4522/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300280.4688 - mean_squared_error: 300280.4688\n",
      "Epoch 4523/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291505.5625 - mean_squared_error: 291505.5625\n",
      "Epoch 4524/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290357.9688 - mean_squared_error: 290357.9688\n",
      "Epoch 4525/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295459.3750 - mean_squared_error: 295459.3750\n",
      "Epoch 4526/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290489.6875 - mean_squared_error: 290489.6875\n",
      "Epoch 4527/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290481.3750 - mean_squared_error: 290481.3750\n",
      "Epoch 4528/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292391.1875 - mean_squared_error: 292391.1875\n",
      "Epoch 4529/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291880.8750 - mean_squared_error: 291880.9062\n",
      "Epoch 4530/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 285053.0625 - mean_squared_error: 285053.0625\n",
      "Epoch 4531/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292627.8750 - mean_squared_error: 292627.8750\n",
      "Epoch 4532/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 302061.9688 - mean_squared_error: 302062.0000\n",
      "Epoch 4533/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294709.4062 - mean_squared_error: 294709.4062\n",
      "Epoch 4534/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293286.1875 - mean_squared_error: 293286.1875\n",
      "Epoch 4535/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293960.7812 - mean_squared_error: 293960.7500\n",
      "Epoch 4536/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288000.5938 - mean_squared_error: 288000.6250\n",
      "Epoch 4537/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294418.1250 - mean_squared_error: 294418.1250\n",
      "Epoch 4538/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287792.0000 - mean_squared_error: 287792.0000\n",
      "Epoch 4539/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304655.0312 - mean_squared_error: 304655.0312\n",
      "Epoch 4540/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299987.5000 - mean_squared_error: 299987.5000\n",
      "Epoch 4541/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297265.8438 - mean_squared_error: 297265.8438\n",
      "Epoch 4542/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 284879.3438 - mean_squared_error: 284879.3438\n",
      "Epoch 4543/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294584.1875 - mean_squared_error: 294584.1875\n",
      "Epoch 4544/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291533.2812 - mean_squared_error: 291533.2812\n",
      "Epoch 4545/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295849.2188 - mean_squared_error: 295849.2188\n",
      "Epoch 4546/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295963.1250 - mean_squared_error: 295963.1250\n",
      "Epoch 4547/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295497.9375 - mean_squared_error: 295497.9375\n",
      "Epoch 4548/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291567.8438 - mean_squared_error: 291567.8438\n",
      "Epoch 4549/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288343.0625 - mean_squared_error: 288343.0625\n",
      "Epoch 4550/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296295.6875 - mean_squared_error: 296295.6875\n",
      "Epoch 4551/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 293155.9688 - mean_squared_error: 293155.9688\n",
      "Epoch 4552/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295883.2812 - mean_squared_error: 295883.2812\n",
      "Epoch 4553/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286092.9062 - mean_squared_error: 286092.9062\n",
      "Epoch 4554/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299607.6562 - mean_squared_error: 299607.6562\n",
      "Epoch 4555/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293452.5312 - mean_squared_error: 293452.5625\n",
      "Epoch 4556/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293779.4688 - mean_squared_error: 293779.4688\n",
      "Epoch 4557/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293819.5625 - mean_squared_error: 293819.5625\n",
      "Epoch 4558/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297255.5312 - mean_squared_error: 297255.5312\n",
      "Epoch 4559/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291285.0000 - mean_squared_error: 291285.0000\n",
      "Epoch 4560/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292040.2812 - mean_squared_error: 292040.2812\n",
      "Epoch 4561/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295859.7500 - mean_squared_error: 295859.7500\n",
      "Epoch 4562/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296608.8438 - mean_squared_error: 296608.8438\n",
      "Epoch 4563/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 291746.4375 - mean_squared_error: 291746.4375\n",
      "Epoch 4564/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294989.9062 - mean_squared_error: 294989.9062\n",
      "Epoch 4565/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297862.6875 - mean_squared_error: 297862.6875\n",
      "Epoch 4566/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300045.3750 - mean_squared_error: 300045.3750\n",
      "Epoch 4567/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299131.0938 - mean_squared_error: 299131.0938\n",
      "Epoch 4568/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290324.5000 - mean_squared_error: 290324.5000\n",
      "Epoch 4569/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298020.0625 - mean_squared_error: 298020.0625\n",
      "Epoch 4570/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 285030.5938 - mean_squared_error: 285030.5938\n",
      "Epoch 4571/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300809.7188 - mean_squared_error: 300809.6875\n",
      "Epoch 4572/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295184.9062 - mean_squared_error: 295184.9062\n",
      "Epoch 4573/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295970.3438 - mean_squared_error: 295970.3438\n",
      "Epoch 4574/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290294.5938 - mean_squared_error: 290294.5938\n",
      "Epoch 4575/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297896.8125 - mean_squared_error: 297896.8125\n",
      "Epoch 4576/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292193.3750 - mean_squared_error: 292193.3750\n",
      "Epoch 4577/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297020.0938 - mean_squared_error: 297020.0938\n",
      "Epoch 4578/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289159.1562 - mean_squared_error: 289159.1562\n",
      "Epoch 4579/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 294385.5312 - mean_squared_error: 294385.5312\n",
      "Epoch 4580/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294407.5000 - mean_squared_error: 294407.5312\n",
      "Epoch 4581/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301152.6875 - mean_squared_error: 301152.6875\n",
      "Epoch 4582/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296724.6875 - mean_squared_error: 296724.6875\n",
      "Epoch 4583/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 294131.9688 - mean_squared_error: 294131.9688\n",
      "Epoch 4584/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302225.8125 - mean_squared_error: 302225.8125\n",
      "Epoch 4585/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292053.2812 - mean_squared_error: 292053.2500\n",
      "Epoch 4586/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296260.4688 - mean_squared_error: 296260.4688\n",
      "Epoch 4587/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290331.1250 - mean_squared_error: 290331.1250\n",
      "Epoch 4588/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296650.4062 - mean_squared_error: 296650.4062\n",
      "Epoch 4589/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296001.4688 - mean_squared_error: 296001.4688\n",
      "Epoch 4590/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299543.0000 - mean_squared_error: 299543.0000\n",
      "Epoch 4591/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287714.1875 - mean_squared_error: 287714.1875\n",
      "Epoch 4592/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292020.2500 - mean_squared_error: 292020.2500\n",
      "Epoch 4593/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297778.0625 - mean_squared_error: 297778.0625\n",
      "Epoch 4594/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294522.7812 - mean_squared_error: 294522.7812\n",
      "Epoch 4595/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 289240.4688 - mean_squared_error: 289240.5000\n",
      "Epoch 4596/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299031.6562 - mean_squared_error: 299031.6562\n",
      "Epoch 4597/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287097.6250 - mean_squared_error: 287097.6250\n",
      "Epoch 4598/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301269.3438 - mean_squared_error: 301269.3438\n",
      "Epoch 4599/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296580.3125 - mean_squared_error: 296580.3125\n",
      "Epoch 4600/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295371.9375 - mean_squared_error: 295371.9375\n",
      "Epoch 4601/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292689.7812 - mean_squared_error: 292689.7812\n",
      "Epoch 4602/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294499.1250 - mean_squared_error: 294499.1250\n",
      "Epoch 4603/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293367.2500 - mean_squared_error: 293367.2500\n",
      "Epoch 4604/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296411.8750 - mean_squared_error: 296411.8750\n",
      "Epoch 4605/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293535.6250 - mean_squared_error: 293535.6250\n",
      "Epoch 4606/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293872.8438 - mean_squared_error: 293872.8438\n",
      "Epoch 4607/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299050.7812 - mean_squared_error: 299050.7812\n",
      "Epoch 4608/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298739.6875 - mean_squared_error: 298739.6875\n",
      "Epoch 4609/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293923.8438 - mean_squared_error: 293923.8438\n",
      "Epoch 4610/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299373.1250 - mean_squared_error: 299373.1250\n",
      "Epoch 4611/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297128.1250 - mean_squared_error: 297128.1250\n",
      "Epoch 4612/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299220.1562 - mean_squared_error: 299220.1562\n",
      "Epoch 4613/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290765.0625 - mean_squared_error: 290765.0625\n",
      "Epoch 4614/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292265.4688 - mean_squared_error: 292265.5312\n",
      "Epoch 4615/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300592.9375 - mean_squared_error: 300592.9375\n",
      "Epoch 4616/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 298064.4688 - mean_squared_error: 298064.4688\n",
      "Epoch 4617/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298661.6250 - mean_squared_error: 298661.6875\n",
      "Epoch 4618/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294171.8125 - mean_squared_error: 294171.8125\n",
      "Epoch 4619/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292427.1250 - mean_squared_error: 292427.1250\n",
      "Epoch 4620/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303092.0000 - mean_squared_error: 303092.0000\n",
      "Epoch 4621/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 306084.6250 - mean_squared_error: 306084.5938\n",
      "Epoch 4622/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 300118.2500 - mean_squared_error: 300118.2500\n",
      "Epoch 4623/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297645.2500 - mean_squared_error: 297645.2188\n",
      "Epoch 4624/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287777.4688 - mean_squared_error: 287777.4688\n",
      "Epoch 4625/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295798.6250 - mean_squared_error: 295798.6250\n",
      "Epoch 4626/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294426.5938 - mean_squared_error: 294426.5625\n",
      "Epoch 4627/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289987.8438 - mean_squared_error: 289987.8438\n",
      "Epoch 4628/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299578.3438 - mean_squared_error: 299578.3438\n",
      "Epoch 4629/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 308328.6875 - mean_squared_error: 308328.6875\n",
      "Epoch 4630/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298944.5312 - mean_squared_error: 298944.5312\n",
      "Epoch 4631/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296349.0000 - mean_squared_error: 296349.0000\n",
      "Epoch 4632/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302597.1562 - mean_squared_error: 302597.1562\n",
      "Epoch 4633/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301508.4375 - mean_squared_error: 301508.4375\n",
      "Epoch 4634/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294927.5312 - mean_squared_error: 294927.5312\n",
      "Epoch 4635/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289773.9688 - mean_squared_error: 289773.9688\n",
      "Epoch 4636/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291984.6875 - mean_squared_error: 291984.6562\n",
      "Epoch 4637/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296780.4375 - mean_squared_error: 296780.4062\n",
      "Epoch 4638/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299238.6250 - mean_squared_error: 299238.6250\n",
      "Epoch 4639/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297618.0000 - mean_squared_error: 297618.0000\n",
      "Epoch 4640/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302503.7812 - mean_squared_error: 302503.7812\n",
      "Epoch 4641/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 284745.7812 - mean_squared_error: 284745.7812\n",
      "Epoch 4642/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295740.8125 - mean_squared_error: 295740.8125\n",
      "Epoch 4643/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286717.3438 - mean_squared_error: 286717.3438\n",
      "Epoch 4644/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297274.0938 - mean_squared_error: 297274.0938\n",
      "Epoch 4645/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299219.5625 - mean_squared_error: 299219.5625\n",
      "Epoch 4646/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300290.5625 - mean_squared_error: 300290.5625\n",
      "Epoch 4647/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288609.9375 - mean_squared_error: 288609.9375\n",
      "Epoch 4648/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287764.3750 - mean_squared_error: 287764.3438\n",
      "Epoch 4649/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296075.1875 - mean_squared_error: 296075.2188\n",
      "Epoch 4650/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293596.9375 - mean_squared_error: 293596.9375\n",
      "Epoch 4651/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294606.6875 - mean_squared_error: 294606.6875\n",
      "Epoch 4652/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294101.0625 - mean_squared_error: 294101.0625\n",
      "Epoch 4653/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 300610.1562 - mean_squared_error: 300610.1562\n",
      "Epoch 4654/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293116.8750 - mean_squared_error: 293116.8750\n",
      "Epoch 4655/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302263.0000 - mean_squared_error: 302263.0000\n",
      "Epoch 4656/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294820.1562 - mean_squared_error: 294820.1562\n",
      "Epoch 4657/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291090.7500 - mean_squared_error: 291090.7500\n",
      "Epoch 4658/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297018.0000 - mean_squared_error: 297018.0000\n",
      "Epoch 4659/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289412.9688 - mean_squared_error: 289412.9688\n",
      "Epoch 4660/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299157.2500 - mean_squared_error: 299157.2500\n",
      "Epoch 4661/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288590.6250 - mean_squared_error: 288590.6250\n",
      "Epoch 4662/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296746.5000 - mean_squared_error: 296746.5000\n",
      "Epoch 4663/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294732.5312 - mean_squared_error: 294732.5312\n",
      "Epoch 4664/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288601.1875 - mean_squared_error: 288601.1875\n",
      "Epoch 4665/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292739.0000 - mean_squared_error: 292739.0000\n",
      "Epoch 4666/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 286776.3125 - mean_squared_error: 286776.2812\n",
      "Epoch 4667/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302258.0000 - mean_squared_error: 302258.0000\n",
      "Epoch 4668/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291971.7812 - mean_squared_error: 291971.7500\n",
      "Epoch 4669/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295175.9688 - mean_squared_error: 295175.9688\n",
      "Epoch 4670/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295150.2188 - mean_squared_error: 295150.2188\n",
      "Epoch 4671/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 304164.7812 - mean_squared_error: 304164.7812\n",
      "Epoch 4672/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302613.0000 - mean_squared_error: 302613.0000\n",
      "Epoch 4673/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288915.6250 - mean_squared_error: 288915.6250\n",
      "Epoch 4674/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299098.0312 - mean_squared_error: 299098.0625\n",
      "Epoch 4675/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295696.5312 - mean_squared_error: 295696.5312\n",
      "Epoch 4676/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298570.1562 - mean_squared_error: 298570.1562\n",
      "Epoch 4677/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292990.2812 - mean_squared_error: 292990.2812\n",
      "Epoch 4678/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285441.5938 - mean_squared_error: 285441.5938\n",
      "Epoch 4679/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295690.8438 - mean_squared_error: 295690.8438\n",
      "Epoch 4680/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291289.9375 - mean_squared_error: 291289.9375\n",
      "Epoch 4681/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304062.7812 - mean_squared_error: 304062.7812\n",
      "Epoch 4682/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298104.7188 - mean_squared_error: 298104.7188\n",
      "Epoch 4683/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294947.4688 - mean_squared_error: 294947.4688\n",
      "Epoch 4684/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295484.7812 - mean_squared_error: 295484.7812\n",
      "Epoch 4685/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295386.3750 - mean_squared_error: 295386.3750\n",
      "Epoch 4686/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292472.1562 - mean_squared_error: 292472.1562\n",
      "Epoch 4687/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296190.3750 - mean_squared_error: 296190.3750\n",
      "Epoch 4688/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299525.6250 - mean_squared_error: 299525.5938\n",
      "Epoch 4689/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294233.4688 - mean_squared_error: 294233.4688\n",
      "Epoch 4690/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293222.1562 - mean_squared_error: 293222.1562\n",
      "Epoch 4691/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295066.1875 - mean_squared_error: 295066.1875\n",
      "Epoch 4692/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290600.2500 - mean_squared_error: 290600.2500\n",
      "Epoch 4693/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292331.4062 - mean_squared_error: 292331.4062\n",
      "Epoch 4694/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301859.3125 - mean_squared_error: 301859.3125\n",
      "Epoch 4695/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294064.1875 - mean_squared_error: 294064.1562\n",
      "Epoch 4696/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297744.7188 - mean_squared_error: 297744.7188\n",
      "Epoch 4697/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283333.5312 - mean_squared_error: 283333.5312\n",
      "Epoch 4698/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296043.6562 - mean_squared_error: 296043.6562\n",
      "Epoch 4699/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299852.9375 - mean_squared_error: 299852.9375\n",
      "Epoch 4700/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300446.1875 - mean_squared_error: 300446.1875\n",
      "Epoch 4701/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295144.3750 - mean_squared_error: 295144.3750\n",
      "Epoch 4702/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288535.9688 - mean_squared_error: 288535.9688\n",
      "Epoch 4703/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296269.8125 - mean_squared_error: 296269.8125\n",
      "Epoch 4704/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301208.3438 - mean_squared_error: 301208.3438\n",
      "Epoch 4705/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288415.0312 - mean_squared_error: 288415.0312\n",
      "Epoch 4706/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 286918.7500 - mean_squared_error: 286918.7188\n",
      "Epoch 4707/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302191.2812 - mean_squared_error: 302191.2812\n",
      "Epoch 4708/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299409.5938 - mean_squared_error: 299409.5938\n",
      "Epoch 4709/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301810.6250 - mean_squared_error: 301810.6250\n",
      "Epoch 4710/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291812.4688 - mean_squared_error: 291812.5000\n",
      "Epoch 4711/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297243.2812 - mean_squared_error: 297243.2812\n",
      "Epoch 4712/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292491.2500 - mean_squared_error: 292491.2500\n",
      "Epoch 4713/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297357.7188 - mean_squared_error: 297357.7188\n",
      "Epoch 4714/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290217.7188 - mean_squared_error: 290217.6875\n",
      "Epoch 4715/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294197.8125 - mean_squared_error: 294197.8125\n",
      "Epoch 4716/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 300371.1562 - mean_squared_error: 300371.1562\n",
      "Epoch 4717/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301861.3750 - mean_squared_error: 301861.3750\n",
      "Epoch 4718/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297248.4688 - mean_squared_error: 297248.4375\n",
      "Epoch 4719/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 305123.5312 - mean_squared_error: 305123.5312\n",
      "Epoch 4720/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290282.5938 - mean_squared_error: 290282.5938\n",
      "Epoch 4721/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281104.5312 - mean_squared_error: 281104.5312\n",
      "Epoch 4722/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292521.1875 - mean_squared_error: 292521.1875\n",
      "Epoch 4723/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290643.8438 - mean_squared_error: 290643.8438\n",
      "Epoch 4724/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300436.5938 - mean_squared_error: 300436.5625\n",
      "Epoch 4725/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296272.8125 - mean_squared_error: 296272.8125\n",
      "Epoch 4726/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 276997.9688 - mean_squared_error: 276997.9688\n",
      "Epoch 4727/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296030.2188 - mean_squared_error: 296030.2188\n",
      "Epoch 4728/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296600.0000 - mean_squared_error: 296600.0000\n",
      "Epoch 4729/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289068.1875 - mean_squared_error: 289068.1875\n",
      "Epoch 4730/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296592.2188 - mean_squared_error: 296592.2188\n",
      "Epoch 4731/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288830.6562 - mean_squared_error: 288830.6562\n",
      "Epoch 4732/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293537.5312 - mean_squared_error: 293537.5312\n",
      "Epoch 4733/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 311580.5625 - mean_squared_error: 311580.5625\n",
      "Epoch 4734/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299703.5000 - mean_squared_error: 299703.4688\n",
      "Epoch 4735/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292120.7500 - mean_squared_error: 292120.7500\n",
      "Epoch 4736/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292808.6562 - mean_squared_error: 292808.6562\n",
      "Epoch 4737/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291914.5000 - mean_squared_error: 291914.5000\n",
      "Epoch 4738/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 282539.8438 - mean_squared_error: 282539.8438\n",
      "Epoch 4739/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299260.4062 - mean_squared_error: 299260.4062\n",
      "Epoch 4740/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296190.5938 - mean_squared_error: 296190.5938\n",
      "Epoch 4741/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296629.7500 - mean_squared_error: 296629.7500\n",
      "Epoch 4742/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294918.9062 - mean_squared_error: 294918.9062\n",
      "Epoch 4743/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299462.0000 - mean_squared_error: 299462.0000\n",
      "Epoch 4744/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306474.1250 - mean_squared_error: 306474.1250\n",
      "Epoch 4745/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291450.0625 - mean_squared_error: 291450.0625\n",
      "Epoch 4746/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305805.4375 - mean_squared_error: 305805.4375\n",
      "Epoch 4747/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297823.0625 - mean_squared_error: 297823.0938\n",
      "Epoch 4748/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 298153.2500 - mean_squared_error: 298153.2812\n",
      "Epoch 4749/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299323.7812 - mean_squared_error: 299323.7812\n",
      "Epoch 4750/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296236.9375 - mean_squared_error: 296236.9062\n",
      "Epoch 4751/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294764.5625 - mean_squared_error: 294764.5625\n",
      "Epoch 4752/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292917.8750 - mean_squared_error: 292917.8750\n",
      "Epoch 4753/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298746.1875 - mean_squared_error: 298746.1875\n",
      "Epoch 4754/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291740.9375 - mean_squared_error: 291740.9375\n",
      "Epoch 4755/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302401.5312 - mean_squared_error: 302401.5312\n",
      "Epoch 4756/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296664.4375 - mean_squared_error: 296664.4375\n",
      "Epoch 4757/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284913.4688 - mean_squared_error: 284913.4688\n",
      "Epoch 4758/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290623.7500 - mean_squared_error: 290623.7188\n",
      "Epoch 4759/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295746.3125 - mean_squared_error: 295746.3125\n",
      "Epoch 4760/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300997.0312 - mean_squared_error: 300997.0312\n",
      "Epoch 4761/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291243.1250 - mean_squared_error: 291243.1250\n",
      "Epoch 4762/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302366.0312 - mean_squared_error: 302366.0312\n",
      "Epoch 4763/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294762.3438 - mean_squared_error: 294762.3750\n",
      "Epoch 4764/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297831.2188 - mean_squared_error: 297831.2188\n",
      "Epoch 4765/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297293.3438 - mean_squared_error: 297293.3438\n",
      "Epoch 4766/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291626.9688 - mean_squared_error: 291626.9688\n",
      "Epoch 4767/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297343.1562 - mean_squared_error: 297343.1562\n",
      "Epoch 4768/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 284460.3125 - mean_squared_error: 284460.3125\n",
      "Epoch 4769/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296018.8125 - mean_squared_error: 296018.8125\n",
      "Epoch 4770/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291701.5625 - mean_squared_error: 291701.5625\n",
      "Epoch 4771/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293883.5000 - mean_squared_error: 293883.5312\n",
      "Epoch 4772/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291551.5625 - mean_squared_error: 291551.5938\n",
      "Epoch 4773/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303908.4688 - mean_squared_error: 303908.4688\n",
      "Epoch 4774/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292065.9062 - mean_squared_error: 292065.9062\n",
      "Epoch 4775/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290763.9375 - mean_squared_error: 290763.9375\n",
      "Epoch 4776/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302240.2500 - mean_squared_error: 302240.2500\n",
      "Epoch 4777/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296925.5625 - mean_squared_error: 296925.5625\n",
      "Epoch 4778/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295547.0312 - mean_squared_error: 295547.0312\n",
      "Epoch 4779/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292134.0312 - mean_squared_error: 292134.0312\n",
      "Epoch 4780/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297909.6562 - mean_squared_error: 297909.6562\n",
      "Epoch 4781/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290322.6562 - mean_squared_error: 290322.6562\n",
      "Epoch 4782/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295179.0312 - mean_squared_error: 295179.0312\n",
      "Epoch 4783/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291085.3750 - mean_squared_error: 291085.3750\n",
      "Epoch 4784/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302076.0312 - mean_squared_error: 302076.0312\n",
      "Epoch 4785/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293661.5000 - mean_squared_error: 293661.5000\n",
      "Epoch 4786/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299641.5312 - mean_squared_error: 299641.5312\n",
      "Epoch 4787/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289638.7500 - mean_squared_error: 289638.7500\n",
      "Epoch 4788/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294456.5000 - mean_squared_error: 294456.5000\n",
      "Epoch 4789/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290853.6562 - mean_squared_error: 290853.6250\n",
      "Epoch 4790/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292702.7500 - mean_squared_error: 292702.7500\n",
      "Epoch 4791/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 289803.3750 - mean_squared_error: 289803.4062\n",
      "Epoch 4792/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295467.0625 - mean_squared_error: 295467.0625\n",
      "Epoch 4793/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294121.0625 - mean_squared_error: 294121.0625\n",
      "Epoch 4794/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292205.6562 - mean_squared_error: 292205.6562\n",
      "Epoch 4795/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299057.7812 - mean_squared_error: 299057.7812\n",
      "Epoch 4796/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299373.4062 - mean_squared_error: 299373.4062\n",
      "Epoch 4797/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295293.9375 - mean_squared_error: 295293.9375\n",
      "Epoch 4798/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350879.1250 - mean_squared_error: 350879.1250\n",
      "Epoch 4799/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296228.0312 - mean_squared_error: 296228.0312\n",
      "Epoch 4800/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298194.3438 - mean_squared_error: 298194.3438\n",
      "Epoch 4801/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293446.4062 - mean_squared_error: 293446.3750\n",
      "Epoch 4802/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 300117.3750 - mean_squared_error: 300117.4062\n",
      "Epoch 4803/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299198.0000 - mean_squared_error: 299198.0000\n",
      "Epoch 4804/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306113.1562 - mean_squared_error: 306113.1562\n",
      "Epoch 4805/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 291931.0312 - mean_squared_error: 291931.0000\n",
      "Epoch 4806/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297784.8750 - mean_squared_error: 297784.8750\n",
      "Epoch 4807/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307583.8438 - mean_squared_error: 307583.8438\n",
      "Epoch 4808/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294983.6875 - mean_squared_error: 294983.6875\n",
      "Epoch 4809/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296075.9062 - mean_squared_error: 296075.9062\n",
      "Epoch 4810/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298142.4688 - mean_squared_error: 298142.4688\n",
      "Epoch 4811/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292452.0938 - mean_squared_error: 292452.0938\n",
      "Epoch 4812/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292889.8750 - mean_squared_error: 292889.8750\n",
      "Epoch 4813/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294064.6250 - mean_squared_error: 294064.6250\n",
      "Epoch 4814/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295710.2500 - mean_squared_error: 295710.2500\n",
      "Epoch 4815/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305600.3125 - mean_squared_error: 305600.3125\n",
      "Epoch 4816/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291504.3438 - mean_squared_error: 291504.3125\n",
      "Epoch 4817/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287835.5312 - mean_squared_error: 287835.5312\n",
      "Epoch 4818/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302775.2500 - mean_squared_error: 302775.2500\n",
      "Epoch 4819/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297677.0000 - mean_squared_error: 297676.9688\n",
      "Epoch 4820/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290390.1562 - mean_squared_error: 290390.1562\n",
      "Epoch 4821/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298826.0938 - mean_squared_error: 298826.0938\n",
      "Epoch 4822/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300247.0625 - mean_squared_error: 300247.0625\n",
      "Epoch 4823/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295129.4062 - mean_squared_error: 295129.4062\n",
      "Epoch 4824/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295186.1875 - mean_squared_error: 295186.1875\n",
      "Epoch 4825/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294303.3125 - mean_squared_error: 294303.3125\n",
      "Epoch 4826/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296189.1250 - mean_squared_error: 296189.1250\n",
      "Epoch 4827/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301322.6250 - mean_squared_error: 301322.6250\n",
      "Epoch 4828/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289675.7812 - mean_squared_error: 289675.7812\n",
      "Epoch 4829/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293736.1562 - mean_squared_error: 293736.1562\n",
      "Epoch 4830/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299248.9688 - mean_squared_error: 299248.9688\n",
      "Epoch 4831/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298454.9375 - mean_squared_error: 298454.9375\n",
      "Epoch 4832/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296321.1875 - mean_squared_error: 296321.1875\n",
      "Epoch 4833/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301632.5000 - mean_squared_error: 301632.5000\n",
      "Epoch 4834/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295909.6875 - mean_squared_error: 295909.6875\n",
      "Epoch 4835/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291577.9375 - mean_squared_error: 291577.9375\n",
      "Epoch 4836/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296086.2812 - mean_squared_error: 296086.3125\n",
      "Epoch 4837/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305976.6562 - mean_squared_error: 305976.6875\n",
      "Epoch 4838/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297446.0000 - mean_squared_error: 297446.0000\n",
      "Epoch 4839/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297809.8125 - mean_squared_error: 297809.8125\n",
      "Epoch 4840/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297987.9375 - mean_squared_error: 297987.9375\n",
      "Epoch 4841/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299106.9688 - mean_squared_error: 299106.9688\n",
      "Epoch 4842/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297215.2812 - mean_squared_error: 297215.2812\n",
      "Epoch 4843/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297053.0938 - mean_squared_error: 297053.0938\n",
      "Epoch 4844/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298523.2500 - mean_squared_error: 298523.2500\n",
      "Epoch 4845/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302284.1875 - mean_squared_error: 302284.1875\n",
      "Epoch 4846/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308828.7812 - mean_squared_error: 308828.7812\n",
      "Epoch 4847/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296367.9375 - mean_squared_error: 296367.9375\n",
      "Epoch 4848/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299362.7188 - mean_squared_error: 299362.7188\n",
      "Epoch 4849/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297702.2188 - mean_squared_error: 297702.2188\n",
      "Epoch 4850/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291304.9688 - mean_squared_error: 291305.0000\n",
      "Epoch 4851/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304432.9688 - mean_squared_error: 304432.9688\n",
      "Epoch 4852/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295832.7812 - mean_squared_error: 295832.7812\n",
      "Epoch 4853/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298425.4688 - mean_squared_error: 298425.4688\n",
      "Epoch 4854/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306158.4688 - mean_squared_error: 306158.4688\n",
      "Epoch 4855/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303987.6250 - mean_squared_error: 303987.6250\n",
      "Epoch 4856/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303699.0625 - mean_squared_error: 303699.0312\n",
      "Epoch 4857/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293622.9375 - mean_squared_error: 293622.9375\n",
      "Epoch 4858/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294711.9688 - mean_squared_error: 294711.9688\n",
      "Epoch 4859/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290961.8438 - mean_squared_error: 290961.8438\n",
      "Epoch 4860/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290080.9062 - mean_squared_error: 290080.9062\n",
      "Epoch 4861/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290619.4375 - mean_squared_error: 290619.4375\n",
      "Epoch 4862/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291592.1562 - mean_squared_error: 291592.1875\n",
      "Epoch 4863/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294548.3438 - mean_squared_error: 294548.3438\n",
      "Epoch 4864/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297259.6562 - mean_squared_error: 297259.6562\n",
      "Epoch 4865/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296063.5312 - mean_squared_error: 296063.5312\n",
      "Epoch 4866/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300749.4375 - mean_squared_error: 300749.4375\n",
      "Epoch 4867/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291909.5312 - mean_squared_error: 291909.5312\n",
      "Epoch 4868/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298266.9062 - mean_squared_error: 298266.9062\n",
      "Epoch 4869/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294574.5938 - mean_squared_error: 294574.5938\n",
      "Epoch 4870/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297216.1250 - mean_squared_error: 297216.1250\n",
      "Epoch 4871/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299393.1875 - mean_squared_error: 299393.2188\n",
      "Epoch 4872/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294851.0312 - mean_squared_error: 294851.0625\n",
      "Epoch 4873/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295026.5938 - mean_squared_error: 295026.5938\n",
      "Epoch 4874/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300933.9688 - mean_squared_error: 300933.9688\n",
      "Epoch 4875/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300403.2188 - mean_squared_error: 300403.2188\n",
      "Epoch 4876/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300902.2500 - mean_squared_error: 300902.2500\n",
      "Epoch 4877/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295741.4688 - mean_squared_error: 295741.4688\n",
      "Epoch 4878/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304987.9688 - mean_squared_error: 304987.9688\n",
      "Epoch 4879/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 309089.7500 - mean_squared_error: 309089.7812\n",
      "Epoch 4880/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 289601.9062 - mean_squared_error: 289601.9375\n",
      "Epoch 4881/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298650.0000 - mean_squared_error: 298650.0000\n",
      "Epoch 4882/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296169.2500 - mean_squared_error: 296169.2500\n",
      "Epoch 4883/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301180.0000 - mean_squared_error: 301180.0000\n",
      "Epoch 4884/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294901.4688 - mean_squared_error: 294901.5000\n",
      "Epoch 4885/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298293.7188 - mean_squared_error: 298293.7188\n",
      "Epoch 4886/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306101.5938 - mean_squared_error: 306101.5938\n",
      "Epoch 4887/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290757.1875 - mean_squared_error: 290757.2188\n",
      "Epoch 4888/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289615.4062 - mean_squared_error: 289615.4062\n",
      "Epoch 4889/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298330.3750 - mean_squared_error: 298330.3750\n",
      "Epoch 4890/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300184.2188 - mean_squared_error: 300184.2188\n",
      "Epoch 4891/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299360.7188 - mean_squared_error: 299360.6875\n",
      "Epoch 4892/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295107.4688 - mean_squared_error: 295107.4688\n",
      "Epoch 4893/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294347.6250 - mean_squared_error: 294347.6250\n",
      "Epoch 4894/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296736.1562 - mean_squared_error: 296736.1875\n",
      "Epoch 4895/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298084.3438 - mean_squared_error: 298084.3438\n",
      "Epoch 4896/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292812.3750 - mean_squared_error: 292812.3750\n",
      "Epoch 4897/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300418.2500 - mean_squared_error: 300418.2500\n",
      "Epoch 4898/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297893.6875 - mean_squared_error: 297893.6875\n",
      "Epoch 4899/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292482.1562 - mean_squared_error: 292482.1562\n",
      "Epoch 4900/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300337.0312 - mean_squared_error: 300337.0312\n",
      "Epoch 4901/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299262.7188 - mean_squared_error: 299262.7188\n",
      "Epoch 4902/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293260.6875 - mean_squared_error: 293260.6875\n",
      "Epoch 4903/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 306344.4062 - mean_squared_error: 306344.4062\n",
      "Epoch 4904/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296637.1875 - mean_squared_error: 296637.1562\n",
      "Epoch 4905/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301841.0625 - mean_squared_error: 301841.0625\n",
      "Epoch 4906/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295494.6250 - mean_squared_error: 295494.6250\n",
      "Epoch 4907/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289052.0000 - mean_squared_error: 289052.0000\n",
      "Epoch 4908/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 300095.3125 - mean_squared_error: 300095.3125\n",
      "Epoch 4909/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304995.3438 - mean_squared_error: 304995.3438\n",
      "Epoch 4910/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 290169.4062 - mean_squared_error: 290169.4062\n",
      "Epoch 4911/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292156.4688 - mean_squared_error: 292156.4688\n",
      "Epoch 4912/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299829.1562 - mean_squared_error: 299829.1562\n",
      "Epoch 4913/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294820.1562 - mean_squared_error: 294820.1562\n",
      "Epoch 4914/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300867.5625 - mean_squared_error: 300867.5625\n",
      "Epoch 4915/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294887.1875 - mean_squared_error: 294887.1875\n",
      "Epoch 4916/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292848.5000 - mean_squared_error: 292848.5000\n",
      "Epoch 4917/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295538.0312 - mean_squared_error: 295538.0000\n",
      "Epoch 4918/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290879.5938 - mean_squared_error: 290879.5938\n",
      "Epoch 4919/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293247.6875 - mean_squared_error: 293247.6875\n",
      "Epoch 4920/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296590.9375 - mean_squared_error: 296590.9375\n",
      "Epoch 4921/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287990.4375 - mean_squared_error: 287990.4375\n",
      "Epoch 4922/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 314410.6562 - mean_squared_error: 314410.6562\n",
      "Epoch 4923/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305023.5000 - mean_squared_error: 305023.5000\n",
      "Epoch 4924/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295301.3750 - mean_squared_error: 295301.3750\n",
      "Epoch 4925/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295329.5625 - mean_squared_error: 295329.5625\n",
      "Epoch 4926/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303672.5938 - mean_squared_error: 303672.5938\n",
      "Epoch 4927/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 286358.3438 - mean_squared_error: 286358.3438\n",
      "Epoch 4928/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295556.4375 - mean_squared_error: 295556.4375\n",
      "Epoch 4929/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292380.5312 - mean_squared_error: 292380.5312\n",
      "Epoch 4930/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 286673.6875 - mean_squared_error: 286673.6875\n",
      "Epoch 4931/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294085.1562 - mean_squared_error: 294085.1562\n",
      "Epoch 4932/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 303535.2500 - mean_squared_error: 303535.2500\n",
      "Epoch 4933/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295204.9375 - mean_squared_error: 295204.9375\n",
      "Epoch 4934/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299426.1875 - mean_squared_error: 299426.1875\n",
      "Epoch 4935/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299620.7500 - mean_squared_error: 299620.7500\n",
      "Epoch 4936/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296877.9062 - mean_squared_error: 296877.9375\n",
      "Epoch 4937/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303751.5000 - mean_squared_error: 303751.5000\n",
      "Epoch 4938/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296151.9688 - mean_squared_error: 296151.9688\n",
      "Epoch 4939/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294584.8750 - mean_squared_error: 294584.8750\n",
      "Epoch 4940/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296236.3125 - mean_squared_error: 296236.3125\n",
      "Epoch 4941/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301941.4375 - mean_squared_error: 301941.4375\n",
      "Epoch 4942/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294205.8750 - mean_squared_error: 294205.8750\n",
      "Epoch 4943/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295203.5625 - mean_squared_error: 295203.5312\n",
      "Epoch 4944/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 302010.3438 - mean_squared_error: 302010.3438\n",
      "Epoch 4945/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 304630.7812 - mean_squared_error: 304630.7812\n",
      "Epoch 4946/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291521.2812 - mean_squared_error: 291521.2812\n",
      "Epoch 4947/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290827.5625 - mean_squared_error: 290827.5625\n",
      "Epoch 4948/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299061.5000 - mean_squared_error: 299061.5000\n",
      "Epoch 4949/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292957.3438 - mean_squared_error: 292957.3438\n",
      "Epoch 4950/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302139.6250 - mean_squared_error: 302139.6250\n",
      "Epoch 4951/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 287296.4062 - mean_squared_error: 287296.4062\n",
      "Epoch 4952/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293488.7812 - mean_squared_error: 293488.7812\n",
      "Epoch 4953/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301523.2812 - mean_squared_error: 301523.3125\n",
      "Epoch 4954/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287545.3750 - mean_squared_error: 287545.3750\n",
      "Epoch 4955/5000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295862.6250 - mean_squared_error: 295862.6250\n",
      "Epoch 4956/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 298829.8750 - mean_squared_error: 298829.8750\n",
      "Epoch 4957/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 295366.7500 - mean_squared_error: 295366.7500\n",
      "Epoch 4958/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300135.8438 - mean_squared_error: 300135.8438\n",
      "Epoch 4959/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 293710.0000 - mean_squared_error: 293709.9688\n",
      "Epoch 4960/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297094.7812 - mean_squared_error: 297094.7812\n",
      "Epoch 4961/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299808.5312 - mean_squared_error: 299808.5312\n",
      "Epoch 4962/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296105.9062 - mean_squared_error: 296105.9062\n",
      "Epoch 4963/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288263.0000 - mean_squared_error: 288263.0000\n",
      "Epoch 4964/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297841.2188 - mean_squared_error: 297841.2500\n",
      "Epoch 4965/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299463.6562 - mean_squared_error: 299463.6562\n",
      "Epoch 4966/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 284686.3438 - mean_squared_error: 284686.3438\n",
      "Epoch 4967/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289967.3750 - mean_squared_error: 289967.3750\n",
      "Epoch 4968/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297247.4062 - mean_squared_error: 297247.4062\n",
      "Epoch 4969/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297892.6562 - mean_squared_error: 297892.6562\n",
      "Epoch 4970/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300605.4375 - mean_squared_error: 300605.4375\n",
      "Epoch 4971/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303418.9062 - mean_squared_error: 303418.9062\n",
      "Epoch 4972/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296857.5625 - mean_squared_error: 296857.5625\n",
      "Epoch 4973/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295116.8438 - mean_squared_error: 295116.8438\n",
      "Epoch 4974/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 291230.5938 - mean_squared_error: 291230.5938\n",
      "Epoch 4975/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293691.7500 - mean_squared_error: 293691.7500\n",
      "Epoch 4976/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 289749.3438 - mean_squared_error: 289749.3125\n",
      "Epoch 4977/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293706.5625 - mean_squared_error: 293706.5625\n",
      "Epoch 4978/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289440.8750 - mean_squared_error: 289440.8750\n",
      "Epoch 4979/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290854.0625 - mean_squared_error: 290854.0625\n",
      "Epoch 4980/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 286279.9062 - mean_squared_error: 286279.9062\n",
      "Epoch 4981/5000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 292104.9062 - mean_squared_error: 292104.9062\n",
      "Epoch 4982/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299323.7500 - mean_squared_error: 299323.7500\n",
      "Epoch 4983/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289523.0312 - mean_squared_error: 289523.0312\n",
      "Epoch 4984/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 283911.0312 - mean_squared_error: 283911.0312\n",
      "Epoch 4985/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291844.2812 - mean_squared_error: 291844.2812\n",
      "Epoch 4986/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293355.9688 - mean_squared_error: 293355.9688\n",
      "Epoch 4987/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296610.9062 - mean_squared_error: 296610.9062\n",
      "Epoch 4988/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286162.5938 - mean_squared_error: 286162.5938\n",
      "Epoch 4989/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297500.5312 - mean_squared_error: 297500.5312\n",
      "Epoch 4990/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295901.4375 - mean_squared_error: 295901.4688\n",
      "Epoch 4991/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 288791.2188 - mean_squared_error: 288791.2188\n",
      "Epoch 4992/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294305.0000 - mean_squared_error: 294305.0000\n",
      "Epoch 4993/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 296355.2812 - mean_squared_error: 296355.2812\n",
      "Epoch 4994/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288313.4688 - mean_squared_error: 288313.4688\n",
      "Epoch 4995/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294479.5938 - mean_squared_error: 294479.5938\n",
      "Epoch 4996/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287110.3750 - mean_squared_error: 287110.3750\n",
      "Epoch 4997/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294565.1562 - mean_squared_error: 294565.1562\n",
      "Epoch 4998/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295657.6562 - mean_squared_error: 295657.6562\n",
      "Epoch 4999/5000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298884.3438 - mean_squared_error: 298884.3438\n",
      "Epoch 5000/5000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 290288.2188 - mean_squared_error: 290288.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:07.807385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:07.808179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:07.808760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:07.879042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:07.903540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:07.904173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:07.904749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:07.999377: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.000017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.000629: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:08.072554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:08.098000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.098651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.099253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:08.194255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.194901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.195516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:08.266865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:08.292159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.292981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.293574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:08.402153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.402813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.403419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:08.500215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.500990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.501569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:08.515533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:08.519827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:08.950140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:08.975118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:08.975750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:08.976332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.054395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:09.079060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.079702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.080295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.094209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.101608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.193569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.194398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.194988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.207719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.272096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:09.296715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.297351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.297932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.310450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:09.400949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.401778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.402367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.415768: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.482117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:09.506743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.507398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.507975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.520567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.531915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.538037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.544823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.548694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.552969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.556820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.653575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.654390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.654980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.751715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.752367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.752969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.766389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.772649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.841502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:09.866347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.867128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.867728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.942186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:09.966693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:09.967331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:09.967908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:09.981533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:09.985767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.075966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.076751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.077330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.090169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.153520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:10.178114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.178739: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.179320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.191777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.282162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.282960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.283562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.296486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.360401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:10.385094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.385727: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.386305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.398725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.405997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.412056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.416388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.420256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.424551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.428439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:10.522967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.523783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.524368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.620091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.620736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.621329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.634702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.641042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.708278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:10.733286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.734065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.734644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.810746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:10.836127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.836764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.837363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.851200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.855596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:10.948167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:10.948965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:10.949560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:10.962877: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.036185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:11.061279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.061918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.062535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.075538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:11.167608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.168413: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.169003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.182246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.247271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:11.272357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.273159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.273958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.292048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.299625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.305994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.310547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.314541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.318946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.322940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:11.421307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.422118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.422720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.495683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:11.520774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.521443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.522045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.629046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.629869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.630488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.708749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:11.733978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.734651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.735273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:11.840897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.841719: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.842324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:11.915301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:11.940561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:11.941230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:11.941817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.062296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.063101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.063715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.136847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:12.161932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.162571: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.163593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.268552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.269356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.269947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.343693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:12.368900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.369583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.370190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:12.475231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.476039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.476641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.550322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:12.578885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.579560: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.580152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:12.632797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype double and shape [?,30,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-07-13 02:24:12.664979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype double and shape [?,30,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-07-13 02:24:12.671982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.678106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.684964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.690959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.697485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.703658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.706463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.728956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype double and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.743401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype double and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.796869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype double and shape [?,30,1]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-07-13 02:24:12.821625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype double and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.835583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype double and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:12.927819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:12.928650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:12.929253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.004025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:13.029014: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.029670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.030272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.126564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.127227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.127858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:13.201804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:13.226864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.227514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.228108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.324543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.325187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.325791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.397718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:13.423734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.424547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.425136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.849183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.850002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.850597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:13.923456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:13.948574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:13.949206: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:13.949784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.046370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.047037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.047655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:14.121101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:14.146675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.147337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.147936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.252351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.252990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.253581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.325936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:14.350970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.351795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.352559: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.383633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:14.390020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:14.396069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:14.402189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:14.490539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.491235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.491841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.565881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:14.598531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.599563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.600477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.704465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.705101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.705689: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:14.777886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:14.804621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.805244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.805819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.912388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:14.913049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:14.913640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:14.988820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:15.016189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.016991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.017712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.121742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.122386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.122966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.194909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:15.220484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.221108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.221689: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.247407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:15.253712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:15.259760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:15.265792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:15.354263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.354919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.355529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:15.428274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:15.453247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.453871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.454455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.554848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.555515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.556090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.627498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:15.655257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.656102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.656703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.763666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.764318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.764900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.836708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:15.862110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.862939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.863535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:15.966591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:15.967245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:15.967850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.039382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:16.064686: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.065454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.066033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.092057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:16.098365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:16.104983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:16.111019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:16.204692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.205338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.205939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.278670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:16.303865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.304503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.305104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.417109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.417767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.418358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.491333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:16.516370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.517037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.517620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.620266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.620916: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.621501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:16.693757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:16.718837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.719521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.720121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.820807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.821466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.822066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.893607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:16.923797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:16.924713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:16.925320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:16.947534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,30,2]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:16.972556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:16.978786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:16.983484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:16.987642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:17.075506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.076158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.076746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.175136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.175963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.176559: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.276949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.277588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.278166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:17.379711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.380488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.381070: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.401433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:17.405740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:17.410017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:17.414216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:17.479234: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:17.506638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.507289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.507865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.582917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:17.613097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.613751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.614337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.689821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:17.714746: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.715409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.716027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.793125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:17.820715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.821343: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.821917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:17.841992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:17.846783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:17.850947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:17.855116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:17.945461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:17.946100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:17.946679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:18.045447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.046249: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.046830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.149607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.150266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.150857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.248649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.249409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.249999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.270031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:18.274301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:18.278569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:18.282760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:18.347639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:18.373147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.373801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.374380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.448499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:18.473980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.474778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.475394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.551221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:18.576216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.576867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.577437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.651611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:18.676821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.677577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.678164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.698442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:18.703220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:18.707349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:18.711495: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:18.799601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.800261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.800852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:18.898998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:18.899826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:18.900426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:19.000781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.001428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.002017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:19.102607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.103384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.103980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:19.124207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:19.128539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype float and shape [?,?,2]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-07-13 02:24:19.132962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:19.137151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,?,?]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-13 02:24:19.202637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:19.228341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.229048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.229634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 02:24:19.304815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:19.330745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.331411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.332034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:19.411918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:19.436811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.437431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.438031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 02:24:19.512731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 02:24:19.537772: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 02:24:19.538398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 02:24:19.538972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "{\"levelname\": \"WARNING\", \"asctime\": \"2023-07-13 02:24:19,572\", \"filename\": \"save.py\", \"funcName\": \"__init__\", \"lineno\": 274, \"message\": \"Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\"}\n",
      "2023-07-13 02:24:19.690781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_1' with dtype double and shape [?,30,1]\n",
      "\t [[{{node serving_default_input_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"levelname\": \"INFO\", \"asctime\": \"2023-07-13 02:24:21,822\", \"filename\": \"builder_impl.py\", \"funcName\": \"copy_assets_to_destination_dir\", \"lineno\": 797, \"message\": \"Assets written to: ./auto_model/best_model/assets\"}\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "\n",
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(1000, window_size, 1)\n",
    "    y_train = np.random.rand(1000, n_forecast, 1)\n",
    "\n",
    "    # Initialize the time series forecaster\n",
    "    input_node = ak.Input()\n",
    "    gru_node = ak.RNNBlock(return_sequences=True, layer_type=\"lstm\")(input_node)\n",
    "    output_node = ak.RegressionHead(output_dim=n_forecast)(gru_node)\n",
    "\n",
    "    auto_model = ak.AutoModel(\n",
    "    inputs=input_node,\n",
    "    outputs=output_node,\n",
    "    overwrite=True,\n",
    "    max_trials=5)\n",
    "\n",
    "#     predict_from = 1\n",
    "#     predict_until = n_forecast\n",
    "#     lookback = window_size\n",
    "#     auto_model = ak.TimeseriesForecaster(\n",
    "#         lookback=lookback,\n",
    "#         predict_from=predict_from,\n",
    "#         predict_until=predict_until,\n",
    "#         max_trials=1,\n",
    "#         objective=\"mse\",\n",
    "#     )\n",
    "    i = np.array(inputs)\n",
    "    t = np.array(targets)\n",
    "    print(t.shape)\n",
    "    # Search for the best model architecture\n",
    "    auto_model.fit(\n",
    "        np.reshape(\n",
    "            i, (-1,window_size, 1)\n",
    "        ),\n",
    "        np.reshape(\n",
    "            t, (-1, n_forecast)\n",
    "        ),\n",
    "        batch_size=100,\n",
    "        epochs=5000,\n",
    "        validation_split=0.1)\n",
    "    \n",
    "    return auto_model\n",
    "\n",
    "model = generate_time_series_forecaster(window_size, nforecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1889a9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1929.53999594, -1961.00165263, -1964.55767678, ...,\n",
       "        -1909.56735679, -1923.05987094, -1945.47483065],\n",
       "       [-1961.00165263, -1964.55767678, -1938.41116982, ...,\n",
       "        -1923.05987094, -1945.47483065, -1953.70679393],\n",
       "       [-1964.55767678, -1938.41116982, -1931.05581382, ...,\n",
       "        -1945.47483065, -1953.70679393, -1946.12153939],\n",
       "       ...,\n",
       "       [-1914.81785501, -1900.09768338, -1885.83581128, ...,\n",
       "        -1931.09257791, -1932.78210875, -1966.10799588],\n",
       "       [-1900.09768338, -1885.83581128, -1923.88924745, ...,\n",
       "        -1932.78210875, -1966.10799588, -1955.35799465],\n",
       "       [-1885.83581128, -1923.88924745, -1906.7273003 , ...,\n",
       "        -1966.10799588, -1955.35799465, -1954.38104772]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ea031d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:08.105213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.105297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.105348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.136682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.136762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.136814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.152414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.152480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.152529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.174867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.175638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.175690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.175737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.226088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.226165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.226213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.240012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.240769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.240819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.240864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.254807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.255584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.255635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.255682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.275930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.276694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.276745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.276792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:08.328566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.329354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.329405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.329452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.350404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.351178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.351236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.351284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.363412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.364167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.364217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.364262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.384907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.384973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.385022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.413048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.413108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.413157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.431967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.432737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.432790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.432837: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.447305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.447367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.447415: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.476323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.477090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.477141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.477189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.513435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.513519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.513571: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:08.554496: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.555304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.555357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.555403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.604099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.604181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.604232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.640227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.641003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.641055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.641102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.679249: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.680017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.680068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.680114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.692506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.693333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.693386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.693435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.750418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.750490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.750538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:08.763612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.763673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.763723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.786611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.786710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.786787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.837749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.838558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.838611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.838659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.883854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.883960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.884036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.897181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.897241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.897288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.923497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.923557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.923605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:08.966315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:08.967085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:08.967136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:08.967183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.009533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.009610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.009660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.083428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.083503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.083552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.102677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.103451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.103503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.103549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.150624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.150692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.150741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.164864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.164919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.164967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:09.249254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.249327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.249375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.291780: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.291855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.291903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.304700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.304756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.304804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.316899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.317644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.317693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.317740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.358748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.359549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.359602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.359649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.387654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.387717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.387764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.401781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.401838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.401886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.444001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.444075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.444123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:09.457401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.457475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.457526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.505908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.506683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.506735: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.506781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.556972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.557748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.557800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.557847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.630518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.630588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.630636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.684318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.685121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.685176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.685223: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.700022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.700083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.700132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.730474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.731235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.731286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.731332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.751166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.751236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.751286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.764421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.764477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.764525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.812510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.812578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.812626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.832551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.832611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.832658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:09.916427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.916501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.916550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.972373: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:09.973156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.973210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.973257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:09.993023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:09.993089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:09.993137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.005268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.006041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.006091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.006139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.018152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.018903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.018953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.018998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.038876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.038937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.038985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.075823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.076574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.076623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.076669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:10.233695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.233769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.233817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.247471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.248222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.248272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.248317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.329624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.330400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.330452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.330499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.349960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.350836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.350899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.350950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.411327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.412071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.412119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.412164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.466218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.466288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.466333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.478163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.478891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.478938: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.478983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.567933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.568002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.568048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.589088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.589840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.589889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.589934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.616796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.617541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.617590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.617635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.634408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.635135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.635183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.635235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.648732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.649461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.649509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.649554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.661288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.662129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.662180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.662227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:10.724033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.724101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.724149: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.828855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.828925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.828972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.937345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:10.938109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.938159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.938204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:10.976936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:10.976997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:10.977043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.019872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.020604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.020652: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.020697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.036224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.036960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.037010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.037056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.092045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.092116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.092165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.110300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.111038: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.111086: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.111131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:11.157220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.157967: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.158017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.158063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.209580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.209654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.209703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.222027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.222082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.222128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.246889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.246996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.247073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.291493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.291558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.291606: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.466958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.467737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.467786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.467831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.493453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.494207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.494255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.494301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.506808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.506862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.506908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.520574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.520628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.520674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.588400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.589158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.589209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.589254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:11.675019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.675091: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.675138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.785599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.786353: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.786401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.786445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.823275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:11.824026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.824075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.824120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:11.994246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:11.994316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:11.994362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.108673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:12.109424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.109472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.109517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.213389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:12.214188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.214237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.214282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.255208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:12.256472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.256556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.256633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.315616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:12.316357: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.316406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.316451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.328099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:49:12.328824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.328873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.328918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:49:12.341369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:49:12.341424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:49:12.341470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:12.602232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:12.603062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:12.603640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:12.674139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:12.698368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:12.698996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:12.699577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:12.795395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:12.796021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:12.796577: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:12.871049: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:12.895943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:12.896580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:12.897151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:12.992017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:12.992653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:12.993217: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.068228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:13.092926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.093747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.094324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.208932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [50,30,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-13 11:49:13.209060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [50,30,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:49:13.308535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.309361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.309948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.386298: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:13.413840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.414487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.415069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.514617: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.515443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.516079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.593737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:13.618898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.619549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.620142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.722678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.723493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.724113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:49:13.798155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:49:13.823310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:49:13.823950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:49:13.824543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pre2 = model.predict(\n",
    "    np.reshape(\n",
    "        i[-50:], (-1,window_size, 1)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f002b07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9878, -1103.6897, -1105.4188, -1107.0457, -1108.6768,\n",
       "        -1110.4156, -1112.1609, -1113.8026, -1115.4579, -1117.1393,\n",
       "        -1118.8564, -1120.5854, -1122.4058, -1124.2347, -1126.0712,\n",
       "        -1127.8594, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9878, -1103.6897, -1105.4188, -1107.0457, -1108.6768,\n",
       "        -1110.4156, -1112.1609, -1113.8026, -1115.4579, -1117.1393,\n",
       "        -1118.8564, -1120.5854, -1122.4058, -1124.2347, -1126.0712,\n",
       "        -1127.8594, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241],\n",
       "       [-1101.9879, -1103.6895, -1105.4188, -1107.0454, -1108.6769,\n",
       "        -1110.4159, -1112.1609, -1113.8024, -1115.4578, -1117.1394,\n",
       "        -1118.8563, -1120.5853, -1122.4059, -1124.2351, -1126.0712,\n",
       "        -1127.8593, -1129.7363, -1131.5598, -1133.3997, -1135.3241]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42ac21a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[  -20.98471561],\n",
       "         [  -12.10540982],\n",
       "         [   19.59098825],\n",
       "         ...,\n",
       "         [   18.99116149],\n",
       "         [   13.16378675],\n",
       "         [   10.50707193]],\n",
       " \n",
       "        [[  -12.10540982],\n",
       "         [   19.59098825],\n",
       "         [   11.19709376],\n",
       "         ...,\n",
       "         [   13.16378675],\n",
       "         [   10.50707193],\n",
       "         [   49.66238216]],\n",
       " \n",
       "        [[   19.59098825],\n",
       "         [   11.19709376],\n",
       "         [  -10.20481069],\n",
       "         ...,\n",
       "         [   10.50707193],\n",
       "         [   49.66238216],\n",
       "         [   59.29808998]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1914.81785501],\n",
       "         [-1900.09768338],\n",
       "         [-1885.83581128],\n",
       "         ...,\n",
       "         [-1931.09257791],\n",
       "         [-1932.78210875],\n",
       "         [-1966.10799588]],\n",
       " \n",
       "        [[-1900.09768338],\n",
       "         [-1885.83581128],\n",
       "         [-1923.88924745],\n",
       "         ...,\n",
       "         [-1932.78210875],\n",
       "         [-1966.10799588],\n",
       "         [-1955.35799465]],\n",
       " \n",
       "        [[-1885.83581128],\n",
       "         [-1923.88924745],\n",
       "         [-1906.7273003 ],\n",
       "         ...,\n",
       "         [-1966.10799588],\n",
       "         [-1955.35799465],\n",
       "         [-1954.38104772]]]),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(\n",
    "        i, (-1,window_size, 1)\n",
    "    ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fbcf563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:24.844580: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.844662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.844712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.875993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.876071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.876120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.891785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.891852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.891902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.914628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:24.915417: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.915469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.915516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.960113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.960190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.960242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.973793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:24.974557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.974607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.974653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:24.988317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:24.989072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:24.989122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:24.989168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.010331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.011103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.011157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.011205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:25.069113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.069900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.069954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.070003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.091258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.092018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.092069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.092115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.104325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.105087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.105138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.105185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.127518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.127614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.127662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.156110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.156172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.156220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.177925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.179200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.179304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.179384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.195442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.195499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.195552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.227860: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.228632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.228684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.228731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.264075: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.264145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.264194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:25.305358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.306148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.306201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.306248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.356810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.356905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.356957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.394137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.394917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.394983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.395030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.433985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.434756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.434807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.434855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.447321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.448069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.448120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.448167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.504831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.504939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.504987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:25.521306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.521380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.521431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.538383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.538441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.538489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.587015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.587793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.587845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.587892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.633853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.633923: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.633971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.646904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.646963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.647010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.673685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.673752: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.673802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.716519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.717293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.717346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.717394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:25.758721: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.758804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.758856: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.831150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.831228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.831278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.851057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:25.851822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.851873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.851919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.899191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.899266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.899316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.913942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.914005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.914053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:25.999263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:25.999342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:25.999393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.041507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.041581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.041630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.054834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.054895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.054943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.067593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.068451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.068506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.068553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.110585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.111476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.111538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.111587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.140850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.140918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.140969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.155639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.155701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.155748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:26.203611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.203690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.203740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.221551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.221679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.221741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.272443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.273320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.273375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.273422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.325986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.326864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.326922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.326971: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.410822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.410905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.410955: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.467911: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.469324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.469416: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.469497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.483510: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.483575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.483623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.515612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.516466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.516522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.516570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.537183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.537247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.537297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.550586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.550647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.550695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.600508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.600582: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.600631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:26.623907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.623979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.624029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.712966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.713045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.713094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.771136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.772045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.772105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.772153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.792987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.793048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.793097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.805519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.806362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.806416: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.806463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.819304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.820175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.820231: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.820280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:26.843103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.843225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.843314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:26.882634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:26.883499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:26.883555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:26.883602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.072842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.072917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.072968: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.087558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.088478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.088543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.088592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.178564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.180007: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.180103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.180185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.200369: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.201222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.201278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.201326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.256924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.257787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.257850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.257897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:27.318496: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.318575: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.318625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.331243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.332100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.332155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.332201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.426962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.427041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.427094: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.449541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.450401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.450456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.450504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.484955: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.486294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.486361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.486418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.504471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.505312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.505367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.505415: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:27.519751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.520589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.520647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.520694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.534157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:27.534998: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.535052: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.535098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:27.598067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:27.598142: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:27.598190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:28.732146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:28.732257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:28.732338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:28.837986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:28.838808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:28.838859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:28.838905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:28.881796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:28.881899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:28.881981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:28.927012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:28.927824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:28.927875: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:28.927922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:28.944443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:28.945244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:28.945295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:28.945340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.006945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.007019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.007068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.025908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.026704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.026756: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.026802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.073774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.074569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.074621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.074667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.127997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.128106: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.128186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.142604: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.142662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.142709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:29.168073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.168151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.168201: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.215352: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.215422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.215469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.405394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.406194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.406244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.406291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.432974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.434263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.434347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.434424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.448116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.448179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.448226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.462282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.462338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.462386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.529194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.530017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.530068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.530113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:29.622522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.622595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.622643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.737747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.738541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.738594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.738640: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.777294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:29.778083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.778135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.778181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:29.955748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:29.955825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:29.955875: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.077563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:30.078340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.078392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.078437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.184457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:30.185248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.185303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.185350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.226448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:30.227225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.227278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.227325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.283295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:30.284116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.284173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.284219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.296422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-07-13 11:41:30.297179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.297229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.297274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-07-13 11:41:30.310024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-07-13 11:41:30.310080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-07-13 11:41:30.310127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:30.585588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:30.586454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:30.587039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:30.661067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:30.685976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:30.686633: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:30.687225: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:30.785651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:30.786553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:30.787492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:30.860675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:30.885474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:30.886151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:30.886755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:30.984516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:30.985153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:30.985723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.059834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:31.084964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.085584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.086164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.177799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1046,30,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-13 11:41:31.177947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [1046,30,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:41:31.296413: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.297266: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.297868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.377009: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:31.402810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.403476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.404076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.508922: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.509786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.510433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.588465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:31.613867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.614520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.615115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.720732: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.721561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.722999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 11:41:31.798345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 11:41:31.823776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 11:41:31.824422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 11:41:31.825016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 3ms/step\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  -19.882252,   -19.408764,   -19.544458, ...,   -21.68626 ,\n",
       "          -21.57542 ,   -21.454838],\n",
       "       [   -8.788613,    -8.169158,    -8.277711, ...,   -10.239681,\n",
       "          -10.036526,    -9.943562],\n",
       "       [  -26.897713,   -26.462757,   -26.327469, ...,   -28.92686 ,\n",
       "          -28.935604,   -28.633213],\n",
       "       ...,\n",
       "       [-1101.9879  , -1103.6895  , -1105.4188  , ..., -1131.5598  ,\n",
       "        -1133.3997  , -1135.3241  ],\n",
       "       [-1101.9879  , -1103.6895  , -1105.4188  , ..., -1131.5598  ,\n",
       "        -1133.3997  , -1135.3241  ],\n",
       "       [-1101.9879  , -1103.6895  , -1105.4188  , ..., -1131.5598  ,\n",
       "        -1133.3997  , -1135.3241  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.array(inputs)\n",
    "pre = model.predict(\n",
    "    np.reshape(\n",
    "        i, (-1,window_size, 1)\n",
    "    ),\n",
    ")\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a68777",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = model.export_model()\n",
    "mo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf16b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e97595e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542971"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564abbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = model.predict(\n",
    "    np.reshape(\n",
    "        i, (-1,window_size, 1)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189c9591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 00:15:18.783736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 00:15:18.784576: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 00:15:18.785171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 00:15:18.857847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 00:15:18.882741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 00:15:18.883395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 00:15:18.883978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-13 00:15:18.981203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 00:15:18.981867: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 00:15:18.982490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 1/33 [..............................] - ETA: 17s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 00:15:19.056305: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-13 00:15:19.081474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-13 00:15:19.082124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-13 00:15:19.082716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pre = mo.predict(np.array(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fff74a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054],\n",
       "       [-906.8989 , -908.65155, -910.44916, -911.9363 , -914.39825,\n",
       "        -915.4458 , -917.4047 , -918.9587 , -920.32935, -921.9673 ,\n",
       "        -923.6033 , -925.5238 , -926.88196, -928.7788 , -930.6477 ,\n",
       "        -932.17084, -933.57294, -935.4267 , -937.32684, -938.68054]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a8d5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "\n",
    "def generate_time_series_forecaster(window_size, n_forecast):\n",
    "    # Generate some dummy data\n",
    "    X_train = np.random.rand(1000, window_size, 1)\n",
    "    y_train = np.random.rand(1000, n_forecast, 1)\n",
    "\n",
    "    # Initialize the time series forecaster\n",
    "    input_node = ak.Input()\n",
    "    gru_node = ak.RNNBlock(return_sequences=True, layer_type=\"lstm\")(input_node)\n",
    "    dense_node = ak.DenseBlock()(gru_node)\n",
    "    output_node = ak.RegressionHead(output_dim=n_forecast)(dense_node)\n",
    "\n",
    "    auto_model = ak.AutoModel(\n",
    "    inputs=input_node,\n",
    "    outputs=output_node,\n",
    "    overwrite=True,\n",
    "    max_trials=2)\n",
    "\n",
    "#     predict_from = 1\n",
    "#     predict_until = n_forecast\n",
    "#     lookback = window_size\n",
    "#     auto_model = ak.TimeseriesForecaster(\n",
    "#         lookback=lookback,\n",
    "#         predict_from=predict_from,\n",
    "#         predict_until=predict_until,\n",
    "#         max_trials=1,\n",
    "#         objective=\"mse\",\n",
    "#     )\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    inputs\n",
    "    # Search for the best model architecture\n",
    "    auto_model.fit(\n",
    "        np.reshape(\n",
    "            np.array(inputs), (-1,window_size)\n",
    "        ),\n",
    "        np.reshape(\n",
    "            np.array(targets), (-1,n_forecast, 1)\n",
    "        ), batch_size=100, epochs=1, validation_split=0.1)\n",
    "    \n",
    "    return auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1319b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(\n",
    "    inputs, (-1,window_size, 1)\n",
    "),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(\n",
    "    np.array(targets), (-1,nforecast,1)\n",
    ")\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(\n",
    "            np.array(inputs), (-1,window_size,1)\n",
    "        )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa82699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 30, 1)\n",
      "(1000, 20, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 23:21:40.446095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1046,20,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-12 23:21:40.446218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1046,20,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-12 23:21:40.467993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1046,20,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-07-12 23:21:40.468104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [1046,20,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expect the input tensor of RNNBlock to have dimensions of [batch_size, time_steps, vec_len], but got (None, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_time_series_forecaster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnforecast\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m, in \u001b[0;36mgenerate_time_series_forecaster\u001b[0;34m(window_size, n_forecast)\u001b[0m\n\u001b[1;32m     34\u001b[0m inputs\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Search for the best model architecture\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mauto_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn_forecast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m auto_model\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m validation_split:\n\u001b[1;32m    288\u001b[0m     dataset, validation_data \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39msplit_dataset(\n\u001b[1;32m    289\u001b[0m         dataset, validation_split\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 292\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/engine/tuner.py:191\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_space()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_model_build(hp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m    194\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs, callbacks\u001b[38;5;241m=\u001b[39mnew_callbacks, verbose\u001b[38;5;241m=\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs\n\u001b[1;32m    195\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:155\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    152\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m    153\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m--> 155\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hypermodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:146\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_hypermodel\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 146\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_compile_args(model)\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py:115\u001b[0m, in \u001b[0;36mHyperModel._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtunable:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Copy `HyperParameters` object so that new entries are not added\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# to the search space.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     hp \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/graph.py:250\u001b[0m, in \u001b[0;36mGraph.build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m    246\u001b[0m     temp_inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    247\u001b[0m         keras_nodes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_to_id[input_node]]\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m input_node \u001b[38;5;129;01min\u001b[39;00m block\u001b[38;5;241m.\u001b[39minputs\n\u001b[1;32m    249\u001b[0m     ]\n\u001b[0;32m--> 250\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output_node, real_output_node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(block\u001b[38;5;241m.\u001b[39moutputs, outputs):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/engine/block.py:38\u001b[0m, in \u001b[0;36mBlock._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hp\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py:115\u001b[0m, in \u001b[0;36mHyperModel._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtunable:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Copy `HyperParameters` object so that new entries are not added\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# to the search space.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     hp \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/autokeras/blocks/basic.py:216\u001b[0m, in \u001b[0;36mRNNBlock.build\u001b[0;34m(self, hp, inputs)\u001b[0m\n\u001b[1;32m    214\u001b[0m shape \u001b[38;5;241m=\u001b[39m input_node\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect the input tensor of RNNBlock to have dimensions of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[batch_size, time_steps, vec_len], \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{shape}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape\u001b[38;5;241m=\u001b[39minput_node\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    222\u001b[0m feature_size \u001b[38;5;241m=\u001b[39m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    223\u001b[0m output_node \u001b[38;5;241m=\u001b[39m input_node\n",
      "\u001b[0;31mValueError\u001b[0m: Expect the input tensor of RNNBlock to have dimensions of [batch_size, time_steps, vec_len], but got (None, 30)"
     ]
    }
   ],
   "source": [
    "model = generate_time_series_forecaster(window_size, nforecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb69f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = model.export_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65e23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = mo.predict(\n",
    "    np.reshape(\n",
    "        np.array(inputs), (-1,window_size,1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79d82680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_compra_comigo.data_handler import Visualizer\n",
    "\n",
    "visualizer = Visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "380dc1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = visualizer.create_gif(\n",
    "    time_data=time_data,\n",
    "    series=series,\n",
    "    forecast=pre,\n",
    "    batch_size=batch_size,\n",
    "    window_size=window_size,\n",
    "    nforecast=nforecast,\n",
    "    gif_window=70\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1540c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[0].save('./tmp/knnak2.gif',\n",
    "             save_all = True, append_images = plots[1:], \n",
    "             optimize = False, duration = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a26c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
